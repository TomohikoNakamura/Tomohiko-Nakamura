
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Tomohiko Nakamura">
      
      
        <link rel="canonical" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/publications.html">
      
      
        <link rel="prev" href="research.html">
      
      
        <link rel="next" href="datasets.html">
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.5">
    
    
      
        <title>Publications / 発表文献 - Tomohiko Nakamura</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.7a7fce14.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9EPRVMYY0Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9EPRVMYY0Z');
</script>
    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="primary">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#publications" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Tomohiko Nakamura" class="md-header__button md-logo" aria-label="Tomohiko Nakamura" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Tomohiko Nakamura
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Publications / 発表文献
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Tomohiko Nakamura" class="md-nav__button md-logo" aria-label="Tomohiko Nakamura" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Tomohiko Nakamura
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="research.html" class="md-nav__link">
        Research / Demo
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="publications.html" class="md-nav__link md-nav__link--active">
        Publications
      </a>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="datasets.html" class="md-nav__link">
        Datasets
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="lecture.html" class="md-nav__link">
        Lecture Notes
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="publications">Publications / 発表文献<a class="headerlink" href="#publications" title="Permanent link">&para;</a></h1>
<p><strong><a href="pdfs/nakamura_CV_short.pdf">Short CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="pdfs/nakamura_CV.pdf">Full CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://scholar.google.com/citations?user=bHny6PAAAAAJ">Google Scholar<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M562.8 267.7c56.5-56.5 56.5-148 0-204.5-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6 31.5 31.5 31.5 82.5 0 114L405.3 334.8c-31.5 31.5-82.5 31.5-114 0-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C189.5 251.2 196 330 246 380c56.5 56.5 148 56.5 204.5 0l112.3-112.3zM43.2 244.3c-56.5 56.5-56.5 148 0 204.5 50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C57 372 57 321 88.5 289.5l112.2-112.3c31.5-31.5 82.5-31.5 114 0 27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C416.5 260.8 410 182 360 132c-56.5-56.5-148-56.5-204.5 0L43.2 244.3z"/></svg></span></a>, <a href="https://researchmap.jp/tomohiko_nakamura">Researchmap<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M562.8 267.7c56.5-56.5 56.5-148 0-204.5-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6 31.5 31.5 31.5 82.5 0 114L405.3 334.8c-31.5 31.5-82.5 31.5-114 0-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C189.5 251.2 196 330 246 380c56.5 56.5 148 56.5 204.5 0l112.3-112.3zM43.2 244.3c-56.5 56.5-56.5 148 0 204.5 50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C57 372 57 321 88.5 289.5l112.2-112.3c31.5-31.5 82.5-31.5 114 0 27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C416.5 260.8 410 182 360 132c-56.5-56.5-148-56.5-204.5 0L43.2 244.3z"/></svg></span></a>, <a href="https://orcid.org/0000-0003-4385-7170">ORCiD<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M562.8 267.7c56.5-56.5 56.5-148 0-204.5-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6 31.5 31.5 31.5 82.5 0 114L405.3 334.8c-31.5 31.5-82.5 31.5-114 0-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C189.5 251.2 196 330 246 380c56.5 56.5 148 56.5 204.5 0l112.3-112.3zM43.2 244.3c-56.5 56.5-56.5 148 0 204.5 50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C57 372 57 321 88.5 289.5l112.2-112.3c31.5-31.5 82.5-31.5 114 0 27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C416.5 260.8 410 182 360 132c-56.5-56.5-148-56.5-204.5 0L43.2 244.3z"/></svg></span></a></strong></p>
<h2 id="journals">Journals / 査読付き論文誌<a class="headerlink" href="#journals" title="Permanent link">&para;</a></h2>
<ol>
<li>Koichi Saito, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, and Hiroshi Saruwatari, “<strong>Sampling-frequency-independent convolutional layer and its application to audio source separation</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 30, pp. 2928–2943, Sep. 2022. <a href="https://doi.org/10.1109/TASLP.2022.3203907">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/sfi_convtasnet/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/sfi_convtasnet">code<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Shihori Kozuka, and Hiroshi Saruwatari, “<strong>Time-domain audio source separation with neural networks based on multiresolution analysis</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 1687–1701, Apr. 2021. <a href="https://doi.org/10.1109/TASLP.2021.3072496">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://drive.google.com/file/d/1ktPip2P8v7Etrivj5pfOQnU5A5MAmpjW/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://drive.google.com/file/d/13B3ixDE4v0vzy5iJfqP55uaLMjtpaOG7/view?usp=sharing">poster<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/MRDLA/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/dwtls">code<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[The Itakura Prize Innovative Young Researcher Award / 第17回日本音響学会・独創研究奨励賞板倉記念]</span></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Harmonic-temporal factor decomposition for unsupervised monaural separation of harmonic sounds</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 68–82, Nov. 2020. <a href="https://doi.org/10.1109/TASLP.2020.3037487">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://drive.google.com/file/d/12JznF2tNTDyA4O324Xo0JBg835kzjULu/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://drive.google.com/file/d/13COFStiemA7GSdtVESQHPqim4navDJFo/view?usp=sharing">poster<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/HTFD/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/HTFD">code<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Real-time audio-to-score alignment of music performances containing errors and arbitrary repeats and skips</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 24, no. 2, pp. 329–339, Feb. 2016. <a href="https://doi.org/10.1109/TASLP.2015.2507862">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/1512.07748">arXiv</a>, <a href="demo/automatic_accompaniment/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Yutaka Hori, and Shinji Hara, “<strong>Hierarchical modeling and local stability analysis for repressilators coupled by quorum sensing</strong>,” <em>SICE Journal of Control, Measurement, and System Integration</em>, vol. 7, no. 3, pp. 133–140, May 2014. <a href="https://doi.org/10.9746/jcmsi.7.133">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[SICE Best Paper Award (Takeda Award) / 2015年計測自動制御学会 論文賞 (武田賞)]</span></li>
<li>Eita Nakamura, <ins>Tomohiko Nakamura</ins>, Yasuyuki Saito, Nobutaka Ono, and Shigeki Sagayama, “<strong>Outer-product type hidden Markov model and polyphonic MIDI score following</strong>,” <em>Journal of New Music Research</em>, vol. 43, pp. 183–201, Apr. 2014. <a href="https://doi.org/10.1080/09298215.2014.884145">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/1404.2313">arXiv</a></li>
</ol>
<h2 id="international-conferences">International Conferences / 査読付き国際会議<a class="headerlink" href="#international-conferences" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>Tomohiko Nakamura</ins>, Shinnosuke Takamichi, Naoko Tanji, Satoru Fukayama, and Hiroshi Saruwatari, “<strong><span class="nocase">jaCappella corpus: A japanese a cappella vocal ensemble corpus</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Jun. 2023. (to appear) <a href="https://arxiv.org/abs/2211.16028">arXiv</a>, <a href="demo/jaCappella_sep">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/asteroid_jaCappella">code<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li>Kota Arai, Yutaro Hirao, Takuji Narumi, <ins>Tomohiko Nakamura</ins>, Shinnosuke Takamichi, and Shigeo Yoshida, “<strong>TimToShape: Supporting practice of musical instruments by visualizing timbre with 2D shapes based on crossmodal correspondences</strong>,” in <em>Proceedings of ACM Conference on Intelligent User Interfaces</em>, Mar. 2023, pp. 850–865. <a href="https://doi.org/10.1145/3581641.3584053">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://medium.com/@shigeo.yoshida/musical-instrument-practice-support-system-based-on-crossmodal-correspondences-to-be-presented-at-500a02fd22b0">blog<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M192 32c0 17.7 14.3 32 32 32 123.7 0 224 100.3 224 224 0 17.7 14.3 32 32 32s32-14.3 32-32C512 128.9 383.1 0 224 0c-17.7 0-32 14.3-32 32zm0 96c0 17.7 14.3 32 32 32 70.7 0 128 57.3 128 128 0 17.7 14.3 32 32 32s32-14.3 32-32c0-106-86-192-192-192-17.7 0-32 14.3-32 32zm-96 16c0-26.5-21.5-48-48-48S0 117.5 0 144v224c0 79.5 64.5 144 144 144s144-64.5 144-144-64.5-144-144-144h-16v96h16c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48V144z"/></svg></span></a></li>
<li>Futa Nakashima, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Satoru Fukayama, and Hiroshi Saruwatari, “<strong>Hyperbolic timbre embedding for musical instrument sound synthesis based on variational autoencoders</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Nov. 2022, pp. 736–743. <a href="https://doi.org/10.23919/APSIPAASC55919.2022.9980158">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2209.13211">arXiv</a></li>
<li>Yuki Ito, <ins>Tomohiko Nakamura</ins>, Shoichi Koyama, and Hiroshi Saruwatari, “<strong>Head-related transfer function interpolation from spatially sparse measurements using autoencoder with source position conditioning</strong>,” in <em>Proceedings of International Workshop on Acoustic Signal Enhancement</em>, Sep. 2022. <a href="https://doi.org/10.1109/IWAENC53105.2022.9914751">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2207.10967">arXiv</a>, <a href="https://github.com/ikets/HRTFInterpAE_public/blob/main/docs/Ito_IWAENC2022_public.pdf">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://ikets.github.io/HRTFInterpAE_public/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/ikets/HRTFInterpAE_public">code<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Finalist of Best Student Paper Award of IWAENC 2022 (Yuki Ito)]</span></li>
<li>Kazuhide Shigemi, Shoichi Koyama, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong>Physics-informed convolutional neural network with bicubic spline interpolation for sound field estimation</strong>,” in <em>Proceedings of International Workshop on Acoustic Signal Enhancement</em>, Sep. 2022. <a href="https://doi.org/10.1109/IWAENC53105.2022.9914792">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2207.10937">arXiv</a></li>
<li>Takaaki Saeki, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Naoko Tanji, and Hiroshi Saruwatari, “<strong>SelfRemaster: Self-supervised speech restoration with analysis-by-synthesis approach using channel modeling</strong>,” in <em>Proceedings of Annual Conference of the International Speech Communication Association</em>, Sep. 2022, pp. 4406–4410. <a href="https://doi.org/10.21437/Interspeech.2022-298">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2203.12937">arXiv</a>, <a href="https://takaaki-saeki.github.io/ssl_remaster_demo/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/Takaaki-Saeki/ssl_speech_restoration">code<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li>Masaya Kawamura, <ins>Tomohiko Nakamura</ins>, Daichi Kitamura, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong>Differentiable digital signal processing mixture model for synthesis parameter extraction from mixture of harmonic sounds</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2022, pp. 941–945. <a href="https://doi.org/10.1109/ICASSP43922.2022.9746399">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2202.00200">arXiv</a>, <a href="https://sarulab-audio.github.io/DDSP_Mixture_Model/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[IEEE Signal Processing Society Japan Student Conference Paper Award (Awardee: Masaya Kawamura) / 第16回 IEEE Signal Processing Society Japan Student Conference Paper Award（受賞者：川村 真也）]</span></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong>Multichannel audio source separation with independent deeply learned matrix analysis using product of source models</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 1226–1233. <a href="https://ieeexplore.ieee.org/document/9689636">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2109.00704">arXiv</a></li>
<li>Sota Misawa, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, Daichi Kitamura, Hiroshi Saruwatari, Masakazu Une, and Shoji Makino, “<strong>Speech enhancement by noise self-supervised rank-constrained spatial covariance matrix estimation via independent deeply learned matrix analysis</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 578–584. <a href="https://ieeexplore.ieee.org/document/9689665/">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2109.04658">arXiv</a></li>
<li>Yusaku Mizobuchi, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong>Prior distribution design for music bleeding-sound reduction based on nonnegative matrix factorization</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 651–658. <a href="https://ieeexplore.ieee.org/document/9689601/">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2109.00237">arXiv</a></li>
<li>Koichi Saito, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, Yuma Koizumi, and Hiroshi Saruwatari, “<strong>Sampling-frequency-independent audio source separation using convolution layer based on impulse invariant method</strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Aug. 2021, pp. 321–325. <a href="https://doi.org/10.23919/EUSIPCO54536.2021.9615941">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2105.04079">arXiv</a></li>
<li>Naoki Narisawa, Rintaro Ikeshita, Norihiro Takamune, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Hiroshi Saruwatari, and Tomohiro Nakatani, “<strong>Independent deeply learned tensor analysis for determined audio source separation</strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Aug. 2021, pp. 326–330. <a href="https://doi.org/10.23919/eusipco54536.2021.9616300">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2106.05529">arXiv</a></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong>Empirical bayesian independent deeply learned matrix analysis for multichannel audio source separation</strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Aug. 2021, pp. 331–335. <a href="https://doi.org/10.23919/eusipco54536.2021.9616245">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2106.03492">arXiv</a></li>
<li>Shihori Kozuka, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong>Investigation on wavelet basis function of DNN-based time domain audio source separation inspired by multiresolution analysis</strong>,” in <em>Proceedings of International Congress and Exposition on Noise Control Engineering</em>, Aug. 2020, pp. 4013–4022. <a href="https://www.ingentaconnect.com/contentone/ince/incecp/2020/00000261/00000002/art00004">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins> and Hiroshi Saruwatari, “<strong>Time-domain audio source separation based on Wave-U-Net combined with discrete wavelet transform</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2020, pp. 386–390. <a href="https://doi.org/10.1109/ICASSP40776.2020.9053934">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://arxiv.org/abs/2001.10190">arXiv</a></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Shifted and convolutive source-filter non-negative matrix factorization for monaural audio source separation</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Mar. 2016, pp. 489–493. <a href="https://doi.org/10.1109/ICASSP.2016.7471723">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Lp-norm non-negative matrix factorization and its application to singing voice enhancement</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Apr. 2015, vol., pp. 2115–2119. <a href="https://doi.org/10.1109/ICASSP.2015.7178344">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Kotaro Shikata, Norihiro Takamune, and Hirokazu Kameoka, “<strong>Harmonic-temporal factor decomposition incorporating music prior information for informed monaural source separation</strong>,” in <em>Proceedings of International Society for Music Information Retrieval Conference</em>, Oct. 2014, pp. 623–628. <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T112_135_Paper.pdf">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/HTFD">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Tateishi Science and Technology Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Fast signal reconstruction from magnitude spectrogram of continuous wavelet transform based on spectrogram consistency</strong>,” in <em>Proceedings of International Conference on Digital Audio Effects</em>, Sep. 2014, pp. 129–135. <a href="http://www.dafx14.fau.de/papers/dafx14_tomohiko_nakamura_fast_signal_reconstructio.pdf">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/fastCWT/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Hara Research Foundation]</span></li>
<li>Takuya Higuchi, Hirofumi Takeda, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>A unified approach for underdetermined blind signal separation and source activity detection by multichannel factorial hidden Markov models</strong>,” in <em>Proceedings of Annual Conference of the International Speech Communication Association</em>, Sep. 2014, pp. 850–854. <a href="https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0850.pdf">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Hirokazu Kameoka, Kazuyoshi Yoshii, and Masataka Goto, “<strong>Timbre replacement of harmonic and drum components for music audio signals</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2014, pp. 7520–7524. <a href="https://doi.org/10.1109/ICASSP.2014.6855052">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/drum_timbre_replacement/">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a></li>
<li>Takuya Higuchi, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>Underdetermined blind separation and tracking of moving sources based on DOA-HMM</strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2014, pp. 3215–3219. <a href="https://doi.org/10.1109/ICASSP.2014.6854189">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li>Shigeki Sagayama, <ins>Tomohiko Nakamura</ins>, Eita Nakamura, Yasuyuki Saito, Hirokazu Kameoka, and Nobutaka Ono, “<strong>Automatic music accompaniment allowing errors and arbitrary repeats and jumps</strong>,” in <em>Proceedings of Meetings on Acoustics, Acoustic Society of America</em>, May 2014, vol. 21, 35003. <a href="https://doi.org/10.1121/1.4877848">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Acoustic score following to musical performance with errors and arbitrary repeats and skips for automatic accompaniment</strong>,” in <em>Proceedings of Sound and Music Computing Conference</em>, Aug. 2013, pp. 299–304. <a href="http://smcnetwork.org/node/1754">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="demo/automatic_accompaniment">demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Telecommunications Advancement Foundation]</span></li>
<li>Masahiro Nakano, Jonathan Le Roux, Hirokazu Kameoka, <ins>Tomohiko Nakamura</ins>, Nobutaka Ono, and Shigeki Sagayama, “<strong>Bayesian nonparametric spectrogram modeling based on infinite factorial infinite hidden Markov model</strong>,” in <em>Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, Oct. 2011, pp. 325–328. <a href="https://doi.org/10.1109/ASPAA.2011.6082324">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Shinji Hara, and Yutaka Hori, “<strong>Local stability analysis for a class of quorum-sensing networks with cyclic gene regulatory networks</strong>,” in <em>Proceedings of SICE Annual Conference</em>, Sep. 2011, pp. 2111–2116. <a href="https://ieeexplore.ieee.org/document/6060320">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[SICE Annual Conference 2011 International Award and Finalist of Young Author's Award]</span></li>
</ol>
<h2 id="domestic-conferences">Domestic Conferences / 国内会議<a class="headerlink" href="#domestic-conferences" title="Permanent link">&para;</a></h2>
<ol>
<li>朴 浚鎔, 高道 慎之介, <ins>中村 友彦</ins>, 関 健太郎, 辛 徳泰,  猿渡 洋, “<strong>Generative spoken language modelを用いた劣化雑音音声の分析と他言語への適用</strong>,” <em>日本音響学会 2023年春期研究発表会</em>, pp. 677–680, Mar. 2023.</li>
<li>三村 正人, 井上 昂治, 河原 達也, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>実環境下日本語話し言葉音声コーパスの構築と音声認識ベンチマーク</strong>,” <em>情報処理学会研究報告</em>, vol. 2023–SLP–146, pp. 1–6, Feb. 2023.</li>
<li><ins>中村 友彦</ins>, 高道 慎之介, 丹治 尚子, 深山 覚,  猿渡 洋, “<strong>jaCappellaコーパス:重唱分離・合成に向けた日本語アカペラ歌唱コーパス</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 1377–1378, Sep. 2022.</li>
<li>溝渕 悠朔, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>時間チャネル非負値行列因子分解を用いた被り音抑圧における初期値頑健性の比較</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 351–354, Sep. 2022.</li>
<li>川村 真也, <ins>中村 友彦</ins>, 高宗 典玄, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>混合differentiable digital signal processingモデルによる合成パラメータ抽出のためのラウドネスの時間変動に基づくロス関数の設計</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 183–186, Sep. 2022.</li>
<li>伊藤 悠貴, <ins>中村 友彦</ins>, 小山 翔一,  猿渡 洋, “<strong>音源位置で条件付けた自己符号化器を用いた少数測定データからの頭部伝達関数補間</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 501–504, Sep. 2022.</li>
<li>今村 奏海, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存畳み込み層のための時間領域ニューラルアナログフィルタ</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 187–190, Sep. 2022. <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Kanami Imamura) / 日本音響学会 第25回学生優秀発表賞（受賞者：今村 奏海）]</span></li>
<li>重見 和秀, 小山 翔一, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>スプライン補間に基づく音場表現を用いたphysics-informed neural networksによる音場推定 －散乱体を含む領域に関する検証－</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 239–242, Sep. 2022. <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Kazuhide Shigemi) / 日本音響学会 第25回学生優秀発表賞（受賞者：重見 和秀）]</span></li>
<li>中島 風太, <ins>中村 友彦</ins>, 高宗 典玄, 深山 覚,  猿渡 洋, “<strong>楽音合成のためのgauss混合変分自己符号化器への定曲率非euclid空間の導入と実験的比較</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 327–330, Sep. 2022.</li>
<li>中島 風大, <ins>中村 友彦</ins>, 高宗 典玄, 深山 覚,  猿渡 洋, “<strong>双曲空間への音色埋め込みを用いたガウス混合変分自己符号化器による楽音合成の検討</strong>,” <em>情報処理学会研究報告</em>, vol. 2022–MUS–134, no. 62, Jun. 2022. <span style="color: var(--md-code-hl-function-color)">[2022 Otogaku Symposium Best Student Presentation Award (Awardee: Futa Nakashima) / 2022年度 音学シンポジウム学生優秀発表賞（受賞者：中島 風大）]</span></li>
<li>佐伯 高明, 高道 慎之介, <ins>中村 友彦</ins>, 丹治 尚子,  猿渡 洋, “<strong>ソース・フィルタ・チャネル分解に基づく自己教師ありニューラル音声復元</strong>,” <em>情報処理学会研究報告</em>, vol. 2022–SLP–140, no. 41, Mar. 2022. <span style="color: var(--md-code-hl-function-color)">[IPSJ Yamashita SIG Research Award (Awardee: Takaaki Saeki) / 情報処理学会 2022年度山下記念研究賞（受賞者：佐伯 高明）]</span></li>
<li>伊藤 悠貴, <ins>中村 友彦</ins>, 小山 翔一,  猿渡 洋, “<strong>球波動関数展開を用いた深層学習による少数測定データからの頭部伝達関数補間</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 121, pp. 163–170, Mar. 2022.</li>
<li>重見 和秀, 小山 翔一, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>差分近似型Helmholtz方程式に基づく損失関数を用いた深層学習による少数観測点からの音場推定</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 121, pp. 132–139, Mar. 2022.</li>
<li><ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>ニューラルアナログフィルタを用いたサンプリング周波数非依存畳み込み層とモノラル音源分離への適用</strong>,” <em>日本音響学会 2022年春期研究発表会</em>, pp. 181–184, Mar. 2022.</li>
<li>川村 真也, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>混合differentiable DSP モデルによる混合楽器音からの合成パラメータ抽出の実験的評価</strong>,” <em>日本音響学会 2022年春期研究発表会</em>, pp. 177–180, Mar. 2022.</li>
<li>渡辺 瑠伊, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>深層学習に基づく周波数帯域予測による高速音源分離法の実験的評価</strong>,” <em>第24回 日本音響学会関西支部 若手研究者交流研究発表会</em>, p. 15, Dec. 2021. <span style="color: var(--md-code-hl-function-color)">[日本音響学会 第24回関西支部若手研究者交流研究発表会 奨励賞（受賞者：渡辺 瑠伊）]</span></li>
<li>溝渕 悠朔, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>非負値行列因子分解を用いた被り音の抑圧</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–132, no. 24, Sep. 2021.</li>
<li>川村 真也, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>楽譜情報を援用した音楽音響信号に対する混合differentiable DSPモデルの合成パラメータ推定</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–132, no. 22, Sep. 2021.</li>
<li>渡辺 瑠伊, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>深層学習に基づく間引きインジケータ付き周波数帯域補間手法による音源分離処理の高速化</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 155–158, Sep. 2021.</li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存音源分離モデルを用いた楽音分離の実験的評価</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 159–162, Sep. 2021.</li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>Product of priors型確率分布を導入した音源モデルに基づく独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 163–166, Sep. 2021.</li>
<li>三澤 颯大, <ins>中村 友彦</ins>, 高宗 典玄, 北村 大地,  猿渡 洋, “<strong>独立深層学習行列分析を用いたランク制約付き空間共分散行列推定による音声強調</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 279–280, Sep. 2021.</li>
<li>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>ヘビーテイル生成モデルに基づく独立深層学習テンソル分析</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 301–304, Sep. 2021.</li>
<li><ins>中村 友彦</ins>,  猿渡 洋, “<strong>多重解像度深層分析を用いた楽音分離の実験的評価</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 13, pp. 1–11, Jun. 2021. <a href="https://drive.google.com/file/d/1wKeRtR1csgcaAwiyTZ5kYwOWBFydbhk6/view">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[2021 Otogaku Symposium Best Presentation Award / 2021年度 音学シンポジウム優秀発表賞]</span></li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>周波数領域でのフィルタ設計に基づくサンプリング周波数非依存畳み込み層を用いたDNN音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 21, pp. 1–6, Jun. 2021. <span style="color: var(--md-code-hl-function-color)">[2021 Otogaku Symposium Best Student Presentation Award (Awardee: Koichi Saito) / 2021年度 音学シンポジウム学生優秀発表賞（受賞者：齋藤 弘一）]</span></li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>非負値行列因子分解を導入したproduct of experts型音源モデルに基づく独立深層学習行列分析による多チャネル音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 37, pp. 1–8, Jun. 2021.</li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>アンチエイリアシング機構を導入したサンプリング周波数非依存畳み込み層を用いた音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–130, pp. 1–6, Mar. 2021.</li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>潜在アナログフィルタ表現に基づく畳み込み層を用いたサンプリング周波数非依存なDNN音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 125–128, Mar. 2021.</li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>経験ベイズ独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 217–220, Mar. 2021. <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Takuya Hasumi) / 日本音響学会 第22回学生優秀発表賞（受賞者：蓮実 拓也）]</span></li>
<li>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>独立深層学習テンソル分析に基づく多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 117–120, Mar. 2021.</li>
<li>成澤 直輝, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>音源分離のための周波数間相関を考慮した多変量複素Gauss分布に基づく深層学習による分散共分散行列推定の検討</strong>,” <em>日本音響学会 2020年秋季研究発表会講演論文集</em>, pp. 315–318, Sep. 2020.</li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>ニューラルネットワークとウェーブレット基底関数の同時学習に基づく多重解像度深層分析を用いた時間領域音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, no. 439, pp. 279–284, Mar. 2020.</li>
<li>高道 慎之介, 齋藤 佑樹, <ins>中村 友彦</ins>, 郡山 知樹,  猿渡 洋, “<strong>manga2voice: マンガ画像からの音声合成に向けた音声分析</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 1065–1068, Mar. 2020.</li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>リフティングスキームによる離散ウェーブレット変換を導入した深層ニューラルネットに基づく時間領域音源分離</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 325–328, Mar. 2020.</li>
<li><ins>中村 友彦</ins>,  猿渡 洋, “<strong>Haar変換を導入した時間領域深層ニューラルネットに基づく音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, no. 306, EA2019–60, pp. 41–48, Nov. 2019.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムからの逐次位相推定法</strong>,” <em>情報処理学会研究報告</em>, vol. 2016–MUS–111, no. 47, pp. 1–5, May 2016.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による超解像声道スペクトル推定法</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 115, no. 523, SP2015–111, pp. 99–104, Mar. 2016.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムに対する実時間位相推定法</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 933–936, Mar. 2016.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による声道スペクトル推定法の検討</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 393–396, Mar. 2016.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>全極スペクトルモデルと擬似周期信号モデルのウェーブレット変換表現を用いた多重音スペクトログラムの調波時間因子分解</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–107, no. 50, pp. 1–8, May 2015. <span style="color: var(--md-code-hl-function-color)">[2015 Otogaku Symposium Award / 2015年度 音学シンポジウム優秀賞]</span></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>全極スペクトルモデルを用いた調波時間因子分解による多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–106, no. 26, pp. 1–7, Mar. 2015.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–104, no. 11, pp. 1–6, Aug. 2014.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>無矛盾性規準に基づく連続ウェーブレット変換スペクトログラムへの位相推定法と高速化</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, no. 41, pp. 1–6, May 2014. <span style="color: var(--md-code-hl-function-color)">[IPSJ Yamashita SIG Research Award / 情報処理学会 2014年度山下記念研究賞]</span></li>
<li>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>確率的モデル化に基づく移動音源の劣決定ブラインド音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 114, no. 52, pp. 211–216, May 2014.</li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解法に基づく事前情報付き多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, no. 18, pp. 1–6, May 2014.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>連続ウェーブレット変換の高速近似アルゴリズムに基づく振幅スケーログラムへの無矛盾位相付加法の検討</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 933–936, Mar. 2014.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号に含まれる調波音の周波数特性とドラムの音色の転写システム</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 1043–1044, Mar. 2014. <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ / 日本音響学会 第9回学生優秀発表賞]</span></li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解に基づく音楽事前情報付き多重音解析</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 1049–1052, Mar. 2014.</li>
<li>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>DOA-HMMに基づく劣決定ブラインド音源分離</strong>,” <em>日本音響学会2013年秋季研究発表会講演集</em>, pp. 23–26, Sep. 2013.</li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>誤り・任意の弾き直し・弾き飛ばしを含む演奏音響信号への高速な楽譜追跡</strong>,” <em>情報処理学会研究報告</em>, vol. 2013–MUS–99, no. 40, pp. 1–5, May 2013.</li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡</strong>,” <em>情報処理学会 第75回全国大会</em>, vol. 2013, no. 1, pp. 283–284, Mar. 2013. <span style="color: var(--md-code-hl-function-color)">[Student Encouragement Award of IPSJ National Convention / 情報処理学会第75回全国大会 学生奨励賞]</span></li>
<li><ins>中村 友彦</ins>, 水野 優, 鈴木 孝輔, 中村 栄太, 樋口 祐介, 深山 覚,  嵯峨山 茂樹, “<strong>音楽演奏の誤りや反復に頑健な音響入力自動伴奏</strong>,” <em>日本音響学会2012年秋季研究発表会講演集</em>, pp. 931–934, Sep. 2012.</li>
<li>中野 允裕, ルルー ジョナトン, 亀岡 弘和, <ins>中村 友彦</ins>, 小野 順貴,  嵯峨山 茂樹, “<strong>スペクトログラムのベイジアンノンパラメトリックモデリングに基づく音楽信号の解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2011–MUS–91, no. 6, pp. 1–8, Jul. 2011.</li>
</ol>
<h2 id="review-papers">Review Papers / 解説記事<a class="headerlink" href="#review-papers" title="Permanent link">&para;</a></h2>
<ol>
<li>亀岡 弘和, <ins>中村 友彦</ins>,  高宗 典玄, “<strong>音楽音響信号処理技術の最先端</strong>,” <em>電子情報通信学会誌</em>, vol. 98, no. 6, pp. 467–474, Jun. 2015.</li>
</ol>
<!-- ## Preprints / プレプリント
 -->

<h2 id="thesis">Thesis / 学位論文<a class="headerlink" href="#thesis" title="Permanent link">&para;</a></h2>
<ul>
<li>Ph.D Thesis: <ins>Tomohiko Nakamura</ins>, “<strong>Source-filter representation and phase estimation in continuous wavelet transform domain for monaural music audio editing</strong>,” PhD thesis, The University of Tokyo, Mar. 2016. <a href="https://doi.org/10.15083/00073992">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <a href="https://repository.dl.itc.u-tokyo.ac.jp/records/48867#.YK0RbKj7QuU">paper<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Dean’s Award, Graduate School of Information Science and Technology, The University of Tokyo / 東京大学大学院情報理工学系研究科 研究科長賞, IPSJ SIG-MUS Recommended Ph.D. Thesis / 情報処理学会 2015年度研究会推薦博士論文]</span></li>
<li>Master Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Fast Score Following to Acoustic Signal of Musical Performance with Errors, Repeats and Skips,"</strong> the University of Tokyo, Mar. 2013. (in Japanese)
   <span style="color: var(--md-code-hl-function-color)">[IPSJ Certificate of Excellent Master’s Thesis / 情報処理学会第75回全国大会 情報処理学会推奨 修士論文認定]</span></li>
<li>Bachelor Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Local Stability Analysis of Cell-to-Cell Networks with Cyclic Gene Regulatory Networks,"</strong> the University of Tokyo, Mar. 2011. (in Japanese)</li>
</ul>
<h2 id="patents">Patents / 特許<a class="headerlink" href="#patents" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特開2021-033374, 01-Mar-2021.</li>
<li><ins>中村 友彦</ins>, “<strong>学習済みモデル、学習装置、学習方法、及び学習プログラム</strong>,” 特開2021-033395, 01-Mar-2021.</li>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特開2021-026685, 22-Feb-2021.</li>
<li><ins>中村 友彦</ins>, 國松 昇平, 櫻井 利彦,  大西 一徳, “<strong>カメラ配置評価装置、カメラ配置評価方法、及びコンピュータプログラム</strong>,” 特開2021-10070, 28-Jan-2021.</li>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第6773829号, 21-Oct-2020.</li>
<li><ins>中村 友彦</ins>, “<strong>学習装置、学習方法、学習プログラム、及び対象物認識装置</strong>,” 特許第6773825号, 21-Oct-2020.</li>
<li><ins>中村 友彦</ins>, “<strong>データベース統合装置、データベース統合方法、データベース統合プログラム、及びデータ補完装置</strong>,” 特許第6768101号, 14-Oct-2020.</li>
<li><ins>中村 友彦</ins>, 伊藤 忠彦,  島岡 政基, “<strong>証明書管理装置</strong>,” 特許第6647259号, 16-Jan-2020.</li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>声道スペクトル推定装置、声道スペクトル推定方法、及びプログラム</strong>,” 特許第6420781号, 07-Nov-2018.</li>
</ol>
<h2 id="invited-other-talks">Invited &amp; other talks / 招待講演とその他の講演<a class="headerlink" href="#invited-other-talks" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Signal-processing-inspired deep learning,"</strong> IEEE NZ Signal Processing/Information Theory Joint Chapter in co-hosted by the Acoustics Research Centre, University of Auckland, Dec. 2022. <a href="https://drive.google.com/file/d/1BedulHb_T6tcmkkSMTtuY6W9snoYJtB-/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>, <strong>"深層学習を用いた音源分離,"</strong> 日本音響学会第23回サマーセミナー，Sep. 2022. <a href="https://drive.google.com/file/d/18pSP7ZfMiTbHNH_Wm-TMU3rM3eQUSCI4/view">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>, <strong>"ウェーブレット変換と深層学習を融合した音源分離,"</strong> 2022年8月電気/応用音響研究会，Aug. 2022.<strong>（招待講演）</strong> <a href="https://drive.google.com/file/d/1l76KxC64IdY3IeUcTcijPNI7H1FKJ0ny/view">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 464h32v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V288h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm96-112h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V368zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>, <strong>"音楽音響信号に対するウェーブレット変換を用いた音源分離,"</strong> <a href="https://www.keisu.t.u-tokyo.ac.jp/2021/09/13/system_colloquium-202102/">東京大学工学部計数工学科 システム情報談話会</a>，Sep. 2021.</li>
</ol>
<h2 id="awards">Awards / 受賞<a class="headerlink" href="#awards" title="Permanent link">&para;</a></h2>
<h3 id="awards-of-my-papers">Awards of My Papers / 自身の受賞<a class="headerlink" href="#awards-of-my-papers" title="Permanent link">&para;</a></h3>
<ol>
<li>2022/03: The Itakura Prize Innovative Young Researcher Award, ASJ / 第17回日本音響学会・独創研究奨励賞板倉記念</li>
<li>2021/07: 2021 Encouragement Award, Foundation of the Promotion of Engineering Research / 総合研究奨励会 令和2年度総合研究奨励賞</li>
<li>2021/06: 2021 Otogaku Symposium Best Presentation Award / 2021年度 音学シンポジウム優秀発表賞</li>
<li>2016/08: IPSJ SIG-MUS Recommended Ph.D. Thesis / 情報処理学会 2015年度研究会推薦博士論文</li>
<li>2016/03: Dean’s Award of Graduate School of Information Science and Technology, The University of Tokyo / 東京大学 大学院情報理工学系研究科 研究科長賞</li>
<li>2016/03: IPSJ Yamashita SIG Research Award / 情報処理学会 2015年度山下記念研究賞</li>
<li>2015/10: SICE Best Paper Award (Takeda Award) / 計測自動制御学会 論文賞（武田賞）</li>
<li>2015/05: 2015 Otogaku Symposium Award / 2015年度 音学シンポジウム優秀賞</li>
<li>2014/03: Best Student Presentation Award from ASJ / 日本音響学会 第9回学生優秀発表賞</li>
<li>2013/03: IPSJ Certificate of Excellent Master’s Thesis / 情報処理学会第75回全国大会 情報処理学会推奨 修士論文認定</li>
<li>2013/03: Student Encouragement Award of IPSJ National Convention / 情報処理学会第75回全国大会 学生奨励賞</li>
<li>2011/09: SICE Annual Conference 2011 International Award</li>
<li>2011/09: SICE Annual Conference 2011 Finalist of Young Author Award</li>
</ol>
<h3 id="awards-received-by-students-and-collaborators">Awards Received by Students and Collaborators / 共著者・指導学生の受賞<a class="headerlink" href="#awards-received-by-students-and-collaborators" title="Permanent link">&para;</a></h3>
<ol>
<li>2022/12: IEEE Signal Processing Society Japan Student Conference Paper Award (Awardee: Masaya Kawamura) / 第16回 IEEE Signal Processing Society Japan Student Conference Paper Award（受賞者：川村 真也）</li>
<li>2022/11: Best Student Presentation Award from ASJ (Awardee: Kanami Imamura) / 日本音響学会 第25回学生優秀発表賞（受賞者：今村 奏海）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2022/11: Best Student Presentation Award from ASJ (Awardee: Kazuhide Shigemi) / 日本音響学会 第25回学生優秀発表賞（受賞者：重見 和秀）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2022/09: Finalist of Best Student Paper Award of IWAENC 2022 (Yuki Ito)</li>
<li>2022/06: IPSJ Yamashita SIG Research Award (Awardee: Takaaki Saeki) / 情報処理学会2022年度山下記念研究賞（受賞者：佐伯 高明）<a href="https://www.ipsj.or.jp/award/yamashita2022.html">link</a></li>
<li>2022/06: 2022 Otogaku Symposium Best Student Presentation Award (Awardee: Futa Nakashima) / 2022年度 音学シンポジウム学生優秀発表賞（受賞者：中島 風大）<a href="https://www.ipsj.or.jp/award/musslp-award2.html">link</a></li>
<li>2022/03: Dean's Award of Graduate School of Information Science and Technology, The University of Tokyo (Awardee: Takuya Hasumi) / 東京大学 大学院情報理工学系研究科 研究科長賞（受賞者：蓮実 拓也）<a href="https://www.i.u-tokyo.ac.jp/news/files/2021_the_dean%27s_award.pdf">link</a></li>
<li>2021/12: 日本音響学会第24回関西支部若手研究者交流研究発表会 奨励賞（受賞者：渡辺 瑠伊）<a href="https://asj-kansai.acoustics.jp/event/24wakate/">link</a></li>
<li>2021/06: 2021 Otogaku Symposium Best Student Presentation Award (Awardee: Koichi Saito) / 2021年度 音学シンポジウム学生優秀発表賞（受賞者：齋藤 弘一）<a href="https://www.ipsj.or.jp/award/musslp-award2.html">link</a></li>
<li>2021/05: Best Student Presentation Award from ASJ (Awardee: Takuya Hasumi) / 日本音響学会 第22回学生優秀発表賞（受賞者：蓮実 拓也）<a href="https://acoustics.jp/awards/student/">link</a></li>
</ol>
<h2 id="other">Other / その他<a class="headerlink" href="#other" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>中村 友彦</ins>，<strong>"コーヒーブレイク　ちょっとしたエッセイ"</strong>, <em>日本音響学会誌</em>，vol. 78, no. 1, Dec. 25, 2021.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝, 亀岡 弘和, <strong>"音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム,"</strong> <em>OngaCRESTシンポジウム2014-音楽情報処理研究が切り拓く未来を探る-,</em> Aug. 23, 2014.<ul>
<li><a href="http://ongacrest.jp/">OngaCREST</a></li>
<li><a href="http://av.watch.impress.co.jp/docs/series/dal/20140825_663420.html">「人型ロボットのダンス」や「声の年齢制御」など、音楽情報処理の最先端をレポート - 藤本健のDigital Audio Laboratory</a></li>
<li><a href="http://pc.watch.impress.co.jp/docs/column/kyokai/20140827_663740.html">コピー不可能な体験を価値の中核に～音楽情報処理の「OngaCRESTシンポジウム」レポート - 森山和道の「ヒトと機械の境界面」</a></li>
</ul>
</li>
</ol>



  



                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021- Tomohoiko Nakamura
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": ["toc.integrate"], "search": "assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.407015b8.min.js"></script>
      
    
  </body>
</html>