
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Tomohiko Nakamura">
      
      
        <link rel="canonical" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/publications.html">
      
      
        <link rel="prev" href="research.html">
      
      
        <link rel="next" href="datasets.html">
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.33">
    
    
      
        <title>Publications / 発表文献 - Tomohiko Nakamura</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9EPRVMYY0Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9EPRVMYY0Z');
</script>
    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="primary">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#publications" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Tomohiko Nakamura" class="md-header__button md-logo" aria-label="Tomohiko Nakamura" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Tomohiko Nakamura
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Publications / 発表文献
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Tomohiko Nakamura" class="md-nav__button md-logo" aria-label="Tomohiko Nakamura" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Tomohiko Nakamura
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="research.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Research / Demo
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="publications.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Publications
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="datasets.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="lecture.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lecture Notes
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="tips.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tips
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="publications">Publications / 発表文献<a class="headerlink" href="#publications" title="Permanent link">&para;</a></h1>
<p><strong><a href="pdfs/nakamura_CV_short.pdf">Short CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="pdfs/nakamura_CV.pdf">Full CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://scholar.google.com/citations?user=bHny6PAAAAAJ">Google Scholar<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6 31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0l112.3-112.3zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5 50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5l112.2-112.3c31.5-31.5 82.5-31.5 114 0 27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg></span></a>, <a href="https://researchmap.jp/tomohiko_nakamura">Researchmap<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6 31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0l112.3-112.3zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5 50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5l112.2-112.3c31.5-31.5 82.5-31.5 114 0 27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg></span></a>, <a href="https://orcid.org/0000-0003-4385-7170">ORCiD<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6 31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0l112.3-112.3zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5 50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5l112.2-112.3c31.5-31.5 82.5-31.5 114 0 27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg></span></a></strong></p>
<h2 id="journals-peer-reviewed">Journals (Peer-reviewed) / 査読付き論文誌<a class="headerlink" href="#journals-peer-reviewed" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Kanami Imamura, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1561/116.20230082">Neural analog filter for sampling-frequency-independent convolutional layer</a></strong>,” <em>APSIPA Transactions on Signal and Information Processing</em>, vol. 13, no. 1, e28, Nov. 2024.  </p>
</li>
<li>
<p>Takaaki Saeki, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Naoko Tanji, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ACCESS.2023.3345027">SelfRemaster: Self-supervised speech restoration for historical audio resources</a></strong>,” <em>IEEE Access</em>, vol. 11, pp. 144831–144843, Jan. 2024.<br />
<a href="https://takaaki-saeki.github.io/selfremaster_demo_access/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/Takaaki-Saeki/ssl_speech_restoration_v2">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></p>
</li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.1109/TASLP.2023.3293044">PoP-IDLMA: Product-of-prior independent deeply learned matrix analysis for multichannel music source separation</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 31, pp. 2680–2694, Jul. 2023.<br />
<a href="https://drive.google.com/file/d/1-XRE6Ohgd9XIkZl7gbNsCIgKV3u54XV-/view?usp=sharing">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li>Koichi Saito, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/TASLP.2022.3203907">Sampling-frequency-independent convolutional layer and its application to audio source separation</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 30, pp. 2928–2943, Sep. 2022.<br />
<a href="https://drive.google.com/file/d/1Fxnvf-K31NCY0zO0dxyCSNEzgYxXVmCS/view?usp=sharing">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://drive.google.com/file/d/1FsygLBnjhi6aE0lEJ2enQDaqGFpavhus/view?usp=sharing">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="demo/sfi_convtasnet/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/sfi_convtasnet">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Shihori Kozuka, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/TASLP.2021.3072496">Time-domain audio source separation with neural networks based on multiresolution analysis</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 1687–1701, Apr. 2021.<br />
<a href="https://drive.google.com/file/d/10z8dxzKtCf8dAfv-_MYQUWkWGawt3rrI/view?usp=share_link">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://drive.google.com/file/d/106d2i7NYkIdNgYR1NpUgm1xXBoP6TKwX/view?usp=share_link">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="demo/MRDLA/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/dwtls">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[The Itakura Prize Innovative Young Researcher Award / 第17回日本音響学会・独創研究奨励賞板倉記念]</span></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/TASLP.2020.3037487">Harmonic-temporal factor decomposition for unsupervised monaural separation of harmonic sounds</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 68–82, Nov. 2020.<br />
<a href="https://drive.google.com/file/d/1029Dp0LhE5fmIH1xhrDmyXtes4fagX7A/view?usp=share_link">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://drive.google.com/file/d/11-LY9X9ZTnc29Rj-yOII38B-hHk1vMJp/view?usp=share_link">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="demo/HTFD/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/HTFD">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>, <a href="https://docs.google.com/forms/d/e/1FAIpQLSeCPCnbnK2RFxhoKcURxr6yRXeHjM5BgTvO2qaAIDhGAB0brA/viewform?usp=sf_link">dataset <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M448 80v48c0 44.2-100.3 80-224 80S0 172.2 0 128V80C0 35.8 100.3 0 224 0s224 35.8 224 80zm-54.8 134.7c20.8-7.4 39.9-16.9 54.8-28.6V288c0 44.2-100.3 80-224 80S0 332.2 0 288V186.1c14.9 11.8 34 21.2 54.8 28.6C99.7 230.7 159.5 240 224 240s124.3-9.3 169.2-25.3zM0 346.1c14.9 11.8 34 21.2 54.8 28.6C99.7 390.7 159.5 400 224 400s124.3-9.3 169.2-25.3c20.8-7.4 39.9-16.9 54.8-28.6V432c0 44.2-100.3 80-224 80S0 476.2 0 432v-85.9z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong><a href="https://doi.org/10.1109/TASLP.2015.2507862">Real-time audio-to-score alignment of music performances containing errors and arbitrary repeats and skips</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 24, no. 2, pp. 329–339, Feb. 2016.<br />
<a href="https://arxiv.org/abs/1512.07748">arXiv</a>, <a href="demo/automatic_accompaniment/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Yutaka Hori, and Shinji Hara, “<strong><a href="https://doi.org/10.9746/jcmsi.7.133">Hierarchical modeling and local stability analysis for repressilators coupled by quorum sensing</a></strong>,” <em>SICE Journal of Control, Measurement, and System Integration</em>, vol. 7, no. 3, pp. 133–140, May 2014.<br />
 <span style="color: var(--md-code-hl-function-color)">[SICE Best Paper Award (Takeda Award) / 2015年計測自動制御学会 論文賞 (武田賞)]</span></li>
<li>Eita Nakamura, <ins>Tomohiko Nakamura</ins>, Yasuyuki Saito, Nobutaka Ono, and Shigeki Sagayama, “<strong><a href="https://doi.org/10.1080/09298215.2014.884145">Outer-product type hidden Markov model and polyphonic MIDI score following</a></strong>,” <em>Journal of New Music Research</em>, vol. 43, pp. 183–201, Apr. 2014.<br />
<a href="https://arxiv.org/abs/1404.2313">arXiv</a></li>
</ol>
<h2 id="international-conferences-workshops">International Conferences &amp; Workshops / 国際会議<a class="headerlink" href="#international-conferences-workshops" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Yuto Ishikawa, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, and Hiroshi Saruwatari, “<strong>Hearing-aids system using distributed assistive device and blind speech extraction method under diffuse noise</strong>,” in <em>International Congress on Acoustics</em>, May 2025.  </p>
</li>
<li>
<p><ins>Tomohiko Nakamura</ins>, Kwanghee Choi, Keigo Hojo, Yoshiaki Bando, Satoru Fukayama, and Shinji Watanabe, “<strong>Discrete speech unit extraction via independent component analysis</strong>,” in <em>SALMA: Speech and Audio Language Models - Architectures, Data Sources, and Training Paradigms, IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops</em>, Apr. 2025.  </p>
</li>
<li>
<p>Yuto Ishikawa, Osamu Take, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, “<strong>Real-time noise estimation for lombard-effect speech synthesis in human–avatar dialogue systems</strong>,” in <em>Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2024.  </p>
</li>
<li>
<p>Hiroaki Hyodo, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Junya Koguchi, and Hiroshi Saruwatari, “<strong>DNN-based ensemble singing voice synthesis with interactions between singers</strong>,” in <em>IEEE Spoken Language Technology Workshop</em>, Dec. 2024.<br />
<a href="https://arxiv.org/abs/2409.09988">arXiv</a></p>
</li>
<li>Hitoshi Suda, Shunsuke Yoshida, <ins>Tomohiko Nakamura</ins>, Fukayama Satoru, and Jun Ogata, “<strong>FruitsMusic: A real-world corpus of Japanese idol-group songs</strong>,” in <em>International Society for Music Information Retrieval Conference</em>, Nov. 2024.<br />
<a href="https://arxiv.org/abs/2409.12549">arXiv</a>, <a href="https://huggingface.co/datasets/fruits-music/fruits-music">dataset <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M448 80v48c0 44.2-100.3 80-224 80S0 172.2 0 128V80C0 35.8 100.3 0 224 0s224 35.8 224 80zm-54.8 134.7c20.8-7.4 39.9-16.9 54.8-28.6V288c0 44.2-100.3 80-224 80S0 332.2 0 288V186.1c14.9 11.8 34 21.2 54.8 28.6C99.7 230.7 159.5 240 224 240s124.3-9.3 169.2-25.3zM0 346.1c14.9 11.8 34 21.2 54.8 28.6C99.7 390.7 159.5 400 224 400s124.3-9.3 169.2-25.3c20.8-7.4 39.9-16.9 54.8-28.6V432c0 44.2-100.3 80-224 80S0 476.2 0 432v-85.9z"/></svg></span></a></li>
<li>
<p>Yuta Amezawa, <ins>Tomohiko Nakamura</ins>, Satoru Fukayama, Takahiro Shiina, and Takahiko Uchide, “<strong>Automatic extraction and peak arrival estimation of later phase in S coda</strong>,” in <em>International Joint Workshop on Slow-to-Fast Earthquakes 2024</em>, Sep. 2024.  </p>
</li>
<li>
<p>Yuto Ishikawa, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, and Hiroshi Saruwatari, “<strong>Real-time framework for speech extraction based on independent low-rank matrix analysis with spatial regularization and rank-constrained spatial covariance matrix estimation</strong>,” in <em>Workshop on Spoken Dialogue Systems for Cybernetic Avatars (SDS4CA)</em>, Sep. 2024.  </p>
</li>
<li>
<p>Kwanghee Choi, Ankita Pasad, <ins>Tomohiko Nakamura</ins>, Satoru Fukayama, Karen Livescu, and Shinji Watanabe, “<strong><a href="https://doi.org/10.21437/Interspeech.2024-1157">Self-supervised speech representations are more phonetic than semantic</a></strong>,” in <em>INTERSPEECH</em>, Sep. 2024, pp. 4578–4582.<br />
<a href="https://arxiv.org/abs/2406.08619">arXiv</a>, <a href="https://github.com/juice500ml/phonetic_semantic_probing">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></p>
</li>
<li>Yoshiaki Bando, <ins>Tomohiko Nakamura</ins>, and Shinji Watanabe, “<strong><a href="https://doi.org/10.21437/Interspeech.2024-1137">Neural blind source separation and diarization for distant speech recognition</a></strong>,” in <em>INTERSPEECH</em>, Sep. 2024, pp. 722–726.<br />
<a href="https://arxiv.org/abs/2406.08396">arXiv</a>, <a href="https://ybando.jp/projects/neural-fcasa/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/b-sigpro/neural-fcasa">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li>Yuto Ishikawa, Kohei Konaka, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ICASSPW62465.2024.10627448">Real-time speech extraction using spatially regularized independent low-rank matrix analysis and rank-constrained spatial covariance matrix estimation</a></strong>,” in <em>Hands-Free Speech Communication and Microphone Arrays, IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops</em>, Apr. 2024, pp. 730–734.<br />
<a href="https://arxiv.org/abs/2403.12477v1">arXiv</a></li>
<li>Kanami Imamura, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Kohei Yatabe, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.23919/EUSIPCO58844.2023.10289819">Algorithms of sampling-frequency-independent layers for non-integer strides</a></strong>,” in <em>European Signal Processing Conference</em>, Sep. 2023, pp. 326–330.<br />
<a href="https://arxiv.org/abs/2306.10718">arXiv</a></li>
<li>Joonyong Park, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Kentaro Seki, Detai Xin, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.21437/Interspeech.2023-981">How generative spoken language model encodes noisy speech: Investigation from phonetics to syntactics</a></strong>,” in <em>INTERSPEECH</em>, Aug. 2023, pp. 1085–1089.<br />
<a href="https://arxiv.org/abs/2306.00697">arXiv</a></li>
<li><ins>Tomohiko Nakamura</ins>, Shinnosuke Takamichi, Naoko Tanji, Satoru Fukayama, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ICASSP49357.2023.10095569"><span class="nocase">jaCappella corpus: A japanese a cappella vocal ensemble corpus</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Jun. 2023.<br />
<a href="https://arxiv.org/abs/2211.16028">arXiv</a>, <a href="demo/jaCappella_sep">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/TomohikoNakamura/asteroid_jaCappella/tree/jaCappella/egs/jaCappella">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>, <a href="https://tomohikonakamura.github.io/jaCappella_corpus/">dataset <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M448 80v48c0 44.2-100.3 80-224 80S0 172.2 0 128V80C0 35.8 100.3 0 224 0s224 35.8 224 80zm-54.8 134.7c20.8-7.4 39.9-16.9 54.8-28.6V288c0 44.2-100.3 80-224 80S0 332.2 0 288V186.1c14.9 11.8 34 21.2 54.8 28.6C99.7 230.7 159.5 240 224 240s124.3-9.3 169.2-25.3zM0 346.1c14.9 11.8 34 21.2 54.8 28.6C99.7 390.7 159.5 400 224 400s124.3-9.3 169.2-25.3c20.8-7.4 39.9-16.9 54.8-28.6V432c0 44.2-100.3 80-224 80S0 476.2 0 432v-85.9z"/></svg></span></a></li>
<li>Kota Arai, Yutaro Hirao, Takuji Narumi, <ins>Tomohiko Nakamura</ins>, Shinnosuke Takamichi, and Shigeo Yoshida, “<strong><a href="https://doi.org/10.1145/3581641.3584053">TimToShape: Supporting practice of musical instruments by visualizing timbre with 2D shapes based on crossmodal correspondences</a></strong>,” in <em>ACM Conference on Intelligent User Interfaces</em>, Mar. 2023, pp. 850–865.<br />
<a href="https://medium.com/@shigeo.yoshida/musical-instrument-practice-support-system-based-on-crossmodal-correspondences-to-be-presented-at-500a02fd22b0">blog <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M192 32c0 17.7 14.3 32 32 32 123.7 0 224 100.3 224 224 0 17.7 14.3 32 32 32s32-14.3 32-32C512 128.9 383.1 0 224 0c-17.7 0-32 14.3-32 32zm0 96c0 17.7 14.3 32 32 32 70.7 0 128 57.3 128 128 0 17.7 14.3 32 32 32s32-14.3 32-32c0-106-86-192-192-192-17.7 0-32 14.3-32 32zm-96 16c0-26.5-21.5-48-48-48S0 117.5 0 144v224c0 79.5 64.5 144 144 144s144-64.5 144-144-64.5-144-144-144h-16v96h16c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48V144z"/></svg></span></a></li>
<li>Futa Nakashima, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Satoru Fukayama, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.23919/APSIPAASC55919.2022.9980158">Hyperbolic timbre embedding for musical instrument sound synthesis based on variational autoencoders</a></strong>,” in <em>Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Nov. 2022, pp. 736–743.<br />
<a href="https://arxiv.org/abs/2209.13211">arXiv</a></li>
<li>Yuki Ito, <ins>Tomohiko Nakamura</ins>, Shoichi Koyama, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/IWAENC53105.2022.9914751">Head-related transfer function interpolation from spatially sparse measurements using autoencoder with source position conditioning</a></strong>,” in <em>International Workshop on Acoustic Signal Enhancement</em>, Sep. 2022.<br />
<a href="https://arxiv.org/abs/2207.10967">arXiv</a>, <a href="https://github.com/ikets/HRTFInterpAE_public/blob/main/docs/Ito_IWAENC2022_public.pdf">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://ikets.github.io/HRTFInterpAE_public/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/ikets/HRTFInterpAE_public">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Finalist of Best Student Paper Award of IWAENC 2022 (Yuki Ito)]</span></li>
<li>Kazuhide Shigemi, Shoichi Koyama, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/IWAENC53105.2022.9914792">Physics-informed convolutional neural network with bicubic spline interpolation for sound field estimation</a></strong>,” in <em>International Workshop on Acoustic Signal Enhancement</em>, Sep. 2022.<br />
<a href="https://arxiv.org/abs/2207.10937">arXiv</a></li>
<li>Takaaki Saeki, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Naoko Tanji, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.21437/Interspeech.2022-298">SelfRemaster: Self-supervised speech restoration with analysis-by-synthesis approach using channel modeling</a></strong>,” in <em>INTERSPEECH</em>, Sep. 2022, pp. 4406–4410.<br />
<a href="https://arxiv.org/abs/2203.12937">arXiv</a>, <a href="https://takaaki-saeki.github.io/ssl_remaster_demo/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <a href="https://github.com/Takaaki-Saeki/ssl_speech_restoration">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li>
<li>Masaya Kawamura, <ins>Tomohiko Nakamura</ins>, Daichi Kitamura, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.1109/ICASSP43922.2022.9746399">Differentiable digital signal processing mixture model for synthesis parameter extraction from mixture of harmonic sounds</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2022, pp. 941–945.<br />
<a href="https://arxiv.org/abs/2202.00200">arXiv</a>, <a href="https://sarulab-audio.github.io/DDSP_Mixture_Model/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[IEEE Signal Processing Society Japan Student Conference Paper Award (Awardee: Masaya Kawamura) / 第16回 IEEE Signal Processing Society Japan Student Conference Paper Award（受賞者：川村 真也）]</span></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong>Multichannel audio source separation with independent deeply learned matrix analysis using product of source models</strong>,” in <em>Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 1226–1233.<br />
<a href="https://ieeexplore.ieee.org/document/9689636">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://arxiv.org/abs/2109.00704">arXiv</a></li>
<li>Sota Misawa, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, Daichi Kitamura, Hiroshi Saruwatari, Masakazu Une, and Shoji Makino, “<strong>Speech enhancement by noise self-supervised rank-constrained spatial covariance matrix estimation via independent deeply learned matrix analysis</strong>,” in <em>Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 578–584.<br />
<a href="https://ieeexplore.ieee.org/document/9689665/">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://arxiv.org/abs/2109.04658">arXiv</a></li>
<li>Yusaku Mizobuchi, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong>Prior distribution design for music bleeding-sound reduction based on nonnegative matrix factorization</strong>,” in <em>Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 651–658.<br />
<a href="https://ieeexplore.ieee.org/document/9689601/">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="https://arxiv.org/abs/2109.00237">arXiv</a></li>
<li>Koichi Saito, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, Yuma Koizumi, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.23919/EUSIPCO54536.2021.9615941">Sampling-frequency-independent audio source separation using convolution layer based on impulse invariant method</a></strong>,” in <em>European Signal Processing Conference</em>, Aug. 2021, pp. 321–325.<br />
<a href="https://arxiv.org/abs/2105.04079">arXiv</a></li>
<li>Naoki Narisawa, Rintaro Ikeshita, Norihiro Takamune, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Hiroshi Saruwatari, and Tomohiro Nakatani, “<strong><a href="https://doi.org/10.23919/eusipco54536.2021.9616300">Independent deeply learned tensor analysis for determined audio source separation</a></strong>,” in <em>European Signal Processing Conference</em>, Aug. 2021, pp. 326–330.<br />
<a href="https://arxiv.org/abs/2106.05529">arXiv</a></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.23919/eusipco54536.2021.9616245">Empirical bayesian independent deeply learned matrix analysis for multichannel audio source separation</a></strong>,” in <em>European Signal Processing Conference</em>, Aug. 2021, pp. 331–335.<br />
<a href="https://arxiv.org/abs/2106.03492">arXiv</a></li>
<li>Shihori Kozuka, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong>Investigation on wavelet basis function of DNN-based time domain audio source separation inspired by multiresolution analysis</strong>,” in <em>International Congress and Exposition on Noise Control Engineering</em>, Aug. 2020, pp. 4013–4022.<br />
<a href="https://www.ingentaconnect.com/contentone/ince/incecp/2020/00000261/00000002/art00004">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins> and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ICASSP40776.2020.9053934">Time-domain audio source separation based on Wave-U-Net combined with discrete wavelet transform</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2020, pp. 386–390.<br />
<a href="https://arxiv.org/abs/2001.10190">arXiv</a></li>
<li>
<p><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/ICASSP.2016.7471723">Shifted and convolutive source-filter non-negative matrix factorization for monaural audio source separation</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Mar. 2016, pp. 489–493.  </p>
</li>
<li>
<p><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/ICASSP.2015.7178344">Lp-norm non-negative matrix factorization and its application to singing voice enhancement</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Apr. 2015, pp. 2115–2119.  </p>
</li>
<li>
<p><ins>Tomohiko Nakamura</ins>, Kotaro Shikata, Norihiro Takamune, and Hirokazu Kameoka, “<strong>Harmonic-temporal factor decomposition incorporating music prior information for informed monaural source separation</strong>,” in <em>International Society for Music Information Retrieval Conference</em>, Oct. 2014, pp. 623–628.<br />
<a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T112_135_Paper.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="demo/HTFD">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Tateishi Science and Technology Foundation]</span></p>
</li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Fast signal reconstruction from magnitude spectrogram of continuous wavelet transform based on spectrogram consistency</strong>,” in <em>International Conference on Digital Audio Effects</em>, Sep. 2014, pp. 129–135.<br />
<a href="http://www.dafx14.fau.de/papers/dafx14_tomohiko_nakamura_fast_signal_reconstructio.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="demo/fastCWT/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Hara Research Foundation]</span></li>
<li>Takuya Higuchi, Hirofumi Takeda, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>A unified approach for underdetermined blind signal separation and source activity detection by multichannel factorial hidden Markov models</strong>,” in <em>INTERSPEECH</em>, Sep. 2014, pp. 850–854.<br />
<a href="https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0850.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Hirokazu Kameoka, Kazuyoshi Yoshii, and Masataka Goto, “<strong><a href="https://doi.org/10.1109/ICASSP.2014.6855052">Timbre replacement of harmonic and drum components for music audio signals</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2014, pp. 7520–7524.<br />
<a href="demo/drum_timbre_replacement/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a></li>
<li>
<p>Takuya Higuchi, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/ICASSP.2014.6854189">Underdetermined blind separation and tracking of moving sources based on DOA-HMM</a></strong>,” in <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2014, pp. 3215–3219.  </p>
</li>
<li>
<p>Shigeki Sagayama, <ins>Tomohiko Nakamura</ins>, Eita Nakamura, Yasuyuki Saito, Hirokazu Kameoka, and Nobutaka Ono, “<strong><a href="https://doi.org/10.1121/1.4877848">Automatic music accompaniment allowing errors and arbitrary repeats and jumps</a></strong>,” in <em>Meetings on Acoustics, Acoustic Society of America</em>, May 2014, vol. 21, 35003.  </p>
</li>
<li>
<p><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Acoustic score following to musical performance with errors and arbitrary repeats and skips for automatic accompaniment</strong>,” in <em>Sound and Music Computing Conference</em>, Aug. 2013, pp. 299–304.<br />
<a href="http://smcnetwork.org/node/1754">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <a href="demo/automatic_accompaniment">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M499.1 6.3c8.1 6 12.9 15.6 12.9 25.7v336c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V147l-256 76.8V432c0 44.2-43 80-96 80S0 476.2 0 432s43-80 96-80c11.2 0 22 1.6 32 4.6V128c0-14.1 9.3-26.6 22.8-30.7l320-96c9.7-2.9 20.2-1.1 28.3 5z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Telecommunications Advancement Foundation]</span></p>
</li>
<li>
<p>Masahiro Nakano, Jonathan Le Roux, Hirokazu Kameoka, <ins>Tomohiko Nakamura</ins>, Nobutaka Ono, and Shigeki Sagayama, “<strong><a href="https://doi.org/10.1109/ASPAA.2011.6082324">Bayesian nonparametric spectrogram modeling based on infinite factorial infinite hidden Markov model</a></strong>,” in <em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, Oct. 2011, pp. 325–328.  </p>
</li>
<li>
<p><ins>Tomohiko Nakamura</ins>, Shinji Hara, and Yutaka Hori, “<strong>Local stability analysis for a class of quorum-sensing networks with cyclic gene regulatory networks</strong>,” in <em>SICE Annual Conference</em>, Sep. 2011, pp. 2111–2116.<br />
<a href="https://ieeexplore.ieee.org/document/6060320">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[SICE Annual Conference 2011 International Award and Finalist of Young Author's Award]</span></p>
</li>
</ol>
<h2 id="domestic-conferences">Domestic Conferences / 国内会議<a class="headerlink" href="#domestic-conferences" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>瀧澤 大吾, <ins>中村 友彦</ins>, 須田 仁志,  深山 覚, “<strong>大規模自己教師あり学習モデルによる日本語方言の音声認識</strong>,” <em>日本音響学会 2025年春期研究発表会</em>, Mar. 2025.  </p>
</li>
<li>
<p>内田 蓮, 矢田部 浩平,  <ins>中村 友彦</ins>, “<strong>直交畳み込み層によるConv-TasNetの完全再構成性の保証</strong>,” <em>日本音響学会 2025年春期研究発表会</em>, Mar. 2025.  </p>
</li>
<li>
<p>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>Local equivariance errorに基づくサンプリング周波数非依存性評価指標の検討</strong>,” <em>日本音響学会 2024年秋期研究発表会</em>, pp. 241–244, Sep. 2024.  </p>
</li>
<li>
<p>石川 悠人, 武 伯寒, <ins>中村 友彦</ins>, 高宗 典玄, 齋藤 佑樹, 高道 慎之介,  猿渡 洋, “<strong>人間とアバターとの対話システムにおける拡散性雑音下リアルタイム推定雑音を用いたLombard効果模擬音声合成のための検討</strong>,” <em>日本音響学会 2024年秋期研究発表会</em>, pp. 141–144, Sep. 2024.  </p>
</li>
<li>
<p>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>非整数ストライド処理アルゴリズムを用いたサンプリング周波数非依存畳み込み層による楽音分離の実験的評価</strong>,” <em>情報処理学会研究報告</em>, vol. 2024–MUS–140, May 2024.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, “<strong>サンプリング周波数に非依存な深層学習を用いた音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 124, pp. 7–13, May 2024.  </p>
</li>
<li>
<p>須田 仁志, <ins>中村 友彦</ins>, 深山 覚,  緒方 淳, “<strong>FruitsMusic: 音楽情報処理のためのアイドルユニット楽曲コーパス</strong>,” <em>情報処理学会研究報告</em>, vol. 2024–MUS–139, Mar. 2024.  </p>
</li>
<li>
<p>兵藤 弘明, 高道 慎之介, <ins>中村 友彦</ins>, 小口 純矢,  猿渡 洋, “<strong>歌唱者間相互作用を再現するDNN重唱歌声合成の検討</strong>,” <em>情報処理学会研究報告</em>, vol. 2024–MUS–139, Mar. 2024.<br />
 <span style="color: var(--md-code-hl-function-color)">[情報処理学会 第139回音楽情報科学研究会 学生奨励賞 Best Research部門（受賞者：兵藤 弘明）]</span></p>
</li>
<li>
<p>王 檬, 赤石 夏輝, <ins>中村 友彦</ins>, 山田 宏樹,  矢田部 浩平, “<strong>コンプレッサー処理された信号の復元に関する検討</strong>,” <em>日本音響学会 2024年春期研究発表会</em>, pp. 205–206, Mar. 2024.  </p>
</li>
<li>
<p>石川 悠人, 大久保 拓哉, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>独立低ランク行列分析における反復射影法の高速化・安定化アルゴリズム</strong>,” <em>日本音響学会 2024年春期研究発表会</em>, pp. 87–90, Mar. 2024.<br />
 <span style="color: var(--md-code-hl-function-color)">[日本音響学会 第28回学生優秀発表賞（受賞者：石川 悠人）]</span></p>
</li>
<li>
<p>石川 悠人, 大久保 拓哉, 高宗 典玄, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>空間正則化付き独立低ランク行列分析におけるベクトルワイズ座標降下法の高速化・安定化アルゴリズム</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 123, pp. 43–50, Feb. 2024.  </p>
</li>
<li>
<p>石川 悠人, 小中 康平, <ins>中村 友彦</ins>, 高宗 典玄,  猿渡 洋, “<strong>目的音声の方位を用いた空間正則化付き独立低ランク行列分析とランク制約付き空間共分散行列推定法による拡散性雑音下リアルタイム音声強調</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 137–140, Sep. 2023.  </p>
</li>
<li>
<p>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存畳み込み層における非整数ストライド処理アルゴリズム</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 157–160, Sep. 2023.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  矢田部 浩平, “<strong>Universal Sound Separationへのサンプリング周波数非依存畳み込み層の適用</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 161–164, Sep. 2023.<br />
 <span style="color: var(--md-code-hl-function-color)">[The Awaya Kiyoshi Research Award from ASJ / 日本音響学会 粟屋潔学術奨励賞]</span></p>
</li>
<li>
<p>王 檬, <ins>中村 友彦</ins>, 山田 宏樹,  矢田部 浩平, “<strong>微分可能なコンプレッサーのパラメータ推定に関する検討</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 259–260, Sep. 2023.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 高道 慎之介, 丹治 尚子, 深山 覚,  猿渡 洋, “<strong>jaCappellaコーパスv2：重唱分離・合成のための日本語アカペラ歌唱コーパスの拡張</strong>,” <em>情報処理学会研究報告</em>, vol. 2023–MUS–138, Aug. 2023.  </p>
</li>
<li>
<p>朴 浚鎔, 高道 慎之介, <ins>中村 友彦</ins>, 関 健太郎, 辛 徳泰,  猿渡 洋, “<strong>Generative spoken language Modelを用いた劣化雑音音声の分析と他言語への適用</strong>,” <em>日本音響学会 2023年春期研究発表会</em>, pp. 677–680, Mar. 2023.  </p>
</li>
<li>
<p>三村 正人, 井上 昂治, 河原 達也, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>実環境下日本語話し言葉音声コーパスの構築と音声認識ベンチマーク</strong>,” <em>情報処理学会研究報告</em>, vol. 2023–SLP–146, pp. 1–6, Feb. 2023.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 高道 慎之介, 丹治 尚子, 深山 覚,  猿渡 洋, “<strong>jaCappellaコーパス:重唱分離・合成に向けた日本語アカペラ歌唱コーパス</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 1377–1378, Sep. 2022.  </p>
</li>
<li>
<p>溝渕 悠朔, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>時間チャネル非負値行列因子分解を用いた被り音抑圧における初期値頑健性の比較</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 351–354, Sep. 2022.  </p>
</li>
<li>
<p>川村 真也, <ins>中村 友彦</ins>, 高宗 典玄, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>混合Differentiable digital signal Processingモデルによる合成パラメータ抽出のためのラウドネスの時間変動に基づくロス関数の設計</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 183–186, Sep. 2022.  </p>
</li>
<li>
<p>伊藤 悠貴, <ins>中村 友彦</ins>, 小山 翔一,  猿渡 洋, “<strong>音源位置で条件付けた自己符号化器を用いた少数測定データからの頭部伝達関数補間</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 501–504, Sep. 2022.  </p>
</li>
<li>
<p>今村 奏海, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存畳み込み層のための時間領域ニューラルアナログフィルタ</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 187–190, Sep. 2022.<br />
 <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Kanami Imamura) / 日本音響学会 第25回学生優秀発表賞（受賞者：今村 奏海）]</span></p>
</li>
<li>重見 和秀, 小山 翔一, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>スプライン補間に基づく音場表現を用いたPhysics-informed neural Networksによる音場推定 －散乱体を含む領域に関する検証－</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 239–242, Sep. 2022.<br />
 <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Kazuhide Shigemi) / 日本音響学会 第25回学生優秀発表賞（受賞者：重見 和秀）]</span></li>
<li>
<p>中島 風太, <ins>中村 友彦</ins>, 高宗 典玄, 深山 覚,  猿渡 洋, “<strong>楽音合成のためのGauss混合変分自己符号化器への定曲率非Euclid空間の導入と実験的比較</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 327–330, Sep. 2022.  </p>
</li>
<li>
<p>中島 風大, <ins>中村 友彦</ins>, 高宗 典玄, 深山 覚,  猿渡 洋, “<strong>双曲空間への音色埋め込みを用いたガウス混合変分自己符号化器による楽音合成の検討</strong>,” <em>情報処理学会研究報告</em>, vol. 2022–MUS–134, no. 62, Jun. 2022.<br />
 <span style="color: var(--md-code-hl-function-color)">[2022 Otogaku Symposium Best Student Presentation Award (Awardee: Futa Nakashima) / 2022年度 音学シンポジウム学生優秀発表賞（受賞者：中島 風大）]</span></p>
</li>
<li>佐伯 高明, 高道 慎之介, <ins>中村 友彦</ins>, 丹治 尚子,  猿渡 洋, “<strong>ソース・フィルタ・チャネル分解に基づく自己教師ありニューラル音声復元</strong>,” <em>情報処理学会研究報告</em>, vol. 2022–SLP–140, no. 41, Mar. 2022.<br />
 <span style="color: var(--md-code-hl-function-color)">[IPSJ Yamashita SIG Research Award (Awardee: Takaaki Saeki) / 情報処理学会 2022年度山下記念研究賞（受賞者：佐伯 高明）]</span></li>
<li>
<p>伊藤 悠貴, <ins>中村 友彦</ins>, 小山 翔一,  猿渡 洋, “<strong>球波動関数展開を用いた深層学習による少数測定データからの頭部伝達関数補間</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 121, pp. 163–170, Mar. 2022.  </p>
</li>
<li>
<p>重見 和秀, 小山 翔一, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>差分近似型Helmholtz方程式に基づく損失関数を用いた深層学習による少数観測点からの音場推定</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 121, pp. 132–139, Mar. 2022.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>ニューラルアナログフィルタを用いたサンプリング周波数非依存畳み込み層とモノラル音源分離への適用</strong>,” <em>日本音響学会 2022年春期研究発表会</em>, pp. 181–184, Mar. 2022.  </p>
</li>
<li>
<p>川村 真也, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>混合Differentiable DSP モデルによる混合楽器音からの合成パラメータ抽出の実験的評価</strong>,” <em>日本音響学会 2022年春期研究発表会</em>, pp. 177–180, Mar. 2022.  </p>
</li>
<li>
<p>渡辺 瑠伊, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>深層学習に基づく周波数帯域予測による高速音源分離法の実験的評価</strong>,” <em>第24回 日本音響学会関西支部 若手研究者交流研究発表会</em>, p. 15, Dec. 2021.<br />
 <span style="color: var(--md-code-hl-function-color)">[日本音響学会 第24回関西支部若手研究者交流研究発表会 奨励賞（受賞者：渡辺 瑠伊）]</span></p>
</li>
<li>
<p>溝渕 悠朔, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>非負値行列因子分解を用いた被り音の抑圧</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–132, no. 24, Sep. 2021.  </p>
</li>
<li>
<p>川村 真也, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>楽譜情報を援用した音楽音響信号に対する混合Differentiable DSPモデルの合成パラメータ推定</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–132, no. 22, Sep. 2021.  </p>
</li>
<li>
<p>渡辺 瑠伊, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>深層学習に基づく間引きインジケータ付き周波数帯域補間手法による音源分離処理の高速化</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 155–158, Sep. 2021.  </p>
</li>
<li>
<p>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存音源分離モデルを用いた楽音分離の実験的評価</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 159–162, Sep. 2021.  </p>
</li>
<li>
<p>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>Product of Priors型確率分布を導入した音源モデルに基づく独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 163–166, Sep. 2021.  </p>
</li>
<li>
<p>三澤 颯大, <ins>中村 友彦</ins>, 高宗 典玄, 北村 大地,  猿渡 洋, “<strong>独立深層学習行列分析を用いたランク制約付き空間共分散行列推定による音声強調</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 279–280, Sep. 2021.  </p>
</li>
<li>
<p>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>ヘビーテイル生成モデルに基づく独立深層学習テンソル分析</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 301–304, Sep. 2021.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  猿渡 洋, “<strong>多重解像度深層分析を用いた楽音分離の実験的評価</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 13, pp. 1–11, Jun. 2021.<br />
<a href="https://drive.google.com/file/d/10KWyhVU9EziBKk1Il5f6HWZD0azVOb4p/view?usp=share_link">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[2021 Otogaku Symposium Best Presentation Award / 2021年度 音学シンポジウム優秀発表賞]</span></p>
</li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>周波数領域でのフィルタ設計に基づくサンプリング周波数非依存畳み込み層を用いたDNN音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 21, pp. 1–6, Jun. 2021.<br />
 <span style="color: var(--md-code-hl-function-color)">[2021 Otogaku Symposium Best Student Presentation Award (Awardee: Koichi Saito) / 2021年度 音学シンポジウム学生優秀発表賞（受賞者：齋藤 弘一）]</span></li>
<li>
<p>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>非負値行列因子分解を導入したproduct of experts型音源モデルに基づく独立深層学習行列分析による多チャネル音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 37, pp. 1–8, Jun. 2021.  </p>
</li>
<li>
<p>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>アンチエイリアシング機構を導入したサンプリング周波数非依存畳み込み層を用いた音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–130, pp. 1–6, Mar. 2021.  </p>
</li>
<li>
<p>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>潜在アナログフィルタ表現に基づく畳み込み層を用いたサンプリング周波数非依存なDNN音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 125–128, Mar. 2021.  </p>
</li>
<li>
<p>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>経験ベイズ独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 217–220, Mar. 2021.<br />
 <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Takuya Hasumi) / 日本音響学会 第22回学生優秀発表賞（受賞者：蓮実 拓也）]</span></p>
</li>
<li>
<p>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>独立深層学習テンソル分析に基づく多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 117–120, Mar. 2021.  </p>
</li>
<li>
<p>成澤 直輝, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>音源分離のための周波数間相関を考慮した多変量複素Gauss分布に基づく深層学習による分散共分散行列推定の検討</strong>,” <em>日本音響学会 2020年秋季研究発表会講演論文集</em>, pp. 315–318, Sep. 2020.  </p>
</li>
<li>
<p>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>ニューラルネットワークとウェーブレット基底関数の同時学習に基づく多重解像度深層分析を用いた時間領域音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, no. 439, pp. 279–284, Mar. 2020.  </p>
</li>
<li>
<p>高道 慎之介, 齋藤 佑樹, <ins>中村 友彦</ins>, 郡山 知樹,  猿渡 洋, “<strong>manga2voice: マンガ画像からの音声合成に向けた音声分析</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 1065–1068, Mar. 2020.  </p>
</li>
<li>
<p>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>リフティングスキームによる離散ウェーブレット変換を導入した深層ニューラルネットに基づく時間領域音源分離</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 325–328, Mar. 2020.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  猿渡 洋, “<strong>Haar変換を導入した時間領域深層ニューラルネットに基づく音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, no. 306, EA2019–60, pp. 41–48, Nov. 2019.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムからの逐次位相推定法</strong>,” <em>情報処理学会研究報告</em>, vol. 2016–MUS–111, no. 47, pp. 1–5, May 2016.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による超解像声道スペクトル推定法</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 115, no. 523, SP2015–111, pp. 99–104, Mar. 2016.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムに対する実時間位相推定法</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 933–936, Mar. 2016.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による声道スペクトル推定法の検討</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 393–396, Mar. 2016.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>全極スペクトルモデルと擬似周期信号モデルのウェーブレット変換表現を用いた多重音スペクトログラムの調波時間因子分解</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–107, no. 50, pp. 1–8, May 2015.<br />
 <span style="color: var(--md-code-hl-function-color)">[2015 Otogaku Symposium Award / 2015年度 音学シンポジウム優秀賞]</span></p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>全極スペクトルモデルを用いた調波時間因子分解による多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–106, no. 26, pp. 1–7, Mar. 2015.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–104, no. 11, pp. 1–6, Aug. 2014.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>無矛盾性規準に基づく連続ウェーブレット変換スペクトログラムへの位相推定法と高速化</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, no. 41, pp. 1–6, May 2014.<br />
 <span style="color: var(--md-code-hl-function-color)">[IPSJ Yamashita SIG Research Award / 情報処理学会 2014年度山下記念研究賞]</span></p>
</li>
<li>
<p>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>確率的モデル化に基づく移動音源の劣決定ブラインド音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 114, no. 52, pp. 211–216, May 2014.  </p>
</li>
<li>
<p>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解法に基づく事前情報付き多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, no. 18, pp. 1–6, May 2014.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>連続ウェーブレット変換の高速近似アルゴリズムに基づく振幅スケーログラムへの無矛盾位相付加法の検討</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 933–936, Mar. 2014.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号に含まれる調波音の周波数特性とドラムの音色の転写システム</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 1043–1044, Mar. 2014.<br />
 <span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ / 日本音響学会 第9回学生優秀発表賞]</span></p>
</li>
<li>
<p>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解に基づく音楽事前情報付き多重音解析</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 1049–1052, Mar. 2014.  </p>
</li>
<li>
<p>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>DOA-HMMに基づく劣決定ブラインド音源分離</strong>,” <em>日本音響学会2013年秋季研究発表会講演集</em>, pp. 23–26, Sep. 2013.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>誤り・任意の弾き直し・弾き飛ばしを含む演奏音響信号への高速な楽譜追跡</strong>,” <em>情報処理学会研究報告</em>, vol. 2013–MUS–99, no. 40, pp. 1–5, May 2013.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡</strong>,” <em>情報処理学会 第75回全国大会</em>, vol. 2013, no. 1, pp. 283–284, Mar. 2013.<br />
 <span style="color: var(--md-code-hl-function-color)">[Student Encouragement Award of IPSJ National Convention / 情報処理学会第75回全国大会 学生奨励賞]</span></p>
</li>
<li>
<p><ins>中村 友彦</ins>, 水野 優, 鈴木 孝輔, 中村 栄太, 樋口 祐介, 深山 覚,  嵯峨山 茂樹, “<strong>音楽演奏の誤りや反復に頑健な音響入力自動伴奏</strong>,” <em>日本音響学会2012年秋季研究発表会講演集</em>, pp. 931–934, Sep. 2012.  </p>
</li>
<li>
<p>中野 允裕, ルルー ジョナトン, 亀岡 弘和, <ins>中村 友彦</ins>, 小野 順貴,  嵯峨山 茂樹, “<strong>スペクトログラムのベイジアンノンパラメトリックモデリングに基づく音楽信号の解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2011–MUS–91, no. 6, pp. 1–8, Jul. 2011.  </p>
</li>
</ol>
<h2 id="review-papers">Review Papers / 解説記事<a class="headerlink" href="#review-papers" title="Permanent link">&para;</a></h2>
<ol>
<li>Shoichi Koyama, Juliano Ribeiro, <ins>Tomohiko Nakamura</ins>, Natsuki Ueno, and Mirco Pezzoli, “<strong><a href="https://doi.org/10.1109/MSP.2024.3465896">Physics-informed machine learning for sound field estimation</a></strong>,” <em>Special Issue on Model-Based and Data-Driven Audio Signal Processing, IEEE Signal Processing Magazine</em>, vol. 41, pp. 60–71, Nov. 2024.<br />
<a href="https://arxiv.org/abs/2408.14731">arXiv</a></li>
<li>亀岡 弘和, <ins>中村 友彦</ins>,  高宗 典玄, “<strong>音楽音響信号処理技術の最先端</strong>,” <em>電子情報通信学会誌</em>, vol. 98, no. 6, pp. 467–474, Jun. 2015.<br />
<a href="https://www.journal.ieice.org/summary.php?id=k98_6_467">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
</ol>
<h2 id="thesis">Thesis / 学位論文<a class="headerlink" href="#thesis" title="Permanent link">&para;</a></h2>
<ul>
<li>Ph.D Thesis: <ins>Tomohiko Nakamura</ins>, “<strong><a href="https://doi.org/10.15083/00073992">Source-filter representation and phase estimation in continuous wavelet transform domain for monaural music audio editing</a></strong>,” PhD thesis, The University of Tokyo, Mar. 2016.<br />
<a href="https://repository.dl.itc.u-tokyo.ac.jp/records/48867#.YK0RbKj7QuU">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a>, <span style="color: var(--md-code-hl-function-color)">[Dean’s Award, Graduate School of Information Science and Technology, The University of Tokyo / 東京大学大学院情報理工学系研究科 研究科長賞, IPSJ SIG-MUS Recommended Ph.D. Thesis / 情報処理学会 2015年度研究会推薦博士論文]</span></li>
<li>Master Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Fast Score Following to Acoustic Signal of Musical Performance with Errors, Repeats and Skips,"</strong> the University of Tokyo, Mar. 2013. (in Japanese)
   <span style="color: var(--md-code-hl-function-color)">[IPSJ Certificate of Excellent Master’s Thesis / 情報処理学会第75回全国大会 情報処理学会推奨 修士論文認定]</span></li>
<li>Bachelor Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Local Stability Analysis of Cell-to-Cell Networks with Cyclic Gene Regulatory Networks,"</strong> the University of Tokyo, Mar. 2011. (in Japanese)</li>
</ul>
<h2 id="patents">Patents / 特許<a class="headerlink" href="#patents" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第7349288号, 13-Sep-2023.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第7349290号, 13-Sep-2023.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, “<strong>学習済みモデル、学習装置、学習方法、及び学習プログラム</strong>,” 特許第7304235号, 28-Jun-2023.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 國松 昇平, 櫻井 利彦,  大西 一徳, “<strong>カメラ配置評価装置、カメラ配置評価方法、及びコンピュータプログラム</strong>,” 特許第7291013号, 06-Jun-2023.  </p>
</li>
<li>
<p>池下 林太郎, 中谷 智広, 成澤 直輝, 高宗 典玄, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>信号処理装置、信号処理方法、およびプログラム</strong>,” 特開2023-089431, 16-Dec-2021.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第6773829号, 05-Oct-2020.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, “<strong>学習装置、学習方法、学習プログラム、及び対象物認識装置</strong>,” 特許第6773825号, 05-Oct-2020.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, “<strong>データベース統合装置、データベース統合方法、データベース統合プログラム、及びデータ補完装置</strong>,” 特許第6768101号, 24-Sep-2020.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>, 伊藤 忠彦,  島岡 政基, “<strong>証明書管理装置</strong>,” 特許第6647259号, 16-Jan-2020.  </p>
</li>
<li>
<p><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>声道スペクトル推定装置、声道スペクトル推定方法、及びプログラム</strong>,” 特許第6420781号, 19-Oct-2018.  </p>
</li>
</ol>
<h2 id="invited-and-visiting-talks">Invited and visiting talks<a class="headerlink" href="#invited-and-visiting-talks" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Sampling-Frequency-Independent Deep Learning for Audio Source Separation,"</strong> Talk at Behavioral-Informatics &amp; Interaction-Computation Lab. in National Tsing Hua University, May 2024.<br />
<a href="https://drive.google.com/file/d/15eN9k_nbRrRUQzYuzirQZpz2r8R__wau/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Toward Music Source Separation for Mixtures of Homogeneous Sources,"</strong> Talk at Music and AI Lab. in National Taiwan University, May 2024.<br />
<a href="https://drive.google.com/file/d/1kuVEw41NhPMWOexkPOxPunDqA0RInTLu/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li>北村 大地, <ins>中村 友彦</ins>, <strong>"音源分離技術の基礎と応用～音源分離チョットワカルになるための手引き～,"</strong> 音学シンポジウム2023, Jun. 2023.<br />
<a href="https://www.docswell.com/s/d-kitamura/ZQ898R-20230624">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Signal-processing-inspired deep learning,"</strong> IEEE NZ Signal Processing/Information Theory Joint Chapter in co-hosted by the Acoustics Research Centre, University of Auckland, Dec. 2022.<br />
<a href="https://drive.google.com/file/d/10SM7U5pkgT5Ae3LDUA6Cr1Zlc2gKbsqQ/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>, <strong>"ウェーブレット変換と深層学習を融合した音源分離,"</strong> 2022年8月電気/応用音響研究会，Aug. 2022.<br />
<a href="https://drive.google.com/file/d/10XuYFUOJmDTWdJ0LDI2bgFV74x11sTOo/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
</ol>
<h2 id="tutorials">Tutorials / 講習会<a class="headerlink" href="#tutorials" title="Permanent link">&para;</a></h2>
<ol>
<li>猿渡 洋，<ins>中村 友彦</ins>, <strong>"音源分離の基礎と最新動向,"</strong>, <a href="http://www.sap.ist.i.kyoto-u.ac.jp/seminar/onsei2308.html">音声認識・対話技術講習会</a>, Aug. 2023.</li>
</ol>
<h2 id="awards">Awards / 受賞<a class="headerlink" href="#awards" title="Permanent link">&para;</a></h2>
<h3 id="awards-of-my-papers">Awards of My Papers / 自身の受賞<a class="headerlink" href="#awards-of-my-papers" title="Permanent link">&para;</a></h3>
<ol>
<li>2024/03: The Awaya Kiyoshi Research Award, ASJ / 第55回 日本音響学会 粟屋潔学術奨励賞</li>
<li>2022/03: The Itakura Prize Innovative Young Researcher Award, ASJ / 第17回 日本音響学会 独創研究奨励賞板倉記念</li>
<li>2021/07: 2021 Encouragement Award, Foundation of the Promotion of Engineering Research / 総合研究奨励会 令和2年度総合研究奨励賞</li>
<li>2021/06: 2021 Otogaku Symposium Best Presentation Award / 2021年度 音学シンポジウム優秀発表賞</li>
<li>2016/08: IPSJ SIG-MUS Recommended Ph.D. Thesis / 情報処理学会 2015年度研究会推薦博士論文</li>
<li>2016/03: Dean’s Award of Graduate School of Information Science and Technology, The University of Tokyo / 東京大学 大学院情報理工学系研究科 研究科長賞</li>
<li>2016/03: IPSJ Yamashita SIG Research Award / 情報処理学会 2015年度山下記念研究賞</li>
<li>2015/10: SICE Best Paper Award (Takeda Award) / 計測自動制御学会 論文賞（武田賞）</li>
<li>2015/05: 2015 Otogaku Symposium Award / 2015年度 音学シンポジウム優秀賞</li>
<li>2014/03: Best Student Presentation Award from ASJ / 日本音響学会 第9回学生優秀発表賞</li>
<li>2013/03: IPSJ Certificate of Excellent Master’s Thesis / 情報処理学会第75回全国大会 情報処理学会推奨 修士論文認定</li>
<li>2013/03: Student Encouragement Award of IPSJ National Convention / 情報処理学会第75回全国大会 学生奨励賞</li>
<li>2011/09: SICE Annual Conference 2011 International Award</li>
<li>2011/09: SICE Annual Conference 2011 Finalist of Young Author Award</li>
</ol>
<h3 id="awards-received-by-students-and-collaborators">Awards Received by Students and Collaborators / 共著者・指導学生の受賞<a class="headerlink" href="#awards-received-by-students-and-collaborators" title="Permanent link">&para;</a></h3>
<ol>
<li>2024/09: Best Student Presentation Award from ASJ (Awardee: Yuto Ishikawa) / 日本音響学会 第28回学生優秀発表賞（受賞者：石川 悠人）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2024/03: 情報処理学会 第139回音楽情報科学研究会 学生奨励賞 Best Research部門（受賞者：兵藤 弘明）<a href="https://www.ipsj.or.jp/award/mus-award3.html">link</a></li>
<li>2023/07: IPSJ Yamashita SIG Research Award (Awardee: Masato Mimura) / 情報処理学会2022年度山下記念研究賞（受賞者：三村 正人）<a href="https://www.ipsj.or.jp/award/yamashita2023.html">link</a></li>
<li>2022/12: IEEE Signal Processing Society Japan Student Conference Paper Award (Awardee: Masaya Kawamura) / 第16回 IEEE Signal Processing Society Japan Student Conference Paper Award（受賞者：川村 真也）</li>
<li>2022/11: Best Student Presentation Award from ASJ (Awardee: Kanami Imamura) / 日本音響学会 第25回学生優秀発表賞（受賞者：今村 奏海）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2022/11: Best Student Presentation Award from ASJ (Awardee: Kazuhide Shigemi) / 日本音響学会 第25回学生優秀発表賞（受賞者：重見 和秀）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2022/09: Finalist of Best Student Paper Award of IWAENC 2022 (Yuki Ito)</li>
<li>2022/06: IPSJ Yamashita SIG Research Award (Awardee: Takaaki Saeki) / 情報処理学会2022年度山下記念研究賞（受賞者：佐伯 高明）<a href="https://www.ipsj.or.jp/award/yamashita2022.html">link</a></li>
<li>2022/06: 2022 Otogaku Symposium Best Student Presentation Award (Awardee: Futa Nakashima) / 2022年度 音学シンポジウム学生優秀発表賞（受賞者：中島 風大）<a href="https://www.ipsj.or.jp/award/musslp-award2.html">link</a></li>
<li>2022/03: Dean's Award of Graduate School of Information Science and Technology, The University of Tokyo (Awardee: Takuya Hasumi) / 東京大学 大学院情報理工学系研究科 研究科長賞（受賞者：蓮実 拓也）<a href="https://www.i.u-tokyo.ac.jp/news/files/2021_the_dean%27s_award.pdf">link</a></li>
<li>2021/12: 日本音響学会第24回関西支部若手研究者交流研究発表会 奨励賞（受賞者：渡辺 瑠伊）<a href="https://asj-kansai.acoustics.jp/event/24wakate/">link</a></li>
<li>2021/06: 2021 Otogaku Symposium Best Student Presentation Award (Awardee: Koichi Saito) / 2021年度 音学シンポジウム学生優秀発表賞（受賞者：齋藤 弘一）<a href="https://www.ipsj.or.jp/award/musslp-award2.html">link</a></li>
<li>2021/05: Best Student Presentation Award from ASJ (Awardee: Takuya Hasumi) / 日本音響学会 第22回学生優秀発表賞（受賞者：蓮実 拓也）<a href="https://acoustics.jp/awards/student/">link</a></li>
</ol>
<h2 id="other">Other / その他<a class="headerlink" href="#other" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>中村 友彦</ins>, <strong>"深層学習を用いた音源分離,"</strong> 日本音響学会第23回サマーセミナー，Sep. 2022.<br />
<a href="https://drive.google.com/file/d/10kswztKvvfdG82Br2ynfW44U28xlmmxD/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 464h48v48H64c-35.3 0-64-28.7-64-64V64C0 28.7 28.7 0 64 0h165.5c17 0 33.3 6.7 45.3 18.7l90.5 90.5c12 12 18.7 28.3 18.7 45.3V304h-48V160h-80c-17.7 0-32-14.3-32-32V48H64c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16zm112-112h32c30.9 0 56 25.1 56 56s-25.1 56-56 56h-16v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-16v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-32c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-16v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V368z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>，<strong>"コーヒーブレイク　ちょっとしたエッセイ"</strong>, <em>日本音響学会誌</em>，vol. 78, no. 1, Dec. 25, 2021.</li>
<li><ins>中村 友彦</ins>, <strong>"音楽音響信号に対するウェーブレット変換を用いた音源分離,"</strong> <a href="https://www.keisu.t.u-tokyo.ac.jp/2021/09/13/system_colloquium-202102/">東京大学工学部計数工学科 システム情報談話会</a>，Sep. 2021.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝, 亀岡 弘和, <strong>"音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム,"</strong> <em>OngaCRESTシンポジウム2014-音楽情報処理研究が切り拓く未来を探る-,</em> Aug. 23, 2014.<ul>
<li><a href="http://ongacrest.jp/">OngaCREST</a></li>
<li><a href="http://av.watch.impress.co.jp/docs/series/dal/20140825_663420.html">「人型ロボットのダンス」や「声の年齢制御」など、音楽情報処理の最先端をレポート - 藤本健のDigital Audio Laboratory</a></li>
<li><a href="http://pc.watch.impress.co.jp/docs/column/kyokai/20140827_663740.html">コピー不可能な体験を価値の中核に～音楽情報処理の「OngaCRESTシンポジウム」レポート - 森山和道の「ヒトと機械の境界面」</a></li>
</ul>
</li>
</ol>







  
  



  


  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021- Tomohoiko Nakamura
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": ".", "features": ["toc.integrate"], "search": "assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.af256bd8.min.js"></script>
      
    
  </body>
</html>