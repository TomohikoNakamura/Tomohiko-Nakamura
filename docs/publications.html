
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <meta name="author" content="Tomohiko Nakamura">
      
      
        <link rel="canonical" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/publications.html">
      
      <link rel="shortcut icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.2.3">
    
    
      
        <title>Publications / 発表文献 - Tomohiko Nakamura</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.3b61ea93.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.39b8e14a.min.css">
        
          
          
          <meta name="theme-color" content="#757575">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    
      
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9EPRVMYY0Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9EPRVMYY0Z');
</script>
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="grey" data-md-color-accent="primary">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#publications" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/" title="Tomohiko Nakamura" class="md-header-nav__button md-logo" aria-label="Tomohiko Nakamura">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      <div class="md-header-nav__ellipsis">
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            Tomohiko Nakamura
          </span>
        </div>
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            
              Publications / 発表文献
            
          </span>
        </div>
      </div>
    </div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="index.html" class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="research.html" class="md-tabs__link">
      Research / Demo
    </a>
  </li>

      
        
  
  
    
  


  <li class="md-tabs__item">
    <a href="publications.html" class="md-tabs__link md-tabs__link--active">
      Publications
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="lecture.html" class="md-tabs__link">
      Lecture Notes
    </a>
  </li>

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/" title="Tomohiko Nakamura" class="md-nav__button md-logo" aria-label="Tomohiko Nakamura">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Tomohiko Nakamura
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      



  <li class="md-nav__item">
    <a href="index.html" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      



  <li class="md-nav__item">
    <a href="research.html" class="md-nav__link">
      Research / Demo
    </a>
  </li>

    
      
      
      


  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
    <a href="publications.html" class="md-nav__link md-nav__link--active">
      Publications
    </a>
    
  </li>

    
      
      
      



  <li class="md-nav__item">
    <a href="lecture.html" class="md-nav__link">
      Lecture Notes
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="publications">Publications / 発表文献<a class="headerlink" href="#publications" title="Permanent link">&para;</a></h1>
<h2>Journals / 査読付き論文誌</h2>
<ol>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Harmonic-Temporal Factor Decomposition for Unsupervised Monaural Separation of Harmonic Sounds</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 68–82, Nov. 2020. <a href="https://doi.org/10.1109/TASLP.2020.3037487"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/HTFD/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 24, no. 2, pp. 329–339, Feb. 2016. <a href="https://doi.org/10.1109/TASLP.2015.2507862"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="http://arxiv.org/abs/1512.07748"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/automatic_accompaniment/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Yutaka Hori, and Shinji Hara, “<strong>Hierarchical Modeling and Local Stability Analysis for Repressilators Coupled by Quorum Sensing</strong>,” <em>SICE Journal of Control, Measurement, and System Integration</em>, vol. 7, no. 3, pp. 133–140, May 2014. <a href="https://www.jstage.jst.go.jp/article/jcmsi/7/3/7_133/_article"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[SICE Best Paper Award (Takeda Award) / 2015年計測自動制御学会 論文賞 (武田賞)]</span></li>
<li>Eita Nakamura, <ins>Tomohiko Nakamura</ins>, Yasuyuki Saito, Nobutaka Ono, and Shigeki Sagayama, “<strong>Outer-Product Type Hidden Markov Model and Polyphonic MIDI Score Following</strong>,” <em>Journal of New Music Research</em>, vol. 43, pp. 183–201, Apr. 2014. <a href="https://doi.org/10.1080/09298215.2014.884145"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="http://arxiv.org/abs/1404.2313"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
</ol>
<h2>International Conferences / 査読付き国際会議</h2>
<ol>
<li>Shihori Kozuka, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong>Investigation on Wavelet Basis Function of DNN-Based Time Domain Audio Source Separation Inspired by Multiresolution Analysis</strong>,” in <em>Proceedings of the 49<sup>th</sup> International Congress and Exposition on Noise Control Engineering</em>, Aug. 2020, pp. 4013–4022.</li>
<li><ins>Tomohiko Nakamura</ins> and Saruwatari Hiroshi, “<strong>Time-Domain Audio Source Separation Based on Wave-U-Net Combined with Discrete Wavelet Transform</strong>,” in <em>Proceedings of the 45<sup>th</sup> International Conference on Acoustics, Speech, and Signal Processing</em>, May 2020, pp. 386–390. <a href="https://doi.org/10.1109/ICASSP40776.2020.9053934"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="https://arxiv.org/abs/2001.10190"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Shifted and Convolutive Source-Filter Non-Negative Matrix Factorization for Monaural Audio Source Separation</strong>,” in <em>Proceedings of the 41<sup>st</sup> IEEE International Conference on Acoustics, Speech and Signal Processing</em>, Mar. 2016, pp. 489–493. <a href="https://doi.org/10.1109/ICASSP.2016.7471723"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Lp-Norm Non-Negative Matrix Factorization and Its Application to Singing Voice Enhancement</strong>,” in <em>Proceedings of 2015 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, Apr. 2015, pp. 2115–2119. <a href="https://doi.org/10.1109/ICASSP.2015.7178344"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Kotaro Shikata, Norihiro Takamune, and Hirokazu Kameoka, “<strong>Harmonic-Temporal Factor Decomposition Incorporating Music Prior Information for Informed Monaural Source Separation</strong>,” in <em>Proceedings of the 15<sup>th</sup> International Society for Music Information Retrieval Conference</em>, Oct. 2014, pp. 623–628. <a href="https://archives.ismir.net/ismir2014/paper/000135.pdf"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/HTFD"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Tateishi Science and Technology Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Fast Signal Reconstruction from Magnitude Spectrogram of Continuous Wavelet Transform Based on Spectrogram Consistency</strong>,” in <em>Proceedings of the 17<sup>th</sup> International Conference on Digital Audio Effects</em>, Sep. 2014, pp. 129–135. <a href="http://www.dafx14.fau.de/papers/dafx14_tomohiko_nakamura_fast_signal_reconstructio.pdf"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/fastCWT/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Hara Research Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins>, Hirokazu Kameoka, Kazuyoshi Yoshii, and Masataka Goto, “<strong>Timbre Replacement of Harmonic and Drum Components for Music Audio Signals</strong>,” in <em>Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, May 2014. <a href="https://doi.org/10.1109/ICASSP.2014.6855052"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/drum_timbre_replacement/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Acoustic Score Following to Musical Performance with Errors and Arbitrary Repeats and Skips for Automatic Accompaniment</strong>,” in <em>Proceedings of Sound and Music Computing Conference</em>, Aug. 2013, pp. 299–304. <a href="http://smcnetwork.org/node/1754"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/automatic_accompaniment"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Telecommunications Advancement Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins>, Shinji Hara, and Yutaka Hori, “<strong>Local Stability Analysis for a Class of Quorum-Sensing Networks with Cyclic Gene Regulatory Networks</strong>,” in <em>Proceedings of SICE Annual Conference</em>, Sep. 2011. <a href="https://ieeexplore.ieee.org/document/6060320"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[SICE Annual Conference 2011 International Award and Finalist of Young Author's Award]</span></li>
<li>Takuya Higuchi, Hirofumi Takeda, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>A Unified Approach for Underdetermined Blind Signal Separation and Source Activity Detection by Multichannel Factorial Hidden Markov Models</strong>,” in <em>Proceedings of the 15<sup>th</sup> Annual Conference of the International Speech Communication Association</em>, Sep. 2014, pp. 850–854. <a href="https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0850.pdf"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li>Takuya Higuchi, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>Underdetermined Blind Separation and Tracking of Moving Sources Based on DOA-HMM</strong>,” in <em>Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, May 2014, pp. 3215–3219. <a href="https://doi.org/10.1109/ICASSP.2014.6854189"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li>Shigeki Sagayama, <ins>Tomohiko Nakamura</ins>, Eita Nakamura, Yasuyuki Saito, Kameoka Hirokazu, and Nobutaka Ono, “<strong>Automatic Music Accompaniment Allowing Errors and Arbitrary Repeats and Jumps</strong>,” in <em>Proceedings of Meetings on Acoustics, Acoustic Society of America</em>, May 2014, vol. 21, 35003. <a href="https://doi.org/10.1121/1.4877848"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li>Masahiro Nakano, Jonathan Le Roux, Kameoka Hirokazu, <ins>Tomohiko Nakamura</ins>, Nobutaka Ono, and Shigeki Sagayama, “<strong>Bayesian Nonparametric Spectrogram Modeling Based on Infinite Factorial Infinite Hidden Markov Model</strong>,” in <em>Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, Oct. 2011, pp. 325–328. <a href="https://doi.org/10.1109/ASPAA.2011.6082324"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
</ol>
<h2>Domestic Conferences / 国内会議</h2>
<ol>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>潜在アナログフィルタ表現に基づく畳み込み層を用いたサンプリング周波数非依存なDNN音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, Mar. 2021. (to appear)</li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>経験ベイズ独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, Mar. 2021. (to appear)</li>
<li>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>独立深層学習テンソル分析に基づく多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, Mar. 2021. (to appear)</li>
<li>成澤 直輝, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>音源分離のための周波数間相関を考慮した多変量複素Gauss分布に基づく深層学習による分散共分散行列推定の検討</strong>,” <em>日本音響学会 2020年秋季研究発表会講演論文集</em>, pp. 315–318, Sep. 2020.</li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>ニューラルネットワークとウェーブレット基底関数の同時学習に基づく多重解像度深層分析を用いた時間領域音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, pp. 279–284, Mar. 2020.</li>
<li>高道 慎之介, 齋藤 佑樹, <ins>中村 友彦</ins>, 郡山 知樹,  猿渡 洋, “<strong>manga2voice: マンガ画像からの音声合成に向けた音声分析</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 1065–1068, Mar. 2020.</li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>リフティングスキームによる離散ウェーブレット変換を導入した深層ニューラルネットに基づく時間領域音源分離</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 325–328, Mar. 2020.</li>
<li><ins>中村 友彦</ins> and 猿渡 洋, “<strong>Haar変換を導入した時間領域深層ニューラルネットに基づく音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, pp. 41–48, Nov. 2019.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムからの逐次位相推定法</strong>,” <em>情報処理学会研究報告</em>, May 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による超解像声道スペクトル推定法</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 115, pp. 99–104, Mar. 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムに対する実時間位相推定法</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 933–936, Mar. 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による声道スペクトル推定法の検討</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 393–396, Mar. 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>全極スペクトルモデルと擬似周期信号モデルのウェーブレット変換表現を用いた多重音スペクトログラムの調波時間因子分解</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–107, May 2015.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>全極スペクトルモデルを用いた調波時間因子分解による多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–106, Mar. 2015.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–104, Aug. 2014.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>無矛盾性規準に基づく連続ウェーブレット変換スペクトログラムへの位相推定法と高速化</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, May 2014.</li>
<li>樋口 卓也, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>確率的モデル化に基づく移動音源の劣決定ブラインド音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 114, pp. 211–216, May 2014.</li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解法に基づく事前情報付き多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, May 2014.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>連続ウェーブレット変換の高速近似アルゴリズムに基づく振幅スケーログラムへの無矛盾位相付加法の検討</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, Mar. 2014.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号に含まれる調波音の周波数特性とドラムの音色の転写システム</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, Mar. 2014.</li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解に基づく音楽事前情報付き多重音解析</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, Mar. 2014.</li>
<li>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>DOA-HMMに基づく劣決定ブラインド音源分離</strong>,” <em>日本音響学会2013年秋季研究発表会講演集</em>, Sep. 2013.</li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>誤り・任意の弾き直し・弾き飛ばしを含む演奏音響信号への高速な楽譜追跡</strong>,” <em>情報処理学会研究報告</em>, vol. 2013–MUS–99, May 2013.</li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡</strong>,” <em>情報処理学会 第75回全国大会</em>, vol. 2013, pp. 283–284, Mar. 2013.</li>
<li><ins>中村 友彦</ins>, 水野 優, 鈴木 孝輔, 中村 栄太, 樋口 祐介, 深山 覚,  嵯峨山 茂樹, “<strong>音楽演奏の誤りや反復に頑健な音響入力自動伴奏</strong>,” <em>日本音響学会2012年秋季研究発表会講演集</em>, pp. 931–934, Sep. 2012.</li>
<li>中野 允裕, ルルー ジョナトン, 亀岡 弘和, <ins>中村 友彦</ins>, 小野 順貴,  嵯峨山 茂樹, “<strong>スペクトログラムのベイジアンノンパラメトリックモデリングに基づく音楽信号の解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2011–MUS–91, Jul. 2011.</li>
</ol>
<h2>Review Papers / 解説記事</h2>
<ol>
<li>亀岡 弘和, <ins>中村 友彦</ins>,  高宗 典玄, “<strong>音楽音響信号処理技術の最先端</strong>,” <em>電子情報通信学会誌</em>, vol. 98, no. 6, pp. 467–474, Jun. 2015.</li>
</ol>
<h2>Thesis / 学位論文</h2>
<ol>
<li>Ph.D. Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Source-Filter Representation and Phase Estimation in Continuous Wavelet Transform Domain for Monaural Music Audio Editing,"</strong> the University of Tokyo, Mar. 2016. <br />
   <span style="color: var(--md-code-hl-function-color)">[Dean’s Award, Graduate School of Information Science and Technology, The University of Tokyo / 東京大学大学院情報理工学系研究科 研究科長賞]</span></li>
<li>Master's Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Fast Score Following to Acoustic Signal of Musical Performance with Errors, Repeats and Skips,"</strong> the University of Tokyo, Mar. 2013. (in Japanese)</li>
<li>Bachelor's Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Local Stability Analysis of Cell-to-Cell Networks with Cyclic Gene Regulatory Networks,"</strong> the University of Tokyo, Mar. 2011. (in Japanese)</li>
</ol>
<h2>Patents / 特許</h2>
<ol>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>声道スペクトル推定装置、声道スペクトル推定方法、及びプログラム</strong>,” 特許第6420781号, 07-Nov-2018.</li>
<li><ins>中村 友彦</ins>, “<strong>データベース統合装置、データベース統合方法、データベース統合プログラム、及びデータ補完装置</strong>,” 特許第6768101号, 14-Oct-2020.</li>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第6773829号, 21-Oct-2020.</li>
<li><ins>中村 友彦</ins>, “<strong>学習装置、学習方法、学習プログラム、及び対象物認識装置</strong>,” 特許第6773825号, 21-Oct-2020.</li>
<li><ins>中村 友彦</ins>, 伊藤 忠彦,  島岡 政基, “<strong>証明書管理装置</strong>,” 特許第6647259号, 16-Jan-2020.</li>
<li><ins>中村 友彦</ins>, 國松 昇平, 櫻井 利彦,  大西 一徳, “<strong>カメラ配置評価装置、カメラ配置評価方法、及びコンピュータプログラム</strong>,” 特開2021-10070, 28-Jan-2021.</li>
</ol>
<h2>Other / その他</h2>
<ol>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝, 亀岡 弘和, <strong>"音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム,"</strong> <em>OngaCRESTシンポジウム2014-音楽情報処理研究が切り拓く未来を探る-,</em> Aug. 23, 2014.<ul>
<li><a href="http://ongacrest.jp/">OngaCREST</a></li>
<li><a href="http://av.watch.impress.co.jp/docs/series/dal/20140825_663420.html">「人型ロボットのダンス」や「声の年齢制御」など、音楽情報処理の最先端をレポート - 藤本健のDigital Audio Laboratory</a></li>
<li><a href="http://pc.watch.impress.co.jp/docs/column/kyokai/20140827_663740.html">コピー不可能な体験を価値の中核に～音楽情報処理の「OngaCRESTシンポジウム」レポート - 森山和道の「ヒトと機械の境界面」</a></li>
</ul>
</li>
</ol>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="research.html" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Research / Demo
              </div>
            </div>
          </a>
        
        
          <a href="lecture.html" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Lecture Notes
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2021- Tomohoiko Nakamura
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="assets/javascripts/vendor.08c56446.min.js"></script>
      <script src="assets/javascripts/bundle.6ced434e.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: ".",
          features: ['navigation.tabs', 'navigation.tabs.sticky', 'toc.integrate'],
          search: Object.assign({
            worker: "assets/javascripts/worker/search.8c7e0a7e.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>