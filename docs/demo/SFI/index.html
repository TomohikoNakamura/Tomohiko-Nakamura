<!doctype html>
<html>
    <head>
        <!-- BOOTSTRAP CORE STYLE  -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
        <!-- GOOGLE FONT -->
        <link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css' crossorigin="anonymous" />

        <!-- BOOTSTRAP JS -->
        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    
        <!-- CUSTOM STYLE CSS -->
        <link href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/assets/css/style.css" rel="stylesheet" />

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

        <!-- Page description -->
        

        <!-- Page keywords -->
        

        <!-- Page author -->
        
            <meta name="author" content="Tomohiko Nakamura" />
        

        <!-- Site title -->
        
        
            <title>Sampling-Frequency-Independent Deep Learning for Audio Media Processing / 音メディア処理のための標本化周波数非依存深層学習 - Tomohiko Nakamura</title>
        
        

        
            
                <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9EPRVMYY0Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9EPRVMYY0Z');
</script>
            
        

    </head>
    <body>
        <!-- START NAB BAR SECTION -->
        <nav class="navbar navbar-expand-md  navbar-dark bg-dark">
            <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navigator" aria-controls="navigator" aria-expanded="false" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>
            
            <div class="collapse navbar-collapse" id="navigator">
              <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/">Home</a></li>
              </ul>
            </div>
          </nav>
        <!--END NAB BAR SECTION-->    

        <section class="jumbotron text-center">
    <div class="container">
        
            <h1 class="jumbotron-heading">音メディア処理のための標本化周波数非依存深層学習（ACT-X「数理・情報のフロンティア」2021年度～2024年度）</h1>
        
        
            <p class="lead">
                Sampling-Frequency-Independent Deep Learning for Audio Media Processing
            </p>
        
    </div>
</section>
        
            <div class="container">
    <div class="row">
        <h1>Abstract</h1>
        <div class="w-100"></div>
        <p class="lead text-left">
            Audio source separation is a technique of separating individual sources from a mixture audio, and it is often used for preprocessing of audio applications. To build a source separation model that can be used as a versatile preprocessor, various acoustic conditions (for example, sampling frequency) required by possible downstream tasks should be handled. Although conventional source separation models based on deep neural networks work well only at a trained sampling frequency, they are difficult to work with sounds of untrained sampling frequencies. In this study, interpreting deep neural networks from a signal processing viewpoint, I develop layers independent of sampling frequency to establish a more versatile deep learning framework for audio media processing.
        </p>
        <div class="w-100"></div>
        <p class="lead text-left">
            混合音から各音源信号を抽出する音源分離は、様々な音メディア処理システムの前処理として利用できます。汎用的に使用可能な音源分離を実現するためには、標本化周波数などの後段のタスクで要求される様々な音響的条件下でも頑健に動作する必要があります。本研究では、深層学習モデルを信号処理の観点から解釈することで、標本化周波数に非依存な層を構築し、汎用的な音メディア処理用深層学習フレームワークの実現を目指します。
        </p>
    </div>
    <div class="row">
        <h1>Research</h1>
        <div class="w-100"></div>
        <p class="lead text-left">
            Coming soon
        </p>
    </div>
    <div class="row">
        <h1>Publications</h1>
        <div class="w-100"></div>
        <p class="lead text-left">
            Coming soon
        </p>
    </div>
</div>
        
    </body>
</html>