
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Tomohiko Nakamura">
      
      
        <link rel="canonical" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/publications/index.html">
      
      
        <link rel="prev" href="../research.html">
      
      
        <link rel="next" href="journals.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Publications / 発表文献 - Tomohiko Nakamura</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9EPRVMYY0Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9EPRVMYY0Z');
</script>
<script>
  function toggleBib(id) {
    var elem = document.getElementById(id);
    if (elem.style.display === "none") {
      elem.style.display = "block";
    } else {
      elem.style.display = "none";
    }
  }
</script>
    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="primary">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#publications" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="Tomohiko Nakamura" class="md-header__button md-logo" aria-label="Tomohiko Nakamura" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Tomohiko Nakamura
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Publications / 発表文献
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Tomohiko Nakamura" class="md-nav__button md-logo" aria-label="Tomohiko Nakamura" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Tomohiko Nakamura
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../research.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Research / Demo
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="index.html" class="md-nav__link md-nav__link--active">
              
  
  
  <span class="md-ellipsis">
    Publications
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Publications
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="journals.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Journals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="int_confs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    International Conferences
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="dom_confs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Domestic Conferences
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="review_patents_and_talks.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Review, Patents, & Talks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="awards.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Awards
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../datasets.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Datasets
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../lecture.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture Notes
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../tips.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tips
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  
  




<h1 id="publications">Publications / 発表文献<a class="headerlink" href="#publications" title="Permanent link">&para;</a></h1>
<p><strong><a href="pdfs/nakamura_CV_short.pdf">Short CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>, <a href="pdfs/nakamura_CV.pdf">Full CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>, <a href="https://scholar.google.com/citations?user=bHny6PAAAAAJ">Google Scholar<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2C505.9 32 576 102 576 188.5c0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1C429.8 399.5 390 416 348.5 416 262.1 416 192 346 192 259.5c0-1.5 0-3 .1-4.5.5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9v2.6c0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zm-144.3 77.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1l-71.1 71.1C73.8 275.5 64 299.1 64 323.6c0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2C70.1 480.2 0 410.2 0 323.7c0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9v3.9c-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8v-2.3c0-33.7-18-63.3-44.8-79.6z"/></svg></span></a>, <a href="https://researchmap.jp/tomohiko_nakamura">Researchmap<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2C505.9 32 576 102 576 188.5c0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1C429.8 399.5 390 416 348.5 416 262.1 416 192 346 192 259.5c0-1.5 0-3 .1-4.5.5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9v2.6c0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zm-144.3 77.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1l-71.1 71.1C73.8 275.5 64 299.1 64 323.6c0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2C70.1 480.2 0 410.2 0 323.7c0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9v3.9c-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8v-2.3c0-33.7-18-63.3-44.8-79.6z"/></svg></span></a>, <a href="https://orcid.org/0000-0003-4385-7170">ORCiD<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2C505.9 32 576 102 576 188.5c0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1C429.8 399.5 390 416 348.5 416 262.1 416 192 346 192 259.5c0-1.5 0-3 .1-4.5.5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9v2.6c0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zm-144.3 77.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1l-71.1 71.1C73.8 275.5 64 299.1 64 323.6c0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2C70.1 480.2 0 410.2 0 323.7c0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9v3.9c-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8v-2.3c0-33.7-18-63.3-44.8-79.6z"/></svg></span></a></strong></p>
<h2 id="journals-peer-reviewed">Journals (Peer-reviewed) / 査読付き論文誌<a class="headerlink" href="#journals-peer-reviewed" title="Permanent link">&para;</a></h2>
<ol>
<li>Yusaku Mizobuchi, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.1561/116.20250020">Music bleeding-sound reduction based on time-channel nonnegative matrix factorization</a></strong>,” <em>APSIPA Transactions on Signal and Information Processing</em>, vol. 14, no. 1, e18, Jul. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YMizobuchi202507APSIPATrans')">bib</a><br><div id="YMizobuchi202507APSIPATrans" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">YMizobuchi202507APSIPATrans</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Mizobuchi, Yusaku and Kitamura, Daichi and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Music bleeding-sound reduction based on time-channel nonnegative matrix factorization&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;APSIPA Transactions on Signal and Information Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;14&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1, e18&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;July&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1561/116.20250020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yuto Ishikawa, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Daichi Kitamura, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.1109/ACCESS.2025.3569590">Real-time speech extraction based on rank-constrained spatial covariance matrix estimation and spatially regularized independent low-rank matrix analysis with fast demixing matrix estimation</a></strong>,” <em>IEEE Access</em>, vol. 13, pp. 88683–88706, May 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa2025IEEEAcess')">bib</a><br><div id="YIshikawa2025IEEEAcess" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">YIshikawa2025IEEEAcess</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Ishikawa, Yuto and Nakamura, Tomohiko and Takamune, Norihiro and Kitamura, Daichi and Saruwatari, Hiroshi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Real-time speech extraction based on rank-constrained spatial covariance matrix estimation and spatially regularized independent low-rank matrix analysis with fast demixing matrix estimation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE Access&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;13&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;88683--88706&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ACCESS.2025.3569590&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Kanami Imamura, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1561/116.20230082">Neural analog filter for sampling-frequency-independent convolutional layer</a></strong>,” <em>APSIPA Transactions on Signal and Information Processing</em>, vol. 13, no. 1, e28, Nov. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2024APSIPATrans')">bib</a>   <a class="md-button md-button--small" href="https://github.com/Kanami-Imamura/Neural_Analog_Filter_music_source_separation">code 1 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/Kanami-Imamura/Neural_Analog_Filter_speech_separation">code 2 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="KImamura2024APSIPATrans" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">KImamura2024APSIPATrans</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Imamura, Kanami and Nakamura, Tomohiko and Yatabe, Kohei and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Neural analog filter for sampling-frequency-independent convolutional layer&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;APSIPA Transactions on Signal and Information Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;13&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1, e28&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;November&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1561/116.20230082&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takaaki Saeki, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Naoko Tanji, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ACCESS.2023.3345027">SelfRemaster: Self-supervised speech restoration for historical audio resources</a></strong>,” <em>IEEE Access</em>, vol. 11, pp. 144831–144843, Jan. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TSaeki2024IEEEAccess')">bib</a>   <a class="md-button md-button--small" href="https://takaaki-saeki.github.io/selfremaster_demo_access/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/Takaaki-Saeki/ssl_speech_restoration_v2">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="TSaeki2024IEEEAccess" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">TSaeki2024IEEEAccess</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Saeki, Takaaki and Takamichi, Shinnosuke and Nakamura, Tomohiko and Tanji, Naoko and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{SelfRemaster: S}elf-Supervised Speech Restoration for Historical Audio Resources&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE Access&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;11&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;144831--144843&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;January&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ACCESS.2023.3345027&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.1109/TASLP.2023.3293044">PoP-IDLMA: Product-of-prior independent deeply learned matrix analysis for multichannel music source separation</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 31, pp. 2680–2694, Jul. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THasumi2023IEEEACMTASLP')">bib</a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/1-XRE6Ohgd9XIkZl7gbNsCIgKV3u54XV-/view?usp=sharing">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="THasumi2023IEEEACMTASLP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">THasumi2023IEEEACMTASLP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hasumi, Takuya and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi and Kitamura, Daichi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE/ACM Transactions on Audio, Speech, and Language Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{PoP-IDLMA: P}roduct-of-Prior Independent Deeply Learned Matrix Analysis for Multichannel Music Source Separation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;July&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;31&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2680--2694&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/TASLP.2023.3293044&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Koichi Saito, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/TASLP.2022.3203907">Sampling-frequency-independent convolutional layer and its application to audio source separation</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 30, pp. 2928–2943, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KSaito2022IEEEACMTASLP')">bib</a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/1Fxnvf-K31NCY0zO0dxyCSNEzgYxXVmCS/view?usp=sharing">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/1FsygLBnjhi6aE0lEJ2enQDaqGFpavhus/view?usp=sharing">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/sfi_convtasnet/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/TomohikoNakamura/sfi_convtasnet">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="KSaito2022IEEEACMTASLP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">KSaito2022IEEEACMTASLP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Saito, Koichi and Nakamura, Tomohiko and Yatabe, Kohei and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE/ACM Transactions on Audio, Speech, and Language Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Sampling-frequency-independent convolutional layer and its application to audio source separation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;30&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2928--2943&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/TASLP.2022.3203907&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Shihori Kozuka, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/TASLP.2021.3072496">Time-domain audio source separation with neural networks based on multiresolution analysis</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 1687–1701, Apr. 2021.<br />
<span style="color: var(--md-code-hl-function-color)">[The Itakura Prize Innovative Young Researcher Award / 第17回日本音響学会・独創研究奨励賞板倉記念]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura202104IEEEACMTASLP')">bib</a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/10z8dxzKtCf8dAfv-_MYQUWkWGawt3rrI/view?usp=share_link">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/106d2i7NYkIdNgYR1NpUgm1xXBoP6TKwX/view?usp=share_link">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/MRDLA/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/TomohikoNakamura/dwtls">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="TNakamura202104IEEEACMTASLP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">TNakamura202104IEEEACMTASLP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Kozuka, Shihori and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE/ACM Transactions on Audio, Speech, and Language Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Time-domain audio source separation with neural networks based on multiresolution analysis&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/TASLP.2021.3072496&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;April&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;29&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1687--1701&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/TASLP.2020.3037487">Harmonic-temporal factor decomposition for unsupervised monaural separation of harmonic sounds</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 68–82, Nov. 2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2020IEEEACMTASLP')">bib</a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/1029Dp0LhE5fmIH1xhrDmyXtes4fagX7A/view?usp=share_link">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/11-LY9X9ZTnc29Rj-yOII38B-hHk1vMJp/view?usp=share_link">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/HTFD/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/TomohikoNakamura/HTFD">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a>   <a class="md-button md-button--small" href="https://docs.google.com/forms/d/e/1FAIpQLSeCPCnbnK2RFxhoKcURxr6yRXeHjM5BgTvO2qaAIDhGAB0brA/viewform?usp=sf_link">dataset <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M448 205.8c-14.8 9.8-31.8 17.7-49.5 24-47 16.8-108.7 26.2-174.5 26.2s-127.6-9.5-174.5-26.2c-17.6-6.3-34.7-14.2-49.5-24V288c0 44.2 100.3 80 224 80s224-35.8 224-80zm0-77.8V80c0-44.2-100.3-80-224-80S0 35.8 0 80v48c0 44.2 100.3 80 224 80s224-35.8 224-80m-49.5 261.8C351.6 406.5 289.9 416 224 416s-127.6-9.5-174.5-26.2c-17.6-6.3-34.7-14.2-49.5-24V432c0 44.2 100.3 80 224 80s224-35.8 224-80v-66.2c-14.8 9.8-31.8 17.7-49.5 24"/></svg></span></a><br><div id="TNakamura2020IEEEACMTASLP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">TNakamura2020IEEEACMTASLP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE/ACM Transactions on Audio, Speech, and Language Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Harmonic-temporal factor decomposition for unsupervised monaural separation of harmonic sounds&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;November&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;29&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;68--82&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/TASLP.2020.3037487&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong><a href="https://doi.org/10.1109/TASLP.2015.2507862">Real-time audio-to-score alignment of music performances containing errors and arbitrary repeats and skips</a></strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 24, no. 2, pp. 329–339, Feb. 2016.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201602IEEEACMTASLP')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/1512.07748">arXiv</a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/automatic_accompaniment/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="TNakamura201602IEEEACMTASLP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">TNakamura201602IEEEACMTASLP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Nakamura, Eita and Sagayama, Shigeki&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;IEEE/ACM Transactions on Audio, Speech, and Language Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;February&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;329--339&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Real-time audio-to-score alignment of music performances containing errors and arbitrary repeats and skips&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;24&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/TASLP.2015.2507862&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Yutaka Hori, and Shinji Hara, “<strong><a href="https://doi.org/10.9746/jcmsi.7.133">Hierarchical modeling and local stability analysis for repressilators coupled by quorum sensing</a></strong>,” <em>SICE Journal of Control, Measurement, and System Integration</em>, vol. 7, no. 3, pp. 133–140, May 2014.<br />
<span style="color: var(--md-code-hl-function-color)">[SICE Best Paper Award (Takeda Award) / 2015年計測自動制御学会 論文賞 (武田賞)]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201405JCMSI')">bib</a><br><div id="TNakamura201405JCMSI" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">TNakamura201405JCMSI</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Hori, Yutaka and Hara, Shinji&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;SICE Journal of Control, Measurement, and System Integration&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;3&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;133--140&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hierarchical modeling and local stability analysis for repressilators coupled by quorum sensing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;7&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.9746/jcmsi.7.133&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Eita Nakamura, <ins>Tomohiko Nakamura</ins>, Yasuyuki Saito, Nobutaka Ono, and Shigeki Sagayama, “<strong><a href="https://doi.org/10.1080/09298215.2014.884145">Outer-product type hidden Markov model and polyphonic MIDI score following</a></strong>,” <em>Journal of New Music Research</em>, vol. 43, pp. 183–201, Apr. 2014.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('ENakamura201404JNMR')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/1404.2313">arXiv</a><br><div id="ENakamura201404JNMR" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">ENakamura201404JNMR</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Eita and Nakamura, Tomohiko and Saito, Yasuyuki and Ono, Nobutaka and Sagayama, Shigeki&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">issue</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Journal of New Music Research&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;183--201&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Outer-product type hidden {Markov} model and polyphonic {MIDI} score following&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;43&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;April&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1080/09298215.2014.884145&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
</ol>
<h2 id="international-conferences-workshops">International Conferences &amp; Workshops / 国際会議<a class="headerlink" href="#international-conferences-workshops" title="Permanent link">&para;</a></h2>
<h3 id="peer-reviewed">Peer-Reviewed<a class="headerlink" href="#peer-reviewed" title="Permanent link">&para;</a></h3>
<ol>
<li>Go Nishikawa, Wataru Nakata, Yuki Saito, Kanami Imamura, Hiroshi Saruwatari, and <ins>Tomohiko Nakamura</ins>, “<strong>Multi-sampling-frequency naturalness MOS prediction using self-supervised learning model with sampling-frequency-independent layer</strong>,” in <em>Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop</em>, Dec. 2025. (First and second authors contributed equally.)<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('GNishikawa2025ASRU')">bib</a><br><div id="GNishikawa2025ASRU" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">GNishikawa2025ASRU</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nishikawa, Go and Nakata, Wataru and Saito, Yuki and Imamura, Kanami and Saruwatari, Hiroshi and Nakamura, Tomohiko&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Multi-sampling-frequency naturalness {MOS} prediction using self-supervised learning model with sampling-frequency-independent layer&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">note</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;(First and second authors contributed equally.)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Ryan Niu, Shoichi Koyama, and <ins>Tomohiko Nakamura</ins>, “<strong>Head-related transfer function individualization using anthropometric features and spatially independent latent representations</strong>,” in <em>Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, Oct. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RNiu2025WASPAA')">bib</a><br><div id="RNiu2025WASPAA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RNiu2025WASPAA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Niu, Ryan and Koyama, Shoichi and Nakamura, Tomohiko&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Head-Related Transfer Function Individualization Using Anthropometric Features and Spatially Independent Latent Representations&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;October&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Hitoshi Suda, Junya Koguchi, Shunsuke Yoshida, <ins>Tomohiko Nakamura</ins>, Fukayama Satoru, and Jun Ogata, “<strong>IdolSongsJp corpus: A multi-singer song corpus in the style of Japanese idol groups</strong>,” in <em>Proceedings of International Society for Music Information Retrieval Conference</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HSuda2025ISMIR')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2507.01349">arXiv</a><br><div id="HSuda2025ISMIR" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HSuda2025ISMIR</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Suda, Hitoshi and Koguchi, Junya and Yoshida, Shunsuke and Nakamura, Tomohiko and Satoru, Fukayama and Ogata, Jun&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Society for Music Information Retrieval Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{IdolSongsJp} Corpus: {A} Multi-Singer Song Corpus in the Style of {Japanese} Idol Groups&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Kanami Imamura, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Kohei Yatabe, and Hiroshi Saruwatari, “<strong>Local equivariance error-based metrics for evaluating sampling-frequency-independent property of neural network</strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2025EUSIPCO')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2506.03550">arXiv</a><br><div id="KImamura2025EUSIPCO" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura2025EUSIPCO</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Imamura, Kanami and Nakamura, Tomohiko and Takamune, Norihiro and Yatabe, Kohei and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of European Signal Processing Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Local equivariance error-based metrics for evaluating sampling-frequency-independent property of neural network&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Aogu Wada, <ins>Tomohiko Nakamura</ins>, and Saruwatari Hiroshi, “<strong>Hyperbolic embeddings for order-aware classification of audio effect chains</strong>,” in <em>Proceedings of International Conference on Digital Audio Effects</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('AWada2025DAFx')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2507.20624">arXiv</a><br><div id="AWada2025DAFx" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AWada2025DAFx</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Wada, Aogu and Nakamura, Tomohiko and Hiroshi, Saruwatari&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Conference on Digital Audio Effects&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hyperbolic embeddings for order-aware classification of audio effect chains&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Kwanghee Choi, Keigo Hojo, Yoshiaki Bando, Satoru Fukayama, and Shinji Watanabe, “<strong>Discrete speech unit extraction via independent component analysis</strong>,” in <em>Proceedings of SALMA: Speech and Audio Language Models - Architectures, Data Sources, and Training Paradigms, IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops</em>, Apr. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2025ICASSPWSALMA')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2501.06562">arXiv</a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/11dGm8IPG98nJVbRwiOQJzgSI3OCI_zaJ/view?usp=sharing">poster <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/TomohikoNakamura/ica_dsu_espnet">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="TNakamura2025ICASSPWSALMA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2025ICASSPWSALMA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Choi, Kwanghee and Hojo, Keigo and Bando, Yoshiaki and Fukayama, Satoru and Watanabe, Shinji&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of SALMA: Speech and Audio Language Models - Architectures, Data Sources, and Training Paradigms, {IEEE} International Conference on Acoustics, Speech, and Signal Processing Workshops&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Discrete Speech Unit Extraction via Independent Component Analysis&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;April&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yuto Ishikawa, Osamu Take, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/APSIPAASC63619.2025.10848599">Real-time noise estimation for Lombard-effect speech synthesis in human–avatar dialogue systems</a></strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa202412APSIPA')">bib</a>   <a class="md-button md-button--small" href="http://www.apsipa2024.org/files/papers/355.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="YIshikawa202412APSIPA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa202412APSIPA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Ishikawa, Yuto and Take, Osamu and Nakamura, Tomohiko and Takamune, Norihiro and Saito, Yuki and Takamichi, Shinnosuke and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Real-Time Noise Estimation for {Lombard}-Effect Speech Synthesis in Human--Avatar Dialogue Systems&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/APSIPAASC63619.2025.10848599&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Hiroaki Hyodo, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Junya Koguchi, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/SLT61566.2024.10832340">DNN-based ensemble singing voice synthesis with interactions between singers</a></strong>,” in <em>Proceedings of IEEE Spoken Language Technology Workshop</em>, Dec. 2024, pp. 660–667.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HHyodo202412SLT')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2409.09988">arXiv</a>   <a class="md-button md-button--small" href="https://github.com/sarulab-speech/ensemble_svs_with_interactions">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="HHyodo202412SLT" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HHyodo202412SLT</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hyodo, Hiroaki and Takamichi, Shinnosuke and Nakamura, Tomohiko and Koguchi, Junya and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE Spoken Language Technology Workshop&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;DNN-based ensemble singing voice synthesis with interactions between singers&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;660--667&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/SLT61566.2024.10832340&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Hitoshi Suda, Shunsuke Yoshida, <ins>Tomohiko Nakamura</ins>, Fukayama Satoru, and Jun Ogata, “<strong><a href="https://doi.org/10.5281/ZENODO.14877287">FruitsMusic: A real-world corpus of Japanese idol-group songs</a></strong>,” in <em>Proceedings of International Society for Music Information Retrieval Conference</em>, Nov. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HSuda202411ISMIR')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2409.12549">arXiv</a>   <a class="md-button md-button--small" href="https://huggingface.co/datasets/fruits-music/fruits-music">dataset <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M448 205.8c-14.8 9.8-31.8 17.7-49.5 24-47 16.8-108.7 26.2-174.5 26.2s-127.6-9.5-174.5-26.2c-17.6-6.3-34.7-14.2-49.5-24V288c0 44.2 100.3 80 224 80s224-35.8 224-80zm0-77.8V80c0-44.2-100.3-80-224-80S0 35.8 0 80v48c0 44.2 100.3 80 224 80s224-35.8 224-80m-49.5 261.8C351.6 406.5 289.9 416 224 416s-127.6-9.5-174.5-26.2c-17.6-6.3-34.7-14.2-49.5-24V432c0 44.2 100.3 80 224 80s224-35.8 224-80v-66.2c-14.8 9.8-31.8 17.7-49.5 24"/></svg></span></a><br><div id="HSuda202411ISMIR" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HSuda202411ISMIR</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Suda, Hitoshi and Yoshida, Shunsuke and Nakamura, Tomohiko and Satoru, Fukayama and Ogata, Jun&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Society for Music Information Retrieval Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{FruitsMusic: A} Real-World Corpus of {Japanese} Idol-Group Songs&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;November&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.5281/ZENODO.14877287&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Kwanghee Choi, Ankita Pasad, <ins>Tomohiko Nakamura</ins>, Satoru Fukayama, Karen Livescu, and Shinji Watanabe, “<strong><a href="https://doi.org/10.21437/Interspeech.2024-1157">Self-supervised speech representations are more phonetic than semantic</a></strong>,” in <em>Proceedings of INTERSPEECH</em>, Sep. 2024, pp. 4578–4582.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KChoi202409INTERSPEECH')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2406.08619">arXiv</a>   <a class="md-button md-button--small" href="https://github.com/juice500ml/phonetic_semantic_probing">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="KChoi202409INTERSPEECH" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KChoi202409INTERSPEECH</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Choi, Kwanghee and Pasad, Ankita and Nakamura, Tomohiko and Fukayama, Satoru and Livescu, Karen and Watanabe, Shinji&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of INTERSPEECH&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Self-Supervised Speech Representations are More Phonetic than Semantic&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;4578--4582&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.21437/Interspeech.2024-1157&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yoshiaki Bando, <ins>Tomohiko Nakamura</ins>, and Shinji Watanabe, “<strong><a href="https://doi.org/10.21437/Interspeech.2024-1137">Neural blind source separation and diarization for distant speech recognition</a></strong>,” in <em>Proceedings of INTERSPEECH</em>, Sep. 2024, pp. 722–726.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YBando202409INTERSPEECH')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2406.08396">arXiv</a>   <a class="md-button md-button--small" href="https://ybando.jp/projects/neural-fcasa/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/b-sigpro/neural-fcasa">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="YBando202409INTERSPEECH" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YBando202409INTERSPEECH</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Bando, Yoshiaki and Nakamura, Tomohiko and Watanabe, Shinji&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of INTERSPEECH&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Neural Blind Source Separation and Diarization for Distant Speech Recognition&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;722--726&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.21437/Interspeech.2024-1137&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yuto Ishikawa, Kohei Konaka, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ICASSPW62465.2024.10627448">Real-time speech extraction using spatially regularized independent low-rank matrix analysis and rank-constrained spatial covariance matrix estimation</a></strong>,” in <em>Proceedings of Hands-Free Speech Communication and Microphone Arrays, IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops</em>, Apr. 2024, pp. 730–734.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa202404ICASSPWHSCMA')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2403.12477v1">arXiv</a><br><div id="YIshikawa202404ICASSPWHSCMA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa202404ICASSPWHSCMA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Ishikawa, Yuto and Konaka, Kohei and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Real-time Speech Extraction Using Spatially Regularized Independent Low-rank Matrix Analysis and Rank-Constrained Spatial Covariance Matrix Estimation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Hands-free Speech Communication and Microphone Arrays, IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;April&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;730--734&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSPW62465.2024.10627448&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Kanami Imamura, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Kohei Yatabe, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.23919/EUSIPCO58844.2023.10289819">Algorithms of sampling-frequency-independent layers for non-integer strides</a></strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Sep. 2023, pp. 326–330.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura202309EUSIPCO')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2306.10718">arXiv</a><br><div id="KImamura202309EUSIPCO" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura202309EUSIPCO</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Imamura, Kanami and Nakamura, Tomohiko and Takamune, Norihiro and Yatabe, Kohei and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Algorithms of Sampling-Frequency-Independent Layers for Non-integer Strides&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of European Signal Processing Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;326--330&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.23919/EUSIPCO58844.2023.10289819&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Joonyong Park, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Kentaro Seki, Detai Xin, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.21437/Interspeech.2023-981">How generative spoken language model encodes noisy speech: Investigation from phonetics to syntactics</a></strong>,” in <em>Proceedings of INTERSPEECH</em>, Aug. 2023, pp. 1085–1089.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('JPark202308INTERSPEECH')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2306.00697">arXiv</a><br><div id="JPark202308INTERSPEECH" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">JPark202308INTERSPEECH</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Park, Joonyong and Takamichi, Shinnosuke and Nakamura, Tomohiko and Seki, Kentaro and Xin, Detai and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;How Generative Spoken Language Model Encodes Noisy Speech{: I}nvestigation from Phonetics to Syntactics&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of INTERSPEECH&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1085--1089&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.21437/Interspeech.2023-981&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Shinnosuke Takamichi, Naoko Tanji, Satoru Fukayama, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ICASSP49357.2023.10095569"><span class="nocase">jaCappella corpus: A Japanese a cappella vocal ensemble corpus</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Jun. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura202306ICASSP')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2211.16028">arXiv</a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/jaCappella_sep">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/TomohikoNakamura/asteroid_jaCappella/tree/jaCappella/egs/jaCappella">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/jaCappella_corpus/">dataset <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M448 205.8c-14.8 9.8-31.8 17.7-49.5 24-47 16.8-108.7 26.2-174.5 26.2s-127.6-9.5-174.5-26.2c-17.6-6.3-34.7-14.2-49.5-24V288c0 44.2 100.3 80 224 80s224-35.8 224-80zm0-77.8V80c0-44.2-100.3-80-224-80S0 35.8 0 80v48c0 44.2 100.3 80 224 80s224-35.8 224-80m-49.5 261.8C351.6 406.5 289.9 416 224 416s-127.6-9.5-174.5-26.2c-17.6-6.3-34.7-14.2-49.5-24V432c0 44.2 100.3 80 224 80s224-35.8 224-80v-66.2c-14.8 9.8-31.8 17.7-49.5 24"/></svg></span></a><br><div id="TNakamura202306ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura202306ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Takamichi, Shinnosuke and Tanji, Naoko and Fukayama, Satoru and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{jaCappella} corpus: {A} {Japanese} a cappella vocal ensemble corpus&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP49357.2023.10095569&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Kota Arai, Yutaro Hirao, Takuji Narumi, <ins>Tomohiko Nakamura</ins>, Shinnosuke Takamichi, and Shigeo Yoshida, “<strong><a href="https://doi.org/10.1145/3581641.3584053">TimToShape: Supporting practice of musical instruments by visualizing timbre with 2D shapes based on crossmodal correspondences</a></strong>,” in <em>Proceedings of ACM Conference on Intelligent User Interfaces</em>, Mar. 2023, pp. 850–865.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KArai202303ACMIUI')">bib</a>   <a class="md-button md-button--small" href="https://medium.com/@shigeo.yoshida/musical-instrument-practice-support-system-based-on-crossmodal-correspondences-to-be-presented-at-500a02fd22b0">blog <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24"/></svg></span></a><br><div id="KArai202303ACMIUI" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KArai202303ACMIUI</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Arai, Kota and Hirao, Yutaro and Narumi, Takuji and Nakamura, Tomohiko and Takamichi, Shinnosuke and Yoshida, Shigeo&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{TimToShape: S}upporting Practice of Musical Instruments by Visualizing Timbre with 2D Shapes based on Crossmodal Correspondences&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of ACM Conference on Intelligent User Interfaces&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;850--865&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1145/3581641.3584053&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Futa Nakashima, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Satoru Fukayama, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.23919/APSIPAASC55919.2022.9980158">Hyperbolic timbre embedding for musical instrument sound synthesis based on variational autoencoders</a></strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Nov. 2022, pp. 736–743.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('FNakashima202211APSIPA')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2209.13211">arXiv</a><br><div id="FNakashima202211APSIPA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FNakashima202211APSIPA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakashima, Futa and Nakamura, Tomohiko and Takamune, Norihiro and Fukayama, Satoru and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hyperbolic timbre embedding for musical instrument sound synthesis based on variational autoencoders&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;November&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;736--743&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.23919/APSIPAASC55919.2022.9980158&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yuki Ito, <ins>Tomohiko Nakamura</ins>, Shoichi Koyama, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/IWAENC53105.2022.9914751">Head-related transfer function interpolation from spatially sparse measurements using autoencoder with source position conditioning</a></strong>,” in <em>Proceedings of International Workshop on Acoustic Signal Enhancement</em>, Sep. 2022.<br />
<span style="color: var(--md-code-hl-function-color)">[Finalist of Best Student Paper Award of IWAENC 2022 (Yuki Ito)]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIto2022IWAENC')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2207.10967">arXiv</a>   <a class="md-button md-button--small" href="https://github.com/ikets/HRTFInterpAE_public/blob/main/docs/Ito_IWAENC2022_public.pdf">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://ikets.github.io/HRTFInterpAE_public/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/ikets/HRTFInterpAE_public">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="YIto2022IWAENC" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIto2022IWAENC</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Ito, Yuki and Nakamura, Tomohiko and Koyama, Shoichi and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Workshop on Acoustic Signal Enhancement&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Head-related transfer function interpolation from spatially sparse measurements using autoencoder with source position conditioning&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/IWAENC53105.2022.9914751&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Kazuhide Shigemi, Shoichi Koyama, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/IWAENC53105.2022.9914792">Physics-informed convolutional neural network with bicubic spline interpolation for sound field estimation</a></strong>,” in <em>Proceedings of International Workshop on Acoustic Signal Enhancement</em>, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KShigemi2022IWAENC')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2207.10937">arXiv</a><br><div id="KShigemi2022IWAENC" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KShigemi2022IWAENC</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Shigemi, Kazuhide and Koyama, Shoichi and Nakamura, Tomohiko and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Workshop on Acoustic Signal Enhancement&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Physics-informed convolutional neural network with bicubic spline interpolation for sound field estimation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/IWAENC53105.2022.9914792&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takaaki Saeki, Shinnosuke Takamichi, <ins>Tomohiko Nakamura</ins>, Naoko Tanji, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.21437/Interspeech.2022-298">SelfRemaster: Self-supervised speech restoration with analysis-by-synthesis approach using channel modeling</a></strong>,” in <em>Proceedings of INTERSPEECH</em>, Sep. 2022, pp. 4406–4410.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TSaeki202209INTERSPEECH')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2203.12937">arXiv</a>   <a class="md-button md-button--small" href="https://takaaki-saeki.github.io/ssl_remaster_demo/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a>   <a class="md-button md-button--small" href="https://github.com/Takaaki-Saeki/ssl_speech_restoration">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="TSaeki202209INTERSPEECH" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TSaeki202209INTERSPEECH</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Saeki, Takaaki and Takamichi, Shinnosuke and Nakamura, Tomohiko and Tanji, Naoko and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of INTERSPEECH&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{SelfRemaster: S}elf-supervised speech restoration with analysis-by-synthesis approach using channel modeling&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;4406--4410&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.21437/Interspeech.2022-298&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Masaya Kawamura, <ins>Tomohiko Nakamura</ins>, Daichi Kitamura, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.1109/ICASSP43922.2022.9746399">Differentiable digital signal processing mixture model for synthesis parameter extraction from mixture of harmonic sounds</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2022, pp. 941–945.<br />
<span style="color: var(--md-code-hl-function-color)">[IEEE Signal Processing Society Japan Student Conference Paper Award (Awardee: Masaya Kawamura) / 第16回 IEEE Signal Processing Society Japan Student Conference Paper Award（受賞者：川村 真也）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('MKawamura202205ICASSP')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2202.00200">arXiv</a>   <a class="md-button md-button--small" href="https://sarulab-audio.github.io/DDSP_Mixture_Model/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="MKawamura202205ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MKawamura202205ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Kawamura, Masaya and Nakamura, Tomohiko and Kitamura, Daichi and Saruwatari, Hiroshi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Differentiable digital signal processing mixture model for synthesis parameter extraction from mixture of harmonic sounds&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;941--945&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP43922.2022.9746399&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong>Multichannel audio source separation with independent deeply learned matrix analysis using product of source models</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 1226–1233.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THasumi202112APSIPA')">bib</a>   <a class="md-button md-button--small" href="https://ieeexplore.ieee.org/document/9689636">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2109.00704">arXiv</a><br><div id="THasumi202112APSIPA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THasumi202112APSIPA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hasumi, Takuya and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi and Kitamura, Daichi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Multichannel audio source separation with independent deeply learned matrix analysis using product of source models&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1226--1233&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Sota Misawa, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, Daichi Kitamura, Hiroshi Saruwatari, Masakazu Une, and Shoji Makino, “<strong>Speech enhancement by noise self-supervised rank-constrained spatial covariance matrix estimation via independent deeply learned matrix analysis</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 578–584.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SMisawa202112APSIPA')">bib</a>   <a class="md-button md-button--small" href="https://ieeexplore.ieee.org/document/9689665/">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2109.04658">arXiv</a><br><div id="SMisawa202112APSIPA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SMisawa202112APSIPA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Misawa, Sota and Takamune, Norihiro and Nakamura, Tomohiko and Kitamura, Daichi and Saruwatari, Hiroshi and Une, Masakazu and Makino, Shoji&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Speech enhancement by noise self-supervised rank-constrained spatial covariance matrix estimation via independent deeply learned matrix analysis&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;578--584&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yusaku Mizobuchi, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Hiroshi Saruwatari, Yu Takahashi, and Kazunobu Kondo, “<strong>Prior distribution design for music bleeding-sound reduction based on nonnegative matrix factorization</strong>,” in <em>Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference</em>, Dec. 2021, pp. 651–658.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YMizobuchi202112APSIPA')">bib</a>   <a class="md-button md-button--small" href="https://ieeexplore.ieee.org/document/9689601/">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2109.00237">arXiv</a><br><div id="YMizobuchi202112APSIPA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YMizobuchi202112APSIPA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Mizobuchi, Yusaku and Kitamura, Daichi and Nakamura, Tomohiko and Saruwatari, Hiroshi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Prior distribution design for music bleeding-sound reduction based on nonnegative matrix factorization&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Asia Pacific Signal and Information Processing Association Annual Summit and Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;651--658&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Koichi Saito, <ins>Tomohiko Nakamura</ins>, Kohei Yatabe, Yuma Koizumi, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.23919/EUSIPCO54536.2021.9615941">Sampling-frequency-independent audio source separation using convolution layer based on impulse invariant method</a></strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Aug. 2021, pp. 321–325.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KSaito202108EUSIPCO')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2105.04079">arXiv</a><br><div id="KSaito202108EUSIPCO" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KSaito202108EUSIPCO</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Saito, Koichi and Nakamura, Tomohiko and Yatabe, Kohei and Koizumi, Yuma and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Sampling-frequency-independent audio source separation using convolution layer based on impulse invariant method&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of European Signal Processing Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;321--325&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.23919/EUSIPCO54536.2021.9615941&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Naoki Narisawa, Rintaro Ikeshita, Norihiro Takamune, Daichi Kitamura, <ins>Tomohiko Nakamura</ins>, Hiroshi Saruwatari, and Tomohiro Nakatani, “<strong><a href="https://doi.org/10.23919/eusipco54536.2021.9616300">Independent deeply learned tensor analysis for determined audio source separation</a></strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Aug. 2021, pp. 326–330.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('NNarisawa202108EUSIPCO')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2106.05529">arXiv</a><br><div id="NNarisawa202108EUSIPCO" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NNarisawa202108EUSIPCO</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Narisawa, Naoki and Ikeshita, Rintaro and Takamune, Norihiro and Kitamura, Daichi and Nakamura, Tomohiko and Saruwatari, Hiroshi and Nakatani, Tomohiro&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Independent deeply learned tensor analysis for determined audio source separation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of European Signal Processing Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;326--330&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.23919/eusipco54536.2021.9616300&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takuya Hasumi, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, Hiroshi Saruwatari, Daichi Kitamura, Yu Takahashi, and Kazunobu Kondo, “<strong><a href="https://doi.org/10.23919/eusipco54536.2021.9616245">Empirical bayesian independent deeply learned matrix analysis for multichannel audio source separation</a></strong>,” in <em>Proceedings of European Signal Processing Conference</em>, Aug. 2021, pp. 331–335.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THasumi202108EUSIPCO')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2106.03492">arXiv</a><br><div id="THasumi202108EUSIPCO" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THasumi202108EUSIPCO</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hasumi, Takuya and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi and Kitamura, Daichi and Takahashi, Yu and Kondo, Kazunobu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Empirical bayesian independent deeply learned matrix analysis for multichannel audio source separation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of European Signal Processing Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;331--335&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.23919/eusipco54536.2021.9616245&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Shihori Kozuka, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong>Investigation on wavelet basis function of DNN-based time domain audio source separation inspired by multiresolution analysis</strong>,” in <em>Proceedings of International Congress and Exposition on Noise Control Engineering</em>, Aug. 2020, pp. 4013–4022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKozuka202008Internoise')">bib</a>   <a class="md-button md-button--small" href="https://www.ingentaconnect.com/contentone/ince/incecp/2020/00000261/00000002/art00004">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="SKozuka202008Internoise" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SKozuka202008Internoise</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Kozuka, Shihori and Nakamura, Tomohiko and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Investigation on wavelet basis function of {DNN}-based time domain audio source separation inspired by multiresolution analysis&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Congress and Exposition on Noise Control Engineering&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;4013--4022&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins> and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1109/ICASSP40776.2020.9053934">Time-domain audio source separation based on Wave-U-Net combined with discrete wavelet transform</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2020, pp. 386–390.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura202005ICASSP')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2001.10190">arXiv</a><br><div id="TNakamura202005ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura202005ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Time-domain audio source separation based on {Wave-U-Net} combined with discrete wavelet transform&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;386--390&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP40776.2020.9053934&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/ICASSP.2016.7471723">Shifted and convolutive source-filter non-negative matrix factorization for monaural audio source separation</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Mar. 2016, pp. 489–493.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201603ICASSP')">bib</a><br><div id="TNakamura201603ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201603ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;489--493&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Shifted and convolutive source-filter non-negative matrix factorization for monaural audio source separation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP.2016.7471723&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/ICASSP.2015.7178344">Lp-norm non-negative matrix factorization and its application to singing voice enhancement</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, Apr. 2015, pp. 2115–2119.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201503ICASSP')">bib</a><br><div id="TNakamura201503ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201503ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Lp-norm non-negative matrix factorization and its application to singing voice enhancement&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2015&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;April&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2115--2119&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP.2015.7178344&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Kotaro Shikata, Norihiro Takamune, and Hirokazu Kameoka, “<strong>Harmonic-temporal factor decomposition incorporating music prior information for informed monaural source separation</strong>,” in <em>Proceedings of International Society for Music Information Retrieval Conference</em>, Oct. 2014, pp. 623–628.<br />
<span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Tateishi Science and Technology Foundation]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201504ISMIR')">bib</a>   <a class="md-button md-button--small" href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T112_135_Paper.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/HTFD">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="TNakamura201504ISMIR" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201504ISMIR</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Shikata, Kotaro and Takamune, Norihiro and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Society for Music Information Retrieval Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;October&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;623--628&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Harmonic-temporal factor decomposition incorporating music prior information for informed monaural source separation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Fast signal reconstruction from magnitude spectrogram of continuous wavelet transform based on spectrogram consistency</strong>,” in <em>Proceedings of International Conference on Digital Audio Effects</em>, Sep. 2014, pp. 129–135.<br />
<span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Hara Research Foundation]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201409DAFx')">bib</a>   <a class="md-button md-button--small" href="http://www.dafx14.fau.de/papers/dafx14_tomohiko_nakamura_fast_signal_reconstructio.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/fastCWT/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="TNakamura201409DAFx" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201409DAFx</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Conference on Digital Audio Effects&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;129--135&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Fast signal reconstruction from magnitude spectrogram of continuous wavelet transform based on spectrogram consistency&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takuya Higuchi, Hirofumi Takeda, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>A unified approach for underdetermined blind signal separation and source activity detection by multichannel factorial hidden Markov models</strong>,” in <em>Proceedings of INTERSPEECH</em>, Sep. 2014, pp. 850–854.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THiguchi201409INTERSPEECH')">bib</a>   <a class="md-button md-button--small" href="https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0850.pdf">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="THiguchi201409INTERSPEECH" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THiguchi201409INTERSPEECH</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Higuchi, Takuya and Takeda, Hirofumi and Nakamura, Tomohiko and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of INTERSPEECH&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;850--854&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;A unified approach for underdetermined blind signal separation and source activity detection by multichannel factorial hidden {Markov} models&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Hirokazu Kameoka, Kazuyoshi Yoshii, and Masataka Goto, “<strong><a href="https://doi.org/10.1109/ICASSP.2014.6855052">Timbre replacement of harmonic and drum components for music audio signals</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2014, pp. 7520–7524.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201405ICASSP')">bib</a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/drum_timbre_replacement/">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="TNakamura201405ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201405ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Kameoka, Hirokazu and Yoshii, Kazuyoshi and Goto, Masataka&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;7520--7524&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Timbre replacement of harmonic and drum components for music audio signals&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP.2014.6855052&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Takuya Higuchi, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong><a href="https://doi.org/10.1109/ICASSP.2014.6854189">Underdetermined blind separation and tracking of moving sources based on DOA-HMM</a></strong>,” in <em>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, May 2014, pp. 3215–3219.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THiguchi201405ICASSP')">bib</a><br><div id="THiguchi201405ICASSP" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THiguchi201405ICASSP</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Higuchi, Takuya and Takamune, Norihiro and Nakamura, Tomohiko and Kameoka, Hirokazu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;3215--3219&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Underdetermined blind separation and tracking of moving sources based on DOA-HMM&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ICASSP.2014.6854189&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Acoustic score following to musical performance with errors and arbitrary repeats and skips for automatic accompaniment</strong>,” in <em>Proceedings of Sound and Music Computing Conference</em>, Aug. 2013, pp. 299–304.<br />
<span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Telecommunications Advancement Foundation]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201308SMC')">bib</a>   <a class="md-button md-button--small" href="http://smcnetwork.org/node/1754">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a>   <a class="md-button md-button--small" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/demo/automatic_accompaniment">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="TNakamura201308SMC" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201308SMC</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Nakamura, Eita and Sagayama, Shigeki&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Sound and Music Computing Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;299--304&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Acoustic score following to musical performance with errors and arbitrary repeats and skips for automatic accompaniment&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2013&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Masahiro Nakano, Jonathan Le Roux, Hirokazu Kameoka, <ins>Tomohiko Nakamura</ins>, Nobutaka Ono, and Shigeki Sagayama, “<strong><a href="https://doi.org/10.1109/ASPAA.2011.6082324">Bayesian nonparametric spectrogram modeling based on infinite factorial infinite hidden Markov model</a></strong>,” in <em>Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, Oct. 2011, pp. 325–328.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('MNakano201110WASPAA')">bib</a><br><div id="MNakano201110WASPAA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MNakano201110WASPAA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakano, Masahiro and {Le Roux}, Jonathan and Kameoka, Hirokazu and Nakamura, Tomohiko and Ono, Nobutaka and Sagayama, Shigeki&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;October&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;325--328&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Bayesian nonparametric spectrogram modeling based on infinite factorial infinite hidden {Markov} model&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2011&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/ASPAA.2011.6082324&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>Tomohiko Nakamura</ins>, Shinji Hara, and Yutaka Hori, “<strong>Local stability analysis for a class of quorum-sensing networks with cyclic gene regulatory networks</strong>,” in <em>Proceedings of SICE Annual Conference</em>, Sep. 2011, pp. 2111–2116.<br />
<span style="color: var(--md-code-hl-function-color)">[SICE Annual Conference 2011 International Award and Finalist of Young Author's Award]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201109SICEAC')">bib</a>   <a class="md-button md-button--small" href="https://ieeexplore.ieee.org/document/6060320">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="TNakamura201109SICEAC" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201109SICEAC</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko and Hara, Shinji and Hori, Yutaka&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of SICE Annual Conference&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Local Stability Analysis for a class of Quorum-Sensing Networks with Cyclic Gene Regulatory Networks&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2011&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2111--2116&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
</ol>
<h3 id="presentation">Presentation<a class="headerlink" href="#presentation" title="Permanent link">&para;</a></h3>
<ol>
<li>Yuto Ishikawa, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, and Hiroshi Saruwatari, “<strong><a href="https://doi.org/10.1121/10.0037481">Hearing-aids system using distributed assistive device and blind speech extraction method under diffuse noise</a></strong>,” in <em>Proceedings of International Congress on Acoustics</em>, May 2025. (Abstract only)<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa202505ICA')">bib</a><br><div id="YIshikawa202505ICA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa202505ICA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Ishikawa, Yuto and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of International Congress on Acoustics&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Hearing-Aids System Using Distributed Assistive Device and Blind Speech Extraction Method under Diffuse Noise&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">note</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;(Abstract only)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1121/10.0037481&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yuta Amezawa, <ins>Tomohiko Nakamura</ins>, Satoru Fukayama, Takahiro Shiina, and Takahiko Uchide, “<strong>Automatic extraction and peak arrival estimation of later phase in S coda</strong>,” in <em>International Joint Workshop on Slow-to-Fast Earthquakes 2024</em>, Sep. 2024. (Abstract only)<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YAmezawa202409IJWStFE')">bib</a><br><div id="YAmezawa202409IJWStFE" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YAmezawa202409IJWStFE</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Amezawa, Yuta and Nakamura, Tomohiko and Fukayama, Satoru and Shiina, Takahiro and Uchide, Takahiko&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;International Joint Workshop on Slow-to-Fast Earthquakes 2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Automatic extraction and peak arrival estimation of later phase in {S} coda&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">note</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;(Abstract only)&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Yuto Ishikawa, <ins>Tomohiko Nakamura</ins>, Norihiro Takamune, and Hiroshi Saruwatari, “<strong>Real-time framework for speech extraction based on independent low-rank matrix analysis with spatial regularization and rank-constrained spatial covariance matrix estimation</strong>,” in <em>Workshop on Spoken Dialogue Systems for Cybernetic Avatars (SDS4CA)</em>, Sep. 2024. (Presentation only)<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa202409SDS4CA')">bib</a><br><div id="YIshikawa202409SDS4CA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa202409SDS4CA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Ishikawa, Yuto and Nakamura, Tomohiko and Takamune, Norihiro and Saruwatari, Hiroshi&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Real-Time Framework for Speech Extraction Based on Independent Low-Rank Matrix Analysis with Spatial Regularization and Rank-Constrained Spatial Covariance Matrix Estimation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Workshop on Spoken Dialogue Systems for Cybernetic Avatars (SDS4CA)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">note</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;(Presentation only)&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Shigeki Sagayama, <ins>Tomohiko Nakamura</ins>, Eita Nakamura, Yasuyuki Saito, Hirokazu Kameoka, and Nobutaka Ono, “<strong><a href="https://doi.org/10.1121/1.4904932">Automatic music accompaniment allowing errors and arbitrary repeats and jumps</a></strong>,” in <em>Proceedings of Meetings on Acoustics, Acoustic Society of America</em>, May 2014, vol. 21, 35003.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SSagayama201405ASA')">bib</a><br><div id="SSagayama201405ASA" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SSagayama201405ASA</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Sagayama, Shigeki and Nakamura, Tomohiko and Nakamura, Eita and Saito, Yasuyuki and Kameoka, Hirokazu and Ono, Nobutaka&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Proceedings of Meetings on Acoustics, Acoustic Society of America&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Automatic music accompaniment allowing errors and arbitrary repeats and jumps&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;21, 035003&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1121/1.4904932&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
</ol>
<h2 id="domestic-conferences">Domestic Conferences / 国内会議<a class="headerlink" href="#domestic-conferences" title="Permanent link">&para;</a></h2>
<ol>
<li>中田 亘, 山内 一輝, 関 健太郎, 齋藤 佑樹, 猿渡 洋, <ins>中村 友彦</ins>, 坂東 宜昭,  深山 覚, “<strong>BigGSE: 自己教師ありモデル特徴量空間でのFlow matchingに基づく生成的音声強調</strong>,” <em>日本音響学会 2025年秋期研究発表会</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('WNakata2025ASJ09_ja')">bib</a><br><div id="WNakata2025ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">WNakata2025ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中田 亘} and {山内 一輝} and {関 健太郎} and {齋藤 佑樹} and {猿渡 洋} and {中村 友彦} and {坂東 宜昭} and {深山 覚}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2025年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;BigGSE: 自己教師ありモデル特徴量空間でのFlow matchingに基づく生成的音声強調&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>竹本 健悟, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>楽譜情報を用いた混合Differentiable digital signal Processingモデルによる合成パラメータ推定手法の検討</strong>,” <em>日本音響学会 2025年秋期研究発表会</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KTakemoto2025ASJ09_ja')">bib</a><br><div id="KTakemoto2025ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KTakemoto2025ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{竹本 健悟} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2025年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;楽譜情報を用いた混合Differentiable Digital Signal Processingモデルによる合成パラメータ推定手法の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>内田 蓮, 矢田部 浩平,  <ins>中村 友彦</ins>, “<strong>完全再構成性を保証したEnd-to-End音声強調の実験的評価</strong>,” <em>日本音響学会 2025年秋期研究発表会</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RUchida2025ASJ09_ja')">bib</a><br><div id="RUchida2025ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RUchida2025ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{内田 蓮} and {矢田部 浩平} and {中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2025年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;完全再構成性を保証したEnd-to-End音声強調の実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>和田 仰, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>双曲埋め込みを用いたエフェクトチェイン識別モデルの実験的評価</strong>,” <em>日本音響学会 2025年秋期研究発表会</em>, Sep. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('AWada2025ASJ09_ja')">bib</a><br><div id="AWada2025ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AWada2025ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{和田 仰} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2025年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;双曲埋め込みを用いたエフェクトチェイン識別モデルの実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>高道 慎之介, <ins>中村 友彦</ins>, 須田 仁志, 深山 覚,  緒方 淳, “<strong>MangaVox：ボイスコミックの計算機理解に向けたマルチモーダル演技音声データセット</strong>,” <em>画像の認識・理解シンポジウム</em>, Aug. 2025. (First, second, and third authors contributed equally.)<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('STakamichi2025MIRU08_ja')">bib</a><br><div id="STakamichi2025MIRU08_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">STakamichi2025MIRU08_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{高道 慎之介} and {中村 友彦} and {須田 仁志} and {深山 覚} and {緒方 淳}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;画像の認識・理解シンポジウム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{MangaVox}：ボイスコミックの計算機理解に向けたマルチモーダル演技音声データセット&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">note</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;(First, second, and third authors contributed equally.)&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>越野 颯太, 上治 正太郎, 高道 慎之介,  <ins>中村 友彦</ins>, “<strong>漫画画像理解性能が漫画音声合成の品質に与える影響の調査</strong>,” <em>コミック工学研究会</em>, Jul. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKoshino2025SIGCC07_ja')">bib</a><br><div id="SKoshino2025SIGCC07_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SKoshino2025SIGCC07_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{越野 颯太} and {上治 正太郎} and {高道 慎之介} and {中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;コミック工学研究会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;漫画画像理解性能が漫画音声合成の品質に与える影響の調査&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;July&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>和田 仰, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>順序を考慮したオーディオエフェクトチェインの推定に対する双曲埋め込み</strong>,” <em>情報処理学会研究報告</em>, vol. 2025–MUS–143, Jun. 2025.<br />
<span style="color: var(--md-code-hl-function-color)">[2025年度 音学シンポジウム学生優秀発表賞（受賞者：和田 仰）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('AWada2025SIGMUS03_ja')">bib</a><br><div id="AWada2025SIGMUS03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AWada2025SIGMUS03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{和田 仰} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;順序を考慮したオーディオエフェクトチェインの推定に対する双曲埋め込み&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025-MUS-143&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;27&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>須田 仁志, 小口 純矢, 吉田 隼輔, <ins>中村 友彦</ins>, 深山 覚,  緒方 淳, “<strong>アイドルグループ楽曲スタイルにもとづく音楽コーパス</strong>,” <em>情報処理学会研究報告</em>, vol. 2025–MUS–142, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HSuda2025SIGMUS03_ja')">bib</a>   <a class="md-button md-button--small" href="https://www.youtube.com/watch?v=JnQyioShrQ4">demo <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M468 7c7.6 6.1 12 15.3 12 25v304c0 44.2-43 80-96 80s-96-35.8-96-80 43-80 96-80c11.2 0 22 1.6 32 4.6V143.9l-224 49.8V400c0 44.2-43 80-96 80S0 444.2 0 400s43-80 96-80c11.2 0 22 1.6 32 4.6V96c0-15 10.4-28 25.1-31.2l288-64c9.5-2.1 19.4.2 27 6.3z"/></svg></span></a><br><div id="HSuda2025SIGMUS03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HSuda2025SIGMUS03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{須田 仁志} and {小口 純矢} and {吉田 隼輔} and {中村 友彦} and {深山 覚} and {緒方 淳}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;アイドルグループ楽曲スタイルにもとづく音楽コーパス&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025-MUS-142&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;45&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>信川 凜佳, 北村 優輝士, <ins>中村 友彦</ins>, 高道 慎之介,  猿渡 洋, “<strong>変分オートエンコーダによるドラムからボーカルパーカッションへの楽器音変換と評価</strong>,” <em>情報処理学会研究報告</em>, vol. 2025–MUS–142, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RNobukawa2025SIGMUS03_ja')">bib</a><br><div id="RNobukawa2025SIGMUS03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RNobukawa2025SIGMUS03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{信川 凜佳} and {北村 優輝士} and {中村 友彦} and {高道 慎之介} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;変分オートエンコーダによるドラムからボーカルパーカッションへの楽器音変換と評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025-MUS-142&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;12&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>Local equivariance Errorに基づくサンプリング周波数非依存性評価指標の提案と分析</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 124, pp. 193–198, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2025EA03_ja')">bib</a><br><div id="KImamura2025EA03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura2025EA03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{今村 奏海} and {中村 友彦} and {高宗 典玄} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Local Equivariance Errorに基づくサンプリング周波数非依存性評価指標の提案と分析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;124&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">no</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;389, EA2024-108&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;193--198&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, チョイ クワンヒー, 北條 圭悟, 坂東 宜昭, 深山 覚,  渡部 晋治, “<strong>独立成分分析を利用した離散音声トークン抽出法</strong>,” <em>情報処理学会研究報告</em>, vol. 2025–SLP–155, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2025SIGSLP03_ja')">bib</a><br><div id="TNakamura2025SIGSLP03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2025SIGSLP03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {チョイ クワンヒー} and {北條 圭悟} and {坂東 宜昭} and {深山 覚} and {渡部 晋治}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;独立成分分析を利用した離散音声トークン抽出法&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025-SLP-155&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;3&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>高道 慎之介, 和田 仰, 小川 諒, 山岡 洸瑛, 中田 亘, 淺井 航平, 関 健太郎, 岡本 悠希, 齋藤 佑樹, 小川 哲司, 猿渡 洋, <ins>中村 友彦</ins>,  深山 覚, “<strong>音声・音響・音楽を扱うオープン基盤モデルの構築に向けたデータセット策定</strong>,” <em>言語処理学会年次大会</em>, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('STakamichi2025NLP03_ja')">bib</a>   <a class="md-button md-button--small" href="https://github.com/sarulab-speech/audio-foundation-model-dataset">code <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg></span></a><br><div id="STakamichi2025NLP03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">STakamichi2025NLP03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{高道 慎之介} and {和田 仰} and {小川 諒} and {山岡 洸瑛} and {中田 亘} and {淺井 航平} and {関 健太郎} and {岡本 悠希} and {齋藤 佑樹} and {小川 哲司} and {猿渡 洋} and {中村 友彦} and {深山 覚}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;言語処理学会年次大会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音声・音響・音楽を扱うオープン基盤モデルの構築に向けたデータセット策定&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>瀧澤 大吾, <ins>中村 友彦</ins>, 須田 仁志,  深山 覚, “<strong>大規模自己教師あり学習モデルによる日本語方言の音声認識</strong>,” <em>日本音響学会 2025年春期研究発表会</em>, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('DTakizawa2024ASP03_ja')">bib</a><br><div id="DTakizawa2024ASP03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DTakizawa2024ASP03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{瀧澤 大吾} and {中村 友彦} and {須田 仁志} and {深山 覚}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2025年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;大規模自己教師あり学習モデルによる日本語方言の音声認識&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>内田 蓮, 矢田部 浩平,  <ins>中村 友彦</ins>, “<strong>直交畳み込み層によるConv-TasNetの完全再構成性の保証</strong>,” <em>日本音響学会 2025年春期研究発表会</em>, Mar. 2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RUchida2024ASP03_ja')">bib</a><br><div id="RUchida2024ASP03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RUchida2024ASP03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{内田 蓮} and {矢田部 浩平} and {中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2025年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;直交畳み込み層によるConv-TasNetの完全再構成性の保証&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>Local equivariance errorに基づくサンプリング周波数非依存性評価指標の検討</strong>,” <em>日本音響学会 2024年秋期研究発表会</em>, pp. 241–244, Sep. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2024ASJ09_ja')">bib</a><br><div id="KImamura2024ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura2024ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{今村 奏海} and {中村 友彦} and {高宗 典玄} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2024年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Local equivariance errorに基づくサンプリング周波数非依存性評価指標の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;241--244&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>石川 悠人, 武 伯寒, <ins>中村 友彦</ins>, 高宗 典玄, 齋藤 佑樹, 高道 慎之介,  猿渡 洋, “<strong>人間とアバターとの対話システムにおける拡散性雑音下リアルタイム推定雑音を用いたLombard効果模擬音声合成のための検討</strong>,” <em>日本音響学会 2024年秋期研究発表会</em>, pp. 141–144, Sep. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa2024ASJ09_ja')">bib</a><br><div id="YIshikawa2024ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa2024ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{石川 悠人} and {武 伯寒} and {中村 友彦} and {高宗 典玄} and {齋藤 佑樹} and {高道 慎之介} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2024年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;人間とアバターとの対話システムにおける拡散性雑音下リアルタイム推定雑音を用いたLombard効果模擬音声合成のための検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;141--144&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>非整数ストライド処理アルゴリズムを用いたサンプリング周波数非依存畳み込み層による楽音分離の実験的評価</strong>,” <em>情報処理学会研究報告</em>, vol. 2024–MUS–140, May 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2024SIGMUS05_ja')">bib</a><br><div id="KImamura2024SIGMUS05_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura2024SIGMUS05_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{今村 奏海} and {中村 友彦} and {高宗 典玄} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;非整数ストライド処理アルゴリズムを用いたサンプリング周波数非依存畳み込み層による楽音分離の実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024-MUS-140&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;67&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>サンプリング周波数に非依存な深層学習を用いた音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 124, pp. 7–13, May 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('Nakamura2024EA05_ja')">bib</a><br><div id="Nakamura2024EA05_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Nakamura2024EA05_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;サンプリング周波数に非依存な深層学習を用いた音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;124&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">no</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;42, EA2024-2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;7--13&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>須田 仁志, <ins>中村 友彦</ins>, 深山 覚,  緒方 淳, “<strong>FruitsMusic: 音楽情報処理のためのアイドルユニット楽曲コーパス</strong>,” <em>情報処理学会研究報告</em>, vol. 2024–MUS–139, Mar. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HSuda2024SIGMUS03_ja')">bib</a><br><div id="HSuda2024SIGMUS03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HSuda2024SIGMUS03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{須田 仁志} and {中村 友彦} and {深山 覚} and {緒方 淳}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;FruitsMusic: 音楽情報処理のためのアイドルユニット楽曲コーパス&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024-MUS-139&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;13&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>兵藤 弘明, 高道 慎之介, <ins>中村 友彦</ins>, 小口 純矢,  猿渡 洋, “<strong>歌唱者間相互作用を再現するDNN重唱歌声合成の検討</strong>,” <em>情報処理学会研究報告</em>, vol. 2024–MUS–139, Mar. 2024.<br />
<span style="color: var(--md-code-hl-function-color)">[情報処理学会 第139回音楽情報科学研究会 学生奨励賞 Best Research部門（受賞者：兵藤 弘明）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HHyodo2024SIGMUS03_ja')">bib</a><br><div id="HHyodo2024SIGMUS03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HHyodo2024SIGMUS03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{兵藤 弘明} and {高道 慎之介} and {中村 友彦} and {小口 純矢} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;歌唱者間相互作用を再現するDNN重唱歌声合成の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024-MUS-139&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;3&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>王 檬, 赤石 夏輝, <ins>中村 友彦</ins>, 山田 宏樹,  矢田部 浩平, “<strong>コンプレッサー処理された信号の復元に関する検討</strong>,” <em>日本音響学会 2024年春期研究発表会</em>, pp. 205–206, Mar. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('Mwang2024ASJ03_ja')">bib</a><br><div id="Mwang2024ASJ03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Mwang2024ASJ03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{王 檬} and {赤石 夏輝} and {中村 友彦} and {山田 宏樹} and {矢田部 浩平}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;コンプレッサー処理された信号の復元に関する検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2024年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;205--206&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>石川 悠人, 大久保 拓哉, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>独立低ランク行列分析における反復射影法の高速化・安定化アルゴリズム</strong>,” <em>日本音響学会 2024年春期研究発表会</em>, pp. 87–90, Mar. 2024.<br />
<span style="color: var(--md-code-hl-function-color)">[日本音響学会 第28回学生優秀発表賞（受賞者：石川 悠人）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa2024ASJ03_ja')">bib</a><br><div id="YIshikawa2024ASJ03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa2024ASJ03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{石川 悠人} and {大久保 拓哉} and {高宗 典玄} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;独立低ランク行列分析における反復射影法の高速化・安定化アルゴリズム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2024年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;87--90&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>石川 悠人, 大久保 拓哉, 高宗 典玄, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>空間正則化付き独立低ランク行列分析におけるベクトルワイズ座標降下法の高速化・安定化アルゴリズム</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 123, pp. 43–50, Feb. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa2024EA02_ja')">bib</a><br><div id="YIshikawa2024EA02_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa2024EA02_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{石川 悠人} and {大久保 拓哉} and {高宗 典玄} and {中村 友彦} and {北村 大地} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;空間正則化付き独立低ランク行列分析におけるベクトルワイズ座標降下法の高速化・安定化アルゴリズム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;February&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;123&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;401, EA2023-68&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;43--50&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>石川 悠人, 小中 康平, <ins>中村 友彦</ins>, 高宗 典玄,  猿渡 洋, “<strong>目的音声の方位を用いた空間正則化付き独立低ランク行列分析とランク制約付き空間共分散行列推定法による拡散性雑音下リアルタイム音声強調</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 137–140, Sep. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIshikawa2023ASJ09_ja')">bib</a><br><div id="YIshikawa2023ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIshikawa2023ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{石川 悠人} and {小中 康平} and {中村 友彦} and {高宗 典玄} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;目的音声の方位を用いた空間正則化付き独立低ランク行列分析とランク制約付き空間共分散行列推定法による拡散性雑音下リアルタイム音声強調&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2023年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;137--140&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>今村 奏海, <ins>中村 友彦</ins>, 高宗 典玄, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存畳み込み層における非整数ストライド処理アルゴリズム</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 157–160, Sep. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2023ASJ09_ja')">bib</a><br><div id="KImamura2023ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura2023ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{今村 奏海} and {中村 友彦} and {高宗 典玄} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;サンプリング周波数非依存畳み込み層における非整数ストライド処理アルゴリズム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2023年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;157--160&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  矢田部 浩平, “<strong>Universal Sound Separationへのサンプリング周波数非依存畳み込み層の適用</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 161–164, Sep. 2023.<br />
<span style="color: var(--md-code-hl-function-color)">[The Awaya Kiyoshi Research Award from ASJ / 日本音響学会 粟屋潔学術奨励賞]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2023ASJ09_ja')">bib</a><br><div id="TNakamura2023ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2023ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {矢田部 浩平}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{Universal Sound Separation}へのサンプリング周波数非依存畳み込み層の適用&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2023年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;161--164&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>王 檬, <ins>中村 友彦</ins>, 山田 宏樹,  矢田部 浩平, “<strong>微分可能なコンプレッサーのパラメータ推定に関する検討</strong>,” <em>日本音響学会 2023年秋期研究発表会</em>, pp. 259–260, Sep. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('MWang2023ASJ09_ja')">bib</a><br><div id="MWang2023ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MWang2023ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{王 檬} and {中村 友彦} and {山田 宏樹} and {矢田部 浩平}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;微分可能なコンプレッサーのパラメータ推定に関する検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2023年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;259--260&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 高道 慎之介, 丹治 尚子, 深山 覚,  猿渡 洋, “<strong>jaCappellaコーパスv2：重唱分離・合成のための日本語アカペラ歌唱コーパスの拡張</strong>,” <em>情報処理学会研究報告</em>, vol. 2023–MUS–138, Aug. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2023SIGMUS08_ja')">bib</a><br><div id="TNakamura2023SIGMUS08_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2023SIGMUS08_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {高道 慎之介} and {丹治 尚子} and {深山 覚} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;jaCappellaコーパスv2：重唱分離・合成のための日本語アカペラ歌唱コーパスの拡張&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023-MUS-138&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;13&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>朴 浚鎔, 高道 慎之介, <ins>中村 友彦</ins>, 関 健太郎, 辛 徳泰,  猿渡 洋, “<strong>Generative spoken language Modelを用いた劣化雑音音声の分析と他言語への適用</strong>,” <em>日本音響学会 2023年春期研究発表会</em>, pp. 677–680, Mar. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('JPark2023ASJ03_ja')">bib</a><br><div id="JPark2023ASJ03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">JPark2023ASJ03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{朴 浚鎔} and {高道 慎之介} and {中村 友彦} and {関 健太郎} and {辛 徳泰} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Generative Spoken Language Modelを用いた劣化雑音音声の分析と他言語への適用&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2023年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;677--680&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>三村 正人, 井上 昂治, 河原 達也, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>実環境下日本語話し言葉音声コーパスの構築と音声認識ベンチマーク</strong>,” <em>情報処理学会研究報告</em>, vol. 2023–SLP–146, pp. 1–6, Feb. 2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('MMimura2023SIGSP03_ja')">bib</a><br><div id="MMimura2023SIGSP03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MMimura2023SIGSP03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{三村 正人} and {井上 昂治} and {河原 達也} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;実環境下日本語話し言葉音声コーパスの構築と音声認識ベンチマーク&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;February&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023-SLP-146&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;12&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--6&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 高道 慎之介, 丹治 尚子, 深山 覚,  猿渡 洋, “<strong>jaCappellaコーパス:重唱分離・合成に向けた日本語アカペラ歌唱コーパス</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 1377–1378, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2022ASJ09_ja')">bib</a><br><div id="TNakamura2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {高道 慎之介} and {丹治 尚子} and {深山 覚} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;jaCappellaコーパス:重唱分離・合成に向けた日本語アカペラ歌唱コーパス&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1377--1378&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>溝渕 悠朔, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>時間チャネル非負値行列因子分解を用いた被り音抑圧における初期値頑健性の比較</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 351–354, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YMizobuchi2022ASJ09_ja')">bib</a><br><div id="YMizobuchi2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YMizobuchi2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{溝渕 悠朔} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;時間チャネル非負値行列因子分解を用いた被り音抑圧における初期値頑健性の比較&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;351--354&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>川村 真也, <ins>中村 友彦</ins>, 高宗 典玄, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>混合Differentiable digital signal Processingモデルによる合成パラメータ抽出のためのラウドネスの時間変動に基づくロス関数の設計</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 183–186, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('MKawamura2022ASJ09_ja')">bib</a><br><div id="MKawamura2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MKawamura2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{川村 真也} and {中村 友彦} and {高宗 典玄} and {北村 大地} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;混合Differentiable Digital Signal Processingモデルによる合成パラメータ抽出のためのラウドネスの時間変動に基づくロス関数の設計&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;183--186&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>伊藤 悠貴, <ins>中村 友彦</ins>, 小山 翔一,  猿渡 洋, “<strong>音源位置で条件付けた自己符号化器を用いた少数測定データからの頭部伝達関数補間</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 501–504, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIto2022ASJ09_ja')">bib</a><br><div id="YIto2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIto2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{伊藤 悠貴} and {中村 友彦} and {小山 翔一} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音源位置で条件付けた自己符号化器を用いた少数測定データからの頭部伝達関数補間&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;501--504&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>今村 奏海, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存畳み込み層のための時間領域ニューラルアナログフィルタ</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 187–190, Sep. 2022.<br />
<span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Kanami Imamura) / 日本音響学会 第25回学生優秀発表賞（受賞者：今村 奏海）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KImamura2022ASJ09_ja')">bib</a><br><div id="KImamura2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KImamura2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{今村 奏海} and {中村 友彦} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;サンプリング周波数非依存畳み込み層のための時間領域ニューラルアナログフィルタ&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;187--190&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>重見 和秀, 小山 翔一, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>スプライン補間に基づく音場表現を用いたPhysics-informed neural Networksによる音場推定 －散乱体を含む領域に関する検証－</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 239–242, Sep. 2022.<br />
<span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Kazuhide Shigemi) / 日本音響学会 第25回学生優秀発表賞（受賞者：重見 和秀）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KShigemi2022ASJ09_ja')">bib</a><br><div id="KShigemi2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KShigemi2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{重見 和秀} and {小山 翔一} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;スプライン補間に基づく音場表現を用いたPhysics-Informed Neural Networksによる音場推定 －散乱体を含む領域に関する検証－&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;239--242&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>中島 風太, <ins>中村 友彦</ins>, 高宗 典玄, 深山 覚,  猿渡 洋, “<strong>楽音合成のためのGauss混合変分自己符号化器への定曲率非Euclid空間の導入と実験的比較</strong>,” <em>日本音響学会 2022年秋期研究発表会</em>, pp. 327–330, Sep. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('FNakashima2022ASJ09_ja')">bib</a><br><div id="FNakashima2022ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FNakashima2022ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中島 風太} and {中村 友彦} and {高宗 典玄} and {深山 覚} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;楽音合成のためのGauss混合変分自己符号化器への定曲率非Euclid空間の導入と実験的比較&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年秋期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;327--330&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>中島 風大, <ins>中村 友彦</ins>, 高宗 典玄, 深山 覚,  猿渡 洋, “<strong>双曲空間への音色埋め込みを用いたガウス混合変分自己符号化器による楽音合成の検討</strong>,” <em>情報処理学会研究報告</em>, vol. 2022–MUS–134, no. 62, Jun. 2022.<br />
<span style="color: var(--md-code-hl-function-color)">[2022 Otogaku Symposium Best Student Presentation Award (Awardee: Futa Nakashima) / 2022年度 音学シンポジウム学生優秀発表賞（受賞者：中島 風大）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('FNakashima2022MUS06_ja')">bib</a><br><div id="FNakashima2022MUS06_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FNakashima2022MUS06_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中島 風大} and {中村 友彦} and {高宗 典玄} and {深山 覚} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;双曲空間への音色埋め込みを用いたガウス混合変分自己符号化器による楽音合成の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022-MUS-134, no. 62&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>佐伯 高明, 高道 慎之介, <ins>中村 友彦</ins>, 丹治 尚子,  猿渡 洋, “<strong>ソース・フィルタ・チャネル分解に基づく自己教師ありニューラル音声復元</strong>,” <em>情報処理学会研究報告</em>, vol. 2022–SLP–140, no. 41, Mar. 2022.<br />
<span style="color: var(--md-code-hl-function-color)">[IPSJ Yamashita SIG Research Award (Awardee: Takaaki Saeki) / 情報処理学会 2022年度山下記念研究賞（受賞者：佐伯 高明）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TSaeki202203SIGSLP_ja')">bib</a><br><div id="TSaeki202203SIGSLP_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TSaeki202203SIGSLP_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{佐伯 高明} and {高道 慎之介} and {中村 友彦} and {丹治 尚子} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;ソース・フィルタ・チャネル分解に基づく自己教師ありニューラル音声復元&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022-SLP-140, no. 41&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>伊藤 悠貴, <ins>中村 友彦</ins>, 小山 翔一,  猿渡 洋, “<strong>球波動関数展開を用いた深層学習による少数測定データからの頭部伝達関数補間</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 121, pp. 163–170, Mar. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YIto202203IEICETechRep_ja')">bib</a><br><div id="YIto202203IEICETechRep_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YIto202203IEICETechRep_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{伊藤 悠貴} and {中村 友彦} and {小山 翔一} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;球波動関数展開を用いた深層学習による少数測定データからの頭部伝達関数補間&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;121&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;383, EA2021-90&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;163--170&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>重見 和秀, 小山 翔一, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>差分近似型Helmholtz方程式に基づく損失関数を用いた深層学習による少数観測点からの音場推定</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 121, pp. 132–139, Mar. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KShigemi202203IEICETechRep_ja')">bib</a><br><div id="KShigemi202203IEICETechRep_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KShigemi202203IEICETechRep_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{重見 和秀} and {小山 翔一} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;差分近似型{Helmholtz}方程式に基づく損失関数を用いた深層学習による少数観測点からの音場推定&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;121&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;383, EA2021-85&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;132--139&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>ニューラルアナログフィルタを用いたサンプリング周波数非依存畳み込み層とモノラル音源分離への適用</strong>,” <em>日本音響学会 2022年春期研究発表会</em>, pp. 181–184, Mar. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2022ASJ03_ja')">bib</a><br><div id="TNakamura2022ASJ03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2022ASJ03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;ニューラルアナログフィルタを用いたサンプリング周波数非依存畳み込み層とモノラル音源分離への適用&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;181--184&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>川村 真也, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>混合Differentiable DSP モデルによる混合楽器音からの合成パラメータ抽出の実験的評価</strong>,” <em>日本音響学会 2022年春期研究発表会</em>, pp. 177–180, Mar. 2022.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKawamura2022ASJ03_ja')">bib</a><br><div id="SKawamura2022ASJ03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SKawamura2022ASJ03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{川村 真也} and {中村 友彦} and {北村 大地} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;混合Differentiable DSP モデルによる混合楽器音からの合成パラメータ抽出の実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2022年春期研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2022&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;177--180&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>渡辺 瑠伊, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>深層学習に基づく周波数帯域予測による高速音源分離法の実験的評価</strong>,” <em>第24回 日本音響学会関西支部 若手研究者交流研究発表会</em>, p. 15, Dec. 2021.<br />
<span style="color: var(--md-code-hl-function-color)">[日本音響学会 第24回関西支部若手研究者交流研究発表会 奨励賞（受賞者：渡辺 瑠伊）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RWatanabe2021ASJKansai12_ja')">bib</a><br><div id="RWatanabe2021ASJKansai12_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RWatanabe2021ASJKansai12_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{渡辺 瑠伊} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;深層学習に基づく周波数帯域予測による高速音源分離法の実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;第24回 日本音響学会関西支部 若手研究者交流研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;15&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;December&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>溝渕 悠朔, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>非負値行列因子分解を用いた被り音の抑圧</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–132, no. 24, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('YMizobuchi2021MUS09_ja')">bib</a><br><div id="YMizobuchi2021MUS09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">YMizobuchi2021MUS09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{溝渕 悠朔} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;非負値行列因子分解を用いた被り音の抑圧&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021-MUS-132, no. 24&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>川村 真也, <ins>中村 友彦</ins>, 北村 大地, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>楽譜情報を援用した音楽音響信号に対する混合Differentiable DSPモデルの合成パラメータ推定</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–132, no. 22, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKawamura2021MUS09_ja')">bib</a><br><div id="SKawamura2021MUS09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SKawamura2021MUS09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{川村 真也} and {中村 友彦} and {北村 大地} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;楽譜情報を援用した音楽音響信号に対する混合Differentiable DSPモデルの合成パラメータ推定&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021-MUS-132, no. 22&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>渡辺 瑠伊, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋, 高橋 祐,  近藤 多伸, “<strong>深層学習に基づく間引きインジケータ付き周波数帯域補間手法による音源分離処理の高速化</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 155–158, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RWatanabe2021ASJ09_ja')">bib</a><br><div id="RWatanabe2021ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RWatanabe2021ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{渡辺 瑠伊} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;深層学習に基づく間引きインジケータ付き周波数帯域補間手法による音源分離処理の高速化&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年秋期研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;155--158&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>サンプリング周波数非依存音源分離モデルを用いた楽音分離の実験的評価</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 159–162, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KSaito2021ASJ09_ja')">bib</a><br><div id="KSaito2021ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KSaito2021ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{齋藤 弘一} and {中村 友彦} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;サンプリング周波数非依存音源分離モデルを用いた楽音分離の実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年秋期研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;159--162&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>Product of Priors型確率分布を導入した音源モデルに基づく独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 163–166, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THasumi2021ASJ09_ja')">bib</a><br><div id="THasumi2021ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THasumi2021ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{蓮実 拓也} and {中村 友彦} and {高宗 典玄} and {猿渡 洋} and {北村 大地} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Product of Priors型確率分布を導入した音源モデルに基づく独立深層学習行列分析による多チャネル音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年秋期研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;163--166&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>三澤 颯大, <ins>中村 友彦</ins>, 高宗 典玄, 北村 大地,  猿渡 洋, “<strong>独立深層学習行列分析を用いたランク制約付き空間共分散行列推定による音声強調</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 279–280, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SMisawa2021ASJ09_ja')">bib</a><br><div id="SMisawa2021ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SMisawa2021ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{三澤 颯大} and {中村 友彦} and {高宗 典玄} and {北村 大地} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;独立深層学習行列分析を用いたランク制約付き空間共分散行列推定による音声強調&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年秋期研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;279--280&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>ヘビーテイル生成モデルに基づく独立深層学習テンソル分析</strong>,” <em>日本音響学会 2021年秋期研究発表会講演論文集</em>, pp. 301–304, Sep. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('NNarisawa2021ASJ09_ja')">bib</a><br><div id="NNarisawa2021ASJ09_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NNarisawa2021ASJ09_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{成澤 直輝} and {池下 林太郎} and {高宗 典玄} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {中谷 智広}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;ヘビーテイル生成モデルに基づく独立深層学習テンソル分析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年秋期研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;301--304&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  猿渡 洋, “<strong>多重解像度深層分析を用いた楽音分離の実験的評価</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 13, pp. 1–11, Jun. 2021.<br />
<span style="color: var(--md-code-hl-function-color)">[2021 Otogaku Symposium Best Presentation Award / 2021年度 音学シンポジウム優秀発表賞]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura2021SIGMUS06_ja')">bib</a>   <a class="md-button md-button--small" href="https://drive.google.com/file/d/10KWyhVU9EziBKk1Il5f6HWZD0azVOb4p/view?usp=share_link">slides <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="TNakamura2021SIGMUS06_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura2021SIGMUS06_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;多重解像度深層分析を用いた楽音分離の実験的評価&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021-MUS-131, no. 13&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--11&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平,  猿渡 洋, “<strong>周波数領域でのフィルタ設計に基づくサンプリング周波数非依存畳み込み層を用いたDNN音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 21, pp. 1–6, Jun. 2021.<br />
<span style="color: var(--md-code-hl-function-color)">[2021 Otogaku Symposium Best Student Presentation Award (Awardee: Koichi Saito) / 2021年度 音学シンポジウム学生優秀発表賞（受賞者：齋藤 弘一）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KSaito2021SIGMUS06_ja')">bib</a><br><div id="KSaito2021SIGMUS06_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KSaito2021SIGMUS06_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{齋藤 弘一} and {中村 友彦} and {矢田部 浩平} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;周波数領域でのフィルタ設計に基づくサンプリング周波数非依存畳み込み層を用いたDNN音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021-MUS-131, no. 21&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--6&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>非負値行列因子分解を導入したproduct of experts型音源モデルに基づく独立深層学習行列分析による多チャネル音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–131, no. 37, pp. 1–8, Jun. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THasumi2021SIGMUS06_ja')">bib</a><br><div id="THasumi2021SIGMUS06_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THasumi2021SIGMUS06_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{蓮実 拓也} and {中村 友彦} and {高宗 典玄} and {猿渡 洋} and {北村 大地} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;非負値行列因子分解を導入したproduct of experts型音源モデルに基づく独立深層学習行列分析による多チャネル音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021-MUS-131, no. 37&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--8&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>アンチエイリアシング機構を導入したサンプリング周波数非依存畳み込み層を用いた音源分離</strong>,” <em>情報処理学会研究報告</em>, vol. 2021–MUS–130, pp. 1–6, Mar. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KSaito2021SIGMUS03_ja')">bib</a><br><div id="KSaito2021SIGMUS03_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KSaito2021SIGMUS03_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{齋藤 弘一} and {中村 友彦} and {矢田部 浩平} and {小泉 悠馬} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;アンチエイリアシング機構を導入したサンプリング周波数非依存畳み込み層を用いた音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021-MUS-130&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">issue</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;32&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--6&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡 洋, “<strong>潜在アナログフィルタ表現に基づく畳み込み層を用いたサンプリング周波数非依存なDNN音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 125–128, Mar. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KSaito2021ASJS_ja')">bib</a><br><div id="KSaito2021ASJS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KSaito2021ASJS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{齋藤 弘一} and {中村 友彦} and {矢田部 浩平} and {小泉 悠馬} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;潜在アナログフィルタ表現に基づく畳み込み層を用いたサンプリング周波数非依存なDNN音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年春季研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;125--128&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>経験ベイズ独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 217–220, Mar. 2021.<br />
<span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ (Awardee: Takuya Hasumi) / 日本音響学会 第22回学生優秀発表賞（受賞者：蓮実 拓也）]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THasumi2021ASJS_ja')">bib</a><br><div id="THasumi2021ASJS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THasumi2021ASJS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{蓮実 拓也} and {中村 友彦} and {高宗 典玄} and {猿渡 洋} and {北村 大地} and {高橋 祐} and {近藤 多伸}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;経験ベイズ独立深層学習行列分析による多チャネル音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年春季研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;217--220&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>独立深層学習テンソル分析に基づく多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, pp. 117–120, Mar. 2021.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('NNarisawa2021ASJS_ja')">bib</a><br><div id="NNarisawa2021ASJS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NNarisawa2021ASJS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{成澤 直輝} and {池下 林太郎} and {高宗 典玄} and {北村 大地} and {中村 友彦} and {猿渡 洋} and {中谷 智広}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;独立深層学習テンソル分析に基づく多チャネル音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2021年春季研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2021&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;117--120&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>成澤 直輝, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>音源分離のための周波数間相関を考慮した多変量複素Gauss分布に基づく深層学習による分散共分散行列推定の検討</strong>,” <em>日本音響学会 2020年秋季研究発表会講演論文集</em>, pp. 315–318, Sep. 2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('NNarisawa2020ASJA_ja')">bib</a><br><div id="NNarisawa2020ASJA_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NNarisawa2020ASJA_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{成澤 直輝} and {高宗 典玄} and {北村 大地} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音源分離のための周波数間相関を考慮した多変量複素{Gauss}分布に基づく深層学習による分散共分散行列推定の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会 2020年秋季研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;315--318&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>ニューラルネットワークとウェーブレット基底関数の同時学習に基づく多重解像度深層分析を用いた時間領域音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, no. 439, pp. 279–284, Mar. 2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKozuka202003IEICETechRep_ja')">bib</a><br><div id="SKozuka202003IEICETechRep_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SKozuka202003IEICETechRep_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{小塚 詩穂里} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;ニューラルネットワークとウェーブレット基底関数の同時学習に基づく多重解像度深層分析を用いた時間領域音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;119, no. 439&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;279--284&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>高道 慎之介, 齋藤 佑樹, <ins>中村 友彦</ins>, 郡山 知樹,  猿渡 洋, “<strong>manga2voice: マンガ画像からの音声合成に向けた音声分析</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 1065–1068, Mar. 2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('STakamichi202003ASJS_ja')">bib</a><br><div id="STakamichi202003ASJS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">STakamichi202003ASJS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{高道 慎之介} and {齋藤 佑樹} and {中村 友彦} and {郡山 知樹} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;manga2voice: マンガ画像からの音声合成に向けた音声分析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2020年春季研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1065--1068&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>リフティングスキームによる離散ウェーブレット変換を導入した深層ニューラルネットに基づく時間領域音源分離</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 325–328, Mar. 2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKozuka202003ASJS_ja')">bib</a><br><div id="SKozuka202003ASJS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SKozuka202003ASJS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{小塚 詩穂里} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;リフティングスキームによる離散ウェーブレット変換を導入した深層ニューラルネットに基づく時間領域音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2020年春季研究発表会講演論文集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;325--328&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  猿渡 洋, “<strong>Haar変換を導入した時間領域深層ニューラルネットに基づく音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, no. 306, EA2019–60, pp. 41–48, Nov. 2019.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201911IEICETechRep_ja')">bib</a><br><div id="TNakamura201911IEICETechRep_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201911IEICETechRep_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Haar変換を導入した時間領域深層ニューラルネットに基づく音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;119, no. 306, EA2019-60&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;41--48&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;November&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2019&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムからの逐次位相推定法</strong>,” <em>情報処理学会研究報告</em>, vol. 2016–MUS–111, no. 47, pp. 1–5, May 2016.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201605IPSJSIGMUS_ja')">bib</a><br><div id="TNakamura201605IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201605IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;高速近似連続ウェーブレット変換による振幅スペクトログラムからの逐次位相推定法&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016-MUS-111, no. 47&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--5&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による超解像声道スペクトル推定法</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 115, no. 523, SP2015–111, pp. 99–104, Mar. 2016.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201603IEICETechRep_ja')">bib</a><br><div id="TNakamura201603IEICETechRep_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201603IEICETechRep_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;非負値行列因子分解に基づく欠損データ補間による超解像声道スペクトル推定法&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;115, no. 523, SP2015-111&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;99--104&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムに対する実時間位相推定法</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 933–936, Mar. 2016.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201603ASJS1_ja')">bib</a><br><div id="TNakamura201603ASJS1_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201603ASJS1_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;高速近似連続ウェーブレット変換による振幅スペクトログラムに対する実時間位相推定法&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2016年春季研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;933--936&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による声道スペクトル推定法の検討</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 393–396, Mar. 2016.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201603ASJS2_ja')">bib</a><br><div id="TNakamura201603ASJS2_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201603ASJS2_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;非負値行列因子分解に基づく欠損データ補間による声道スペクトル推定法の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2016年春季研究発表会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;393--396&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>全極スペクトルモデルと擬似周期信号モデルのウェーブレット変換表現を用いた多重音スペクトログラムの調波時間因子分解</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–107, no. 50, pp. 1–8, May 2015.<br />
<span style="color: var(--md-code-hl-function-color)">[2015 Otogaku Symposium Award / 2015年度 音学シンポジウム優秀賞]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201505IPSJSIGMUS_ja')">bib</a><br><div id="TNakamura201505IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201505IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;全極スペクトルモデルと擬似周期信号モデルのウェーブレット変換表現を用いた多重音スペクトログラムの調波時間因子分解&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2015-MUS-107, no. 50&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--8&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2015&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>全極スペクトルモデルを用いた調波時間因子分解による多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–106, no. 26, pp. 1–7, Mar. 2015.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201503IPSJSIGMUS_ja')">bib</a><br><div id="TNakamura201503IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201503IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;全極スペクトルモデルを用いた調波時間因子分解による多重音解析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2015-MUS-106, no. 26&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--7&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2015&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–104, no. 11, pp. 1–6, Aug. 2014.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201408IPSJSIGMUS_ja')">bib</a><br><div id="TNakamura201408IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201408IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {吉井 和佳} and {後藤 真孝} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014-MUS-104, no. 11&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;August&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>無矛盾性規準に基づく連続ウェーブレット変換スペクトログラムへの位相推定法と高速化</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, no. 41, pp. 1–6, May 2014.<br />
<span style="color: var(--md-code-hl-function-color)">[IPSJ Yamashita SIG Research Award / 情報処理学会 2014年度山下記念研究賞]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201405IPSJSIGMUS_ja')">bib</a><br><div id="TNakamura201405IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201405IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;無矛盾性規準に基づく連続ウェーブレット変換スペクトログラムへの位相推定法と高速化&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014-MUS-103, no. 41&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>確率的モデル化に基づく移動音源の劣決定ブラインド音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 114, no. 52, pp. 211–216, May 2014.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('THiguchi201405IEICETechRep_ja')">bib</a><br><div id="THiguchi201405IEICETechRep_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">THiguchi201405IEICETechRep_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{樋口 卓哉} and {高宗 典玄} and {中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;確率的モデル化に基づく移動音源の劣決定ブラインド音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会技術研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;114, no. 52&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;211--216&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解法に基づく事前情報付き多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, no. 18, pp. 1–6, May 2014.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KShihou201405IPSJSIGMUS_ja')">bib</a><br><div id="KShihou201405IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KShihou201405IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{四方 紘太郎} and {高宗 典玄} and {中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;調波時間因子分解法に基づく事前情報付き多重音解析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014-MUS-103, no. 18&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>連続ウェーブレット変換の高速近似アルゴリズムに基づく振幅スケーログラムへの無矛盾位相付加法の検討</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 933–936, Mar. 2014.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201403ASJS1_ja')">bib</a><br><div id="TNakamura201403ASJS1_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201403ASJS1_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;連続ウェーブレット変換の高速近似アルゴリズムに基づく振幅スケーログラムへの無矛盾位相付加法の検討&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2014年春季研究発表会講演集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;933--936&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号に含まれる調波音の周波数特性とドラムの音色の転写システム</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 1043–1044, Mar. 2014.<br />
<span style="color: var(--md-code-hl-function-color)">[Best Student Presentation Award from ASJ / 日本音響学会 第9回学生優秀発表賞]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201403ASJS2_ja')">bib</a><br><div id="TNakamura201403ASJS2_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201403ASJS2_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {吉井 和佳} and {後藤 真孝} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音楽音響信号に含まれる調波音の周波数特性とドラムの音色の転写システム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2014年春季研究発表会講演集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1043--1044&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解に基づく音楽事前情報付き多重音解析</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, pp. 1049–1052, Mar. 2014.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KShihou201403ASJS_ja')">bib</a><br><div id="KShihou201403ASJS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KShihou201403ASJS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{四方 紘太郎} and {高宗 典玄} and {中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;調波時間因子分解に基づく音楽事前情報付き多重音解析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2014年春季研究発表会講演集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1049--1052&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2014&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>DOA-HMMに基づく劣決定ブラインド音源分離</strong>,” <em>日本音響学会2013年秋季研究発表会講演集</em>, pp. 23–26, Sep. 2013.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SHiguchi201309ASJA_ja')">bib</a><br><div id="SHiguchi201309ASJA_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SHiguchi201309ASJA_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{樋口 卓哉} and {高宗 典玄} and {中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;DOA-HMMに基づく劣決定ブラインド音源分離&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2013年秋季研究発表会講演集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2013&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;23--26&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>誤り・任意の弾き直し・弾き飛ばしを含む演奏音響信号への高速な楽譜追跡</strong>,” <em>情報処理学会研究報告</em>, vol. 2013–MUS–99, no. 40, pp. 1–5, May 2013.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201305IPSJSIGMUS_ja')">bib</a><br><div id="TNakamura201305IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201305IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {中村 栄太} and {嵯峨山 茂樹}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;誤り・任意の弾き直し・弾き飛ばしを含む演奏音響信号への高速な楽譜追跡&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2013-MUS-99, no. 40&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--5&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;May&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2013&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡</strong>,” <em>情報処理学会 第75回全国大会</em>, vol. 2013, no. 1, pp. 283–284, Mar. 2013.<br />
<span style="color: var(--md-code-hl-function-color)">[Student Encouragement Award of IPSJ National Convention / 情報処理学会第75回全国大会 学生奨励賞]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201303IPSJConv_ja')">bib</a><br><div id="TNakamura201303IPSJConv_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201303IPSJConv_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {中村 栄太} and {嵯峨山 茂樹}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会 第75回全国大会&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2013, no. 1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;283--284&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2013&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 水野 優, 鈴木 孝輔, 中村 栄太, 樋口 祐介, 深山 覚,  嵯峨山 茂樹, “<strong>音楽演奏の誤りや反復に頑健な音響入力自動伴奏</strong>,” <em>日本音響学会2012年秋季研究発表会講演集</em>, pp. 931–934, Sep. 2012.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201209ASJA_ja')">bib</a><br><div id="TNakamura201209ASJA_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TNakamura201209ASJA_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {水野 優} and {鈴木 孝輔} and {中村 栄太} and {樋口 祐介} and {深山 覚} and {嵯峨山 茂樹}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音楽演奏の誤りや反復に頑健な音響入力自動伴奏&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;日本音響学会2012年秋季研究発表会講演集&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;931--934&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2012&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>中野 允裕, ルルー ジョナトン, 亀岡 弘和, <ins>中村 友彦</ins>, 小野 順貴,  嵯峨山 茂樹, “<strong>スペクトログラムのベイジアンノンパラメトリックモデリングに基づく音楽信号の解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2011–MUS–91, no. 6, pp. 1–8, Jul. 2011.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('INakano201107IPSJSIGMUS_ja')">bib</a><br><div id="INakano201107IPSJSIGMUS_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">INakano201107IPSJSIGMUS_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中野 允裕} and {ルルー ジョナトン} and {亀岡 弘和} and {中村 友彦} and {小野 順貴} and {嵯峨山 茂樹}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;スペクトログラムのベイジアンノンパラメトリックモデリングに基づく音楽信号の解析&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理学会研究報告&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2011-MUS-91, no. 6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;July&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;1--8&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2011&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
</ol>
<h2 id="review-papers">Review Papers / 解説記事<a class="headerlink" href="#review-papers" title="Permanent link">&para;</a></h2>
<ol>
<li>Shoichi Koyama, Juliano Ribeiro, <ins>Tomohiko Nakamura</ins>, Natsuki Ueno, and Mirco Pezzoli, “<strong><a href="https://doi.org/10.1109/MSP.2024.3465896">Physics-informed machine learning for sound field estimation</a></strong>,” <em>Special Issue on Model-Based and Data-Driven Audio Signal Processing, IEEE Signal Processing Magazine</em>, vol. 41, pp. 60–71, Nov. 2024.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('SKoyama2024IEEESPM')">bib</a>   <a class="md-button md-button--small" href="https://arxiv.org/abs/2408.14731">arXiv</a><br><div id="SKoyama2024IEEESPM" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">SKoyama2024IEEESPM</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Koyama, Shoichi and Ribeiro, Juliano and Nakamura, Tomohiko and Ueno, Natsuki and Pezzoli, Mirco&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Physics-Informed Machine Learning For Sound Field Estimation&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Special Issue on Model-based and Data-Driven Audio Signal Processing, IEEE Signal Processing Magazine&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2024&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;November&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;41&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">issue</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;60--71&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.1109/MSP.2024.3465896&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>亀岡 弘和, <ins>中村 友彦</ins>,  高宗 典玄, “<strong>音楽音響信号処理技術の最先端</strong>,” <em>電子情報通信学会誌</em>, vol. 98, no. 6, pp. 467–474, Jun. 2015.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('HKameoka2015IEICEMag_ja')">bib</a>   <a class="md-button md-button--small" href="https://www.journal.ieice.org/summary.php?id=k98_6_467">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="HKameoka2015IEICEMag_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">HKameoka2015IEICEMag_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{亀岡 弘和} and {中村 友彦} and {高宗 典玄}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;音楽音響信号処理技術の最先端&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;電子情報通信学会誌&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;98&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;467--474&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2015&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
</ol>
<h2 id="thesis">Thesis / 学位論文<a class="headerlink" href="#thesis" title="Permanent link">&para;</a></h2>
<ul>
<li>Ph.D Thesis: <ins>Tomohiko Nakamura</ins>, “<strong><a href="https://doi.org/10.15083/00073992">Source-filter representation and phase estimation in continuous wavelet transform domain for monaural music audio editing</a></strong>,” PhD thesis, The University of Tokyo, Mar. 2016.<br />
<span style="color: var(--md-code-hl-function-color)">[Dean’s Award, Graduate School of Information Science and Technology, The University of Tokyo / 東京大学大学院情報理工学系研究科 研究科長賞, IPSJ SIG-MUS Recommended Ph.D. Thesis / 情報処理学会 2015年度研究会推薦博士論文]</span><br><a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura201603PhD')">bib</a>   <a class="md-button md-button--small" href="https://repository.dl.itc.u-tokyo.ac.jp/records/48867#.YK0RbKj7QuU">paper <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a><br><div id="TNakamura201603PhD" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">TNakamura201603PhD</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Nakamura, Tomohiko&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;Source-filter representation and phase estimation in continuous wavelet transform domain for monaural music audio editing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">school</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;The University of Tokyo&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2016&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;March&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;10.15083/00073992&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>Master Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Fast score following to acoustic signal of musical performance with errors, repeats, and skips,"</strong> the University of Tokyo, Mar. 2013. (in Japanese)
   <span style="color: var(--md-code-hl-function-color)">[IPSJ Certificate of Excellent Master’s Thesis / 情報処理学会第75回全国大会 情報処理学会推奨 修士論文認定]</span></li>
<li>Bachelor Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Local stability analysis of cell-to-cell networks with cyclic gene regulatory networks,"</strong> the University of Tokyo, Mar. 2011. (in Japanese)</li>
</ul>
<h2 id="patents">Patents / 特許<a class="headerlink" href="#patents" title="Permanent link">&para;</a></h2>
<ol>
<li>池下 林太郎, 中谷 智広, 成澤 直輝, 高宗 典玄, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>信号処理装置、信号処理方法、およびプログラム</strong>,” 特許7709139号, 08-Jul-2025.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('RIkeshita20211216Patent_ja')">bib</a><br><div id="RIkeshita20211216Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">RIkeshita20211216Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{池下 林太郎} and {中谷 智広} and {成澤 直輝} and {高宗 典玄} and {中村 友彦} and {猿渡 洋}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;信号処理装置、信号処理方法、およびプログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許7709139号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;8&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;July&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2025&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第7349288号, 13-Sep-2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20230913Patent_ja')">bib</a><br><div id="TNakamura20230913Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20230913Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;対象物認識装置、対象物認識方法、及び対象物認識プログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第7349288号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;13&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第7349290号, 13-Sep-2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20230913Patent_ja_1')">bib</a><br><div id="TNakamura20230913Patent_ja_1" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20230913Patent_ja_1</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;対象物認識装置、対象物認識方法、及び対象物認識プログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第7349290号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;13&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>学習済みモデル、学習装置、学習方法、及び学習プログラム</strong>,” 特許第7304235号, 28-Jun-2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20230628Patent_ja_2')">bib</a><br><div id="TNakamura20230628Patent_ja_2" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20230628Patent_ja_2</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;学習済みモデル、学習装置、学習方法、及び学習プログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第7304235号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;28&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li>新井 康太, 平尾 悠太朗, 鳴海 拓志, <ins>中村 友彦</ins>, 高道 慎之介,  門村（吉田） 成朗, “<strong>情報処理装置、情報処理方法、及び情報処理プログラム</strong>,” 特開2024-110900, 07-Jun-2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('KArai20230607Patent_ja')">bib</a><br><div id="KArai20230607Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">KArai20230607Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{新井 康太} and {平尾 悠太朗} and {鳴海 拓志} and {中村 友彦} and {高道 慎之介} and {門村（吉田） 成朗}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;情報処理装置、情報処理方法、及び情報処理プログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特開2024-110900&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;7&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 國松 昇平, 櫻井 利彦,  大西 一徳, “<strong>カメラ配置評価装置、カメラ配置評価方法、及びコンピュータプログラム</strong>,” 特許第7291013号, 06-Jun-2023.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20230606Patent_ja')">bib</a><br><div id="TNakamura20230606Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20230606Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {國松 昇平} and {櫻井 利彦} and {大西 一徳}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;カメラ配置評価装置、カメラ配置評価方法、及びコンピュータプログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第7291013号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;6&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;June&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2023&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>対象物認識装置、対象物認識方法、及び対象物認識プログラム</strong>,” 特許第6773829号, 05-Oct-2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20201005Patent_ja_1')">bib</a><br><div id="TNakamura20201005Patent_ja_1" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20201005Patent_ja_1</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;対象物認識装置、対象物認識方法、及び対象物認識プログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第6773829号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;5&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;October&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>学習装置、学習方法、学習プログラム、及び対象物認識装置</strong>,” 特許第6773825号, 05-Oct-2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20201005Patent_ja_2')">bib</a><br><div id="TNakamura20201005Patent_ja_2" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20201005Patent_ja_2</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;学習装置、学習方法、学習プログラム、及び対象物認識装置&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第6773825号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;5&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;October&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, “<strong>データベース統合装置、データベース統合方法、データベース統合プログラム、及びデータ補完装置</strong>,” 特許第6768101号, 24-Sep-2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20200924Patent_ja')">bib</a><br><div id="TNakamura20200924Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20200924Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;データベース統合装置、データベース統合方法、データベース統合プログラム、及びデータ補完装置&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第6768101号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;September&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;24&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>, 伊藤 忠彦,  島岡 政基, “<strong>証明書管理装置</strong>,” 特許第6647259号, 16-Jan-2020.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20200116Patent_ja')">bib</a><br><div id="TNakamura20200116Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20200116Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {伊藤 忠彦} and {島岡 政基}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;証明書管理装置&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第6647259号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;16&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;January&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2020&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
<li><ins>中村 友彦</ins>,  亀岡 弘和, “<strong>声道スペクトル推定装置、声道スペクトル推定方法、及びプログラム</strong>,” 特許第6420781号, 19-Oct-2018.<br />
<a class="md-button md-button--small" href="javascript:void(0);" onclick="toggleBib('TNakamura20181019Patent_ja')">bib</a><br><div id="TNakamura20181019Patent_ja" class="bibtex" style="display:none;"><div class="highlight"><pre><span></span><code><span class="nc">@patent</span><span class="p">{</span><span class="nl">TNakamura20181019Patent_ja</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;{中村 友彦} and {亀岡 弘和}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;声道スペクトル推定装置、声道スペクトル推定方法、及びプログラム&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;特許第6420781号&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">day</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;19&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;October&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">&quot;2018&quot;</span>
<span class="p">}</span>
</code></pre></div></div></li>
</ol>
<h2 id="invited-and-visiting-talks">Invited and visiting talks<a class="headerlink" href="#invited-and-visiting-talks" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>中村友彦</ins>, <strong>"深層学習を用いた音源分離の動向と展望,"</strong> 電子通信情報学会 電気/応用音響研究会, vol. 124, no. 389, EA2024-93, p. 104, Mar. 2025.<br />
<a href="https://drive.google.com/file/d/1YUU3kOZjL-9E4zcPRmDo4Mn7YageDvtz/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Sampling-Frequency-Independent Deep Learning for Audio Source Separation,"</strong> Talk at Behavioral-Informatics &amp; Interaction-Computation Lab. in National Tsing Hua University, May 2024.<br />
<a href="https://drive.google.com/file/d/15eN9k_nbRrRUQzYuzirQZpz2r8R__wau/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Toward Music Source Separation for Mixtures of Homogeneous Sources,"</strong> Talk at Music and AI Lab. in National Taiwan University, May 2024.<br />
<a href="https://drive.google.com/file/d/1kuVEw41NhPMWOexkPOxPunDqA0RInTLu/view?usp=sharing">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
<li>北村 大地, <ins>中村 友彦</ins>, <strong>"音源分離技術の基礎と応用～音源分離チョットワカルになるための手引き～,"</strong> 音学シンポジウム2023, vol. 2023-MUS-137 no. 35, Jun. 2023.<br />
<a href="https://www.docswell.com/s/d-kitamura/ZQ898R-20230624">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, <strong>"Signal-processing-inspired deep learning,"</strong> IEEE NZ Signal Processing/Information Theory Joint Chapter in co-hosted by the Acoustics Research Centre, University of Auckland, Dec. 2022.<br />
<a href="https://drive.google.com/file/d/10SM7U5pkgT5Ae3LDUA6Cr1Zlc2gKbsqQ/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>, <strong>"ウェーブレット変換と深層学習を融合した音源分離,"</strong> 電子通信情報学会 電気/応用音響研究会，vol.122, no. 144, EA2022-32, p. 25, Aug. 2022.<br />
<a href="https://drive.google.com/file/d/10XuYFUOJmDTWdJ0LDI2bgFV74x11sTOo/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
</ol>
<h2 id="tutorials">Tutorials / 講習会<a class="headerlink" href="#tutorials" title="Permanent link">&para;</a></h2>
<ol>
<li>猿渡 洋，<ins>中村 友彦</ins>, <strong>"音源分離の基礎と最新動向,"</strong>, <a href="http://www.sap.ist.i.kyoto-u.ac.jp/seminar/onsei2308.html">音声認識・対話技術講習会</a>, Aug. 2023.</li>
</ol>
<h2 id="awards">Awards / 受賞<a class="headerlink" href="#awards" title="Permanent link">&para;</a></h2>
<h3 id="awards-of-my-papers">Awards of My Papers / 自身の受賞<a class="headerlink" href="#awards-of-my-papers" title="Permanent link">&para;</a></h3>
<ol>
<li>2024/03: The Awaya Kiyoshi Research Award, ASJ / 第55回 日本音響学会 粟屋潔学術奨励賞</li>
<li>2022/03: The Itakura Prize Innovative Young Researcher Award, ASJ / 第17回 日本音響学会 独創研究奨励賞板倉記念</li>
<li>2021/07: 2021 Encouragement Award, Foundation of the Promotion of Engineering Research / 総合研究奨励会 令和2年度総合研究奨励賞</li>
<li>2021/06: 2021 Otogaku Symposium Best Presentation Award / 2021年度 音学シンポジウム優秀発表賞</li>
<li>2016/08: IPSJ SIG-MUS Recommended Ph.D. Thesis / 情報処理学会 2015年度研究会推薦博士論文</li>
<li>2016/03: Dean’s Award of Graduate School of Information Science and Technology, The University of Tokyo / 東京大学 大学院情報理工学系研究科 研究科長賞</li>
<li>2016/03: IPSJ Yamashita SIG Research Award / 情報処理学会 2015年度山下記念研究賞</li>
<li>2015/10: SICE Best Paper Award (Takeda Award) / 計測自動制御学会 論文賞（武田賞）</li>
<li>2015/05: 2015 Otogaku Symposium Award / 2015年度 音学シンポジウム優秀賞</li>
<li>2014/03: Best Student Presentation Award from ASJ / 日本音響学会 第9回学生優秀発表賞</li>
<li>2013/03: IPSJ Certificate of Excellent Master’s Thesis / 情報処理学会第75回全国大会 情報処理学会推奨 修士論文認定</li>
<li>2013/03: Student Encouragement Award of IPSJ National Convention / 情報処理学会第75回全国大会 学生奨励賞</li>
<li>2011/09: SICE Annual Conference 2011 International Award</li>
<li>2011/09: SICE Annual Conference 2011 Finalist of Young Author Award</li>
</ol>
<h3 id="awards-received-by-students-and-collaborators">Awards Received by Students and Collaborators / 共著者・指導学生の受賞<a class="headerlink" href="#awards-received-by-students-and-collaborators" title="Permanent link">&para;</a></h3>
<ol>
<li>2025/06: 2025 Otogaku Symposium Best Student Presentation Award (Awardee: Aogu Wada) / 2025年度 音学シンポジウム学生優秀発表賞（受賞者：和田 仰）</li>
<li>2024/09: Best Student Presentation Award from ASJ (Awardee: Yuto Ishikawa) / 日本音響学会 第28回学生優秀発表賞（受賞者：石川 悠人）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2024/03: IPSJ SIG-MUS 139 Student Encouragement Award (Awardee: Hiroaki Hyodo) / 情報処理学会 第139回音楽情報科学研究会 学生奨励賞 Best Research部門（受賞者：兵藤 弘明）<a href="https://www.ipsj.or.jp/award/mus-award3.html">link</a></li>
<li>2023/07: IPSJ Yamashita SIG Research Award (Awardee: Masato Mimura) / 情報処理学会2022年度山下記念研究賞（受賞者：三村 正人）<a href="https://www.ipsj.or.jp/award/yamashita2023.html">link</a></li>
<li>2022/12: IEEE Signal Processing Society Japan Student Conference Paper Award (Awardee: Masaya Kawamura) / 第16回 IEEE Signal Processing Society Japan Student Conference Paper Award（受賞者：川村 真也）</li>
<li>2022/11: Best Student Presentation Award from ASJ (Awardee: Kanami Imamura) / 日本音響学会 第25回学生優秀発表賞（受賞者：今村 奏海）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2022/11: Best Student Presentation Award from ASJ (Awardee: Kazuhide Shigemi) / 日本音響学会 第25回学生優秀発表賞（受賞者：重見 和秀）<a href="https://acoustics.jp/awards/student/">link</a></li>
<li>2022/09: Finalist of Best Student Paper Award of IWAENC 2022 (Yuki Ito)</li>
<li>2022/06: IPSJ Yamashita SIG Research Award (Awardee: Takaaki Saeki) / 情報処理学会2022年度山下記念研究賞（受賞者：佐伯 高明）<a href="https://www.ipsj.or.jp/award/yamashita2022.html">link</a></li>
<li>2022/06: 2022 Otogaku Symposium Best Student Presentation Award (Awardee: Futa Nakashima) / 2022年度 音学シンポジウム学生優秀発表賞（受賞者：中島 風大）<a href="https://www.ipsj.or.jp/award/musslp-award2.html">link</a></li>
<li>2022/03: Dean's Award of Graduate School of Information Science and Technology, The University of Tokyo (Awardee: Takuya Hasumi) / 東京大学 大学院情報理工学系研究科 研究科長賞（受賞者：蓮実 拓也）<a href="https://www.i.u-tokyo.ac.jp/news/files/2021_the_dean%27s_award.pdf">link</a></li>
<li>2021/12: 日本音響学会第24回関西支部若手研究者交流研究発表会 奨励賞（受賞者：渡辺 瑠伊）<a href="https://asj-kansai.acoustics.jp/event/24wakate/">link</a></li>
<li>2021/06: 2021 Otogaku Symposium Best Student Presentation Award (Awardee: Koichi Saito) / 2021年度 音学シンポジウム学生優秀発表賞（受賞者：齋藤 弘一）<a href="https://www.ipsj.or.jp/award/musslp-award2.html">link</a></li>
<li>2021/05: Best Student Presentation Award from ASJ (Awardee: Takuya Hasumi) / 日本音響学会 第22回学生優秀発表賞（受賞者：蓮実 拓也）<a href="https://acoustics.jp/awards/student/">link</a></li>
</ol>
<h2 id="other">Other / その他<a class="headerlink" href="#other" title="Permanent link">&para;</a></h2>
<ol>
<li><ins>中村 友彦</ins>, <strong>"深層学習を用いた音源分離,"</strong> 日本音響学会第23回サマーセミナー，Sep. 2022.<br />
<a href="https://drive.google.com/file/d/10kswztKvvfdG82Br2ynfW44U28xlmmxD/view?usp=share_link">slides<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M208 48H96c-8.8 0-16 7.2-16 16v384c0 8.8 7.2 16 16 16h80v48H96c-35.3 0-64-28.7-64-64V64C32 28.7 60.7 0 96 0h133.5c17 0 33.3 6.7 45.3 18.7l122.5 122.6c12 12 18.7 28.3 18.7 45.3v149.5h-48v-128h-88c-39.8 0-72-32.2-72-72v-88zm140.1 112L256 67.9V136c0 13.3 10.7 24 24 24zM240 380h32c33.1 0 60 26.9 60 60s-26.9 60-60 60h-12v28c0 11-9 20-20 20s-20-9-20-20V400c0-11 9-20 20-20m32 80c11 0 20-9 20-20s-9-20-20-20h-12v40zm96-80h32c28.7 0 52 23.3 52 52v64c0 28.7-23.3 52-52 52h-32c-11 0-20-9-20-20V400c0-11 9-20 20-20m32 128c6.6 0 12-5.4 12-12v-64c0-6.6-5.4-12-12-12h-12v88zm76-108c0-11 9-20 20-20h48c11 0 20 9 20 20s-9 20-20 20h-28v24h28c11 0 20 9 20 20s-9 20-20 20h-28v44c0 11-9 20-20 20s-20-9-20-20z"/></svg></span></a></li>
<li><ins>中村 友彦</ins>，<strong>"コーヒーブレイク　ちょっとしたエッセイ"</strong>, <em>日本音響学会誌</em>，vol. 78, no. 1, Dec. 25, 2021.</li>
<li><ins>中村 友彦</ins>, <strong>"音楽音響信号に対するウェーブレット変換を用いた音源分離,"</strong> <a href="https://www.keisu.t.u-tokyo.ac.jp/2021/09/13/system_colloquium-202102/">東京大学工学部計数工学科 システム情報談話会</a>，Sep. 2021.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝, 亀岡 弘和, <strong>"音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム,"</strong> <em>OngaCRESTシンポジウム2014-音楽情報処理研究が切り拓く未来を探る-,</em> Aug. 23, 2014.<ul>
<li><a href="http://ongacrest.jp/">OngaCREST</a></li>
<li><a href="http://av.watch.impress.co.jp/docs/series/dal/20140825_663420.html">「人型ロボットのダンス」や「声の年齢制御」など、音楽情報処理の最先端をレポート - 藤本健のDigital Audio Laboratory</a></li>
<li><a href="http://pc.watch.impress.co.jp/docs/column/kyokai/20140827_663740.html">コピー不可能な体験を価値の中核に～音楽情報処理の「OngaCRESTシンポジウム」レポート - 森山和道の「ヒトと機械の境界面」</a></li>
</ul>
</li>
</ol>







  
  



  


  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021- Tomohoiko Nakamura
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["toc.integrate", "navigation.indexes"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.50899def.min.js"></script>
      
    
  </body>
</html>