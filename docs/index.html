
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <meta name="author" content="Tomohiko Nakamura">
      
      
        <link rel="canonical" href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/">
      
      <link rel="shortcut icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.2.3">
    
    
      
        <title>Tomohiko Nakamura - Tomohiko Nakamura</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.3b61ea93.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.39b8e14a.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9EPRVMYY0Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9EPRVMYY0Z');
</script>
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tomohiko-nakamura" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/" title="Tomohiko Nakamura" class="md-header-nav__button md-logo" aria-label="Tomohiko Nakamura">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      <div class="md-header-nav__ellipsis">
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            Tomohiko Nakamura
          </span>
        </div>
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            
              Tomohiko Nakamura
            
          </span>
        </div>
      </div>
    </div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="/#research-topics-demos" class="md-tabs__link">
      Research Topics
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="/#biography" class="md-tabs__link">
      Biography
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="/#publications" class="md-tabs__link">
      Publications
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="/#funds-awards" class="md-tabs__link">
      Funds & Awards
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="lecture/" class="md-tabs__link">
      Lecture Notes
    </a>
  </li>

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://tomohikonakamura.github.io/Tomohiko-Nakamura/" title="Tomohiko Nakamura" class="md-nav__button md-logo" aria-label="Tomohiko Nakamura">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Tomohiko Nakamura
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      



  <li class="md-nav__item">
    <a href="/#research-topics-demos" class="md-nav__link">
      Research Topics
    </a>
  </li>

    
      
      
      



  <li class="md-nav__item">
    <a href="/#biography" class="md-nav__link">
      Biography
    </a>
  </li>

    
      
      
      



  <li class="md-nav__item">
    <a href="/#publications" class="md-nav__link">
      Publications
    </a>
  </li>

    
      
      
      



  <li class="md-nav__item">
    <a href="/#funds-awards" class="md-nav__link">
      Funds & Awards
    </a>
  </li>

    
      
      
      



  <li class="md-nav__item">
    <a href="lecture/" class="md-nav__link">
      Lecture Notes
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="tomohiko-nakamura">Tomohiko Nakamura<a class="headerlink" href="#tomohiko-nakamura" title="Permanent link">&para;</a></h1>
<p><img alt="" src="images/nakamura100x100.jpg" width="120" /> </p>
<p>I received B.S., M.S., and Ph.D. degrees from the University of Tokyo, Japan, in 2011, 2013, and 2016.
I am currently with Graduate School of Information Science and Technology, the University of Tokyo.
I am a member of IEEE Signal Processing Society (SPS), Information Processing Society of Japan (IPSJ), and Acoustic Society of Japan (ASJ).</p>
<p><strong>E-mail: tomohiko.nakamura.jp[at]ieee.org (replace [at] with "@")</strong><br />
<a href="pdfs/nakamura_CV.pdf">My CV<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> / <a href="https://scholar.google.com/citations?user=bHny6PAAAAAJ">Google Scholar<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></span></a> / <a href="https://researchmap.jp/tomohiko_nakamura">Researchmap<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></span></a> / <a href="https://www.linkedin.com/in/%E5%8F%8B%E5%BD%A6-%E4%B8%AD%E6%9D%91-971758192/">Linkedin<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></span></a> / <a href="https://orcid.org/0000-0003-4385-7170">ORCiD<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></span></a></p>
<hr />
<!-- [Google Scholar:fontawesome-solid-link:](https://scholar.google.com/citations?user=bHny6PAAAAAJ){: .md-button}[Researchmap:fontawesome-solid-link:](https://researchmap.jp/tomohiko_nakamura){: .md-button}[Linkedin:fontawesome-solid-link:](https://www.linkedin.com/in/%E5%8F%8B%E5%BD%A6-%E4%B8%AD%E6%9D%91-971758192/){: .md-button}[ORCiD:fontawesome-solid-link:](https://orcid.org/0000-0003-4385-7170){: .md-button} -->

<h2 id="research-topics-demos">Research Topics &amp; Demos<a class="headerlink" href="#research-topics-demos" title="Permanent link">&para;</a></h2>
<ul>
<li>Signal-Processing-based Deep Learning<ul>
<li>Multiresolution Deep Layered Analysis: End-to-end Music Source Separation Inspired by Multiresolution Analysis</li>
</ul>
</li>
<li>Music Information &amp; Audio Processing<ul>
<li>Harmonic-Temporal Factor Decomposition for Unsupervised Monaural Audio Source Separation <a href="demo/HTFD/">[Automatic Key Transposition Demo]<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li>Unsupervised Drum Timbre Replacement between Two Music Audio Recordings <a href="demo/drum_timbre_replacement/">Demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li>Score Following and Automatic Accompaniment During Practice <a href="demo/automatic_accompaniment/">[Acoustic Input Demo]<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a>, <a href="http://hil.t.u-tokyo.ac.jp/software/Eurydice/index-e.html">[MIDI Input Demo]<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
</ul>
</li>
<li>Audio Signal Synthesis/Construction<ul>
<li>Fast Signal Reconstruction from Magnitude Spectrogram of Continuous Wavelet Transform <a href="demo/fastCWT/">Demo<span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
</ul>
</li>
</ul>
<h2 id="biography">Biography<a class="headerlink" href="#biography" title="Permanent link">&para;</a></h2>
<ul>
<li>Apr. 2007 - Mar. 2009:<ul>
<li>Natural Science Course I, College of Arts and Sciences, the University of Tokyo.</li>
</ul>
</li>
<li>Apr. 2009 - Mar. 2011:<ul>
<li>Department of Mathematical Engineering and Information Physics, Faculty of Engineering, the University of Tokyo.</li>
</ul>
</li>
<li>Apr. 2011 - Mar. 2013:<ul>
<li>Master Course, Graduate School of Information Science and Technology, the University of Tokyo. (Supervised by <a href="http://hil.t.u-tokyo.ac.jp/~sagayama/index-e.html">Prof. Shigeki Sagayama</a>)</li>
</ul>
</li>
<li>Jul. 2011 - Aug.:<ul>
<li>Summer internship at NTT Communication Science Lab. (Supervised by Dr. <a href="https://www.kecl.ntt.co.jp/as/members/iwata/">Tomoharu Iwata</a>)</li>
</ul>
</li>
<li>Apr. 2013 - Mar. 2016:<ul>
<li>Ph.D. Course, Graduate School of Information Science and Technology, the University of Tokyo. (Supervised by <a href="http://www.cyb.ipc.i.u-tokyo.ac.jp/members/hara/index.html">Prof. Shinji Hara</a> and <a href="http://hil.t.u-tokyo.ac.jp/~kameoka/index-e.html">Visiting Associate Prof. Hirokazu Kameoka</a>)</li>
</ul>
</li>
<li>Aug. 2013 - Sept. 2013:<ul>
<li>Internship at <a href="https://staff.aist.go.jp/m.goto/MIG/index-j.html">Media Interaction Group</a>, Information Technology Research Insitutute, National Institute of Advanced Industrial Science and Technology. (Supervised by <a href="https://staff.aist.go.jp/m.goto/index.html">Dr. Masataka Goto</a> and <a href="https://winnie.kuis.kyoto-u.ac.jp/members/yoshii">Dr. Kazuyoshi Yoshii</a>)</li>
</ul>
</li>
<li>Apr. 2015 - Mar. 2016:<ul>
<li>Research Fellow of Japan Society for the Promotion of Science (JSPS)</li>
</ul>
</li>
<li>Apr. 2016 - Aug. 2019:<ul>
<li>Intelligent Systems Laboratory, SECOM</li>
</ul>
</li>
<li>Sept. 2019 - Present:<ul>
<li>Project Research Associate, <a href="http://www.sp.ipc.i.u-tokyo.ac.jp/">Saruwatari &amp; Koyama Lab.</a>, Graduate School of Information Science and Technology, the University of Tokyo.</li>
</ul>
</li>
</ul>
<h2 id="publications">Publications<a class="headerlink" href="#publications" title="Permanent link">&para;</a></h2>
<h3 id="journals">Journals<a class="headerlink" href="#journals" title="Permanent link">&para;</a></h3>
<ol>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Harmonic-Temporal Factor Decomposition for Unsupervised Monaural Separation of Harmonic Sounds</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 29, pp. 68–82, Nov. 2020.<br />
<a href="https://doi.org/10.1109/TASLP.2020.3037487"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/HTFD/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips</strong>,” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 24, no. 2, pp. 329–339, Feb. 2016.<br />
<a href="https://doi.org/10.1109/TASLP.2015.2507862"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="http://arxiv.org/abs/1512.07748"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/automatic_accompaniment/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Yutaka Hori, and Shinji Hara, “<strong>Hierarchical Modeling and Local Stability Analysis for Repressilators Coupled by Quorum Sensing</strong>,” <em>SICE Journal of Control, Measurement, and System Integration</em>, vol. 7, no. 3, pp. 133–140, May 2014.<br />
<a href="https://www.jstage.jst.go.jp/article/jcmsi/7/3/7_133/_article"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[SICE Best Paper Award (Takeda Award) / 2015年計測自動制御学会 論文賞 (武田賞)]</span></li>
<li>Eita Nakamura, <ins>Tomohiko Nakamura</ins>, Yasuyuki Saito, Nobutaka Ono, and Shigeki Sagayama, “<strong>Outer-Product Type Hidden Markov Model and Polyphonic MIDI Score Following</strong>,” <em>Journal of New Music Research</em>, vol. 43, pp. 183–201, Apr. 2014.<br />
<a href="https://doi.org/10.1080/09298215.2014.884145"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="http://arxiv.org/abs/1404.2313"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
</ol>
<h3 id="international-conferences">International Conferences<a class="headerlink" href="#international-conferences" title="Permanent link">&para;</a></h3>
<ol>
<li>Shihori Kozuka, <ins>Tomohiko Nakamura</ins>, and Hiroshi Saruwatari, “<strong>Investigation on Wavelet Basis Function of DNN-Based Time Domain Audio Source Separation Inspired by Multiresolution Analysis</strong>,” in <em>Proceedings of the 49<sup>th</sup> International Congress and Exposition on Noise Control Engineering</em>, Aug. 2020, pp. 4013–4022.</li>
<li><ins>Tomohiko Nakamura</ins> and Saruwatari Hiroshi, “<strong>Time-Domain Audio Source Separation Based on Wave-u-Net Combined with Discrete Wavelet Transform</strong>,” in <em>Proceedings of the 45<sup>th</sup> International Conference on Acoustics, Speech, and Signal Processing</em>, May 2020, pp. 386–390.<br />
<a href="https://doi.org/10.1109/ICASSP40776.2020.9053934"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="https://arxiv.org/abs/2001.10190"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Shifted and Convolutive Source-Filter Non-Negative Matrix Factorization for Monaural Audio Source Separation</strong>,” in <em>Proceedings of the 41<sup>st</sup> IEEE International Conference on Acoustics, Speech and Signal Processing</em>, Mar. 2016, pp. 489–493.<br />
<a href="https://doi.org/10.1109/ICASSP.2016.7471723"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Kotaro Shikata, Norihiro Takamune, and Hirokazu Kameoka, “<strong>Harmonic-Temporal Factor Decomposition Incorporating Music Prior Information for Informed Monaural Source Separation</strong>,” in <em>Proceedings of the 15<sup>th</sup> International Society for Music Information Retrieval Conference</em>, Oct. 2014, pp. 623–628.<br />
<a href="https://archives.ismir.net/ismir2014/paper/000135.pdf"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/HTFD"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Tateishi Science and Technology Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Fast Signal Reconstruction from Magnitude Spectrogram of Continuous Wavelet Transform Based on Spectrogram Consistency</strong>,” in <em>Proceedings of the 17<sup>th</sup> International Conference on Digital Audio Effects</em>, Sep. 2014, pp. 129–135.<br />
<a href="http://www.dafx14.fau.de/papers/dafx14_tomohiko_nakamura_fast_signal_reconstructio.pdf"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/fastCWT/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Hara Research Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins>, Hirokazu Kameoka, Kazuyoshi Yoshii, and Masataka Goto, “<strong>Timbre Replacement of Harmonic and Drum Components for Music Audio Signals</strong>,” in <em>Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, May 2014.<br />
<a href="https://doi.org/10.1109/ICASSP.2014.6855052"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/drum_timbre_replacement/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a></li>
<li><ins>Tomohiko Nakamura</ins>, Eita Nakamura, and Shigeki Sagayama, “<strong>Acoustic Score Following to Musical Performance with Errors and Arbitrary Repeats and Skips for Automatic Accompaniment</strong>,” in <em>Proceedings of Sound and Music Computing Conference</em>, Aug. 2013, pp. 299–304.<br />
<a href="http://smcnetwork.org/node/1754"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <a href="demo/automatic_accompaniment"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M470.38 1.51L150.41 96A32 32 0 00128 126.51v261.41A139 139 0 0096 384c-53 0-96 28.66-96 64s43 64 96 64 96-28.66 96-64V214.32l256-75v184.61a138.4 138.4 0 00-32-3.93c-53 0-96 28.66-96 64s43 64 96 64 96-28.65 96-64V32a32 32 0 00-41.62-30.49z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[Travel Grant by the Telecommunications Advancement Foundation]</span></li>
<li><ins>Tomohiko Nakamura</ins>, Shinji Hara, and Yutaka Hori, “<strong>Local Stability Analysis for a Class of Quorum-Sensing Networks with Cyclic Gene Regulatory Networks</strong>,” in <em>Proceedings of SICE Annual Conference</em>, Sep. 2011.<br />
<a href="https://ieeexplore.ieee.org/document/6060320"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a> <span style="color: var(--md-code-hl-function-color)">[SICE Annual Conference 2011 International Award and Finalist of Young Author's Award]</span></li>
<li>Takuya Higuchi, Hirofumi Takeda, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>A Unified Approach for Underdetermined Blind Signal Separation and Source Activity Detection by Multichannel Factorial Hidden Markov Models</strong>,” in <em>Proceedings of the 15<sup>th</sup> Annual Conference of the International Speech Communication Association</em>, Sep. 2014, pp. 850–854.<br />
<a href="https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0850.pdf"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li>Takuya Higuchi, Norihiro Takamune, <ins>Tomohiko Nakamura</ins>, and Hirokazu Kameoka, “<strong>Underdetermined Blind Separation and Tracking of Moving Sources Based on DOA-HMM</strong>,” in <em>Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, May 2014, pp. 3215–3219.<br />
<a href="https://doi.org/10.1109/ICASSP.2014.6854189"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li>Shigeki Sagayama, <ins>Tomohiko Nakamura</ins>, Eita Nakamura, Yasuyuki Saito, Kameoka Hirokazu, and Nobutaka Ono, “<strong>Automatic Music Accompaniment Allowing Errors and Arbitrary Repeats and Jumps</strong>,” in <em>Proceedings of Meetings on Acoustics, Acoustic Society of America</em>, May 2014, vol. 21, 35003.<br />
<a href="https://doi.org/10.1121/1.4877848"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
<li>Masahiro Nakano, Jonathan Le Roux, Kameoka Hirokazu, <ins>Tomohiko Nakamura</ins>, Nobutaka Ono, and Shigeki Sagayama, “<strong>Bayesian Nonparametric Spectrogram Modeling Based on Infinite Factorial Infinite Hidden Markov Model</strong>,” in <em>Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, Oct. 2011, pp. 325–328.<br />
<a href="https://doi.org/10.1109/ASPAA.2011.6082324"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path d="M369.9 97.9L286 14C277 5 264.8-.1 252.1-.1H48C21.5 0 0 21.5 0 48v416c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V131.9c0-12.7-5.1-25-14.1-34zM332.1 128H256V51.9l76.1 76.1zM48 464V48h160v104c0 13.3 10.7 24 24 24h104v288H48zm250.2-143.7c-12.2-12-47-8.7-64.4-6.5-17.2-10.5-28.7-25-36.8-46.3 3.9-16.1 10.1-40.6 5.4-56-4.2-26.2-37.8-23.6-42.6-5.9-4.4 16.1-.4 38.5 7 67.1-10 23.9-24.9 56-35.4 74.4-20 10.3-47 26.2-51 46.2-3.3 15.8 26 55.2 76.1-31.2 22.4-7.4 46.8-16.5 68.4-20.1 18.9 10.2 41 17 55.8 17 25.5 0 28-28.2 17.5-38.7zm-198.1 77.8c5.1-13.7 24.5-29.5 30.4-35-19 30.3-30.4 35.7-30.4 35zm81.6-190.6c7.4 0 6.7 32.1 1.8 40.8-4.4-13.9-4.3-40.8-1.8-40.8zm-24.4 136.6c9.7-16.9 18-37 24.7-54.7 8.3 15.1 18.9 27.2 30.1 35.5-20.8 4.3-38.9 13.1-54.8 19.2zm131.6-5s-5 6-37.3-7.8c35.1-2.6 40.9 5.4 37.3 7.8z"/></svg></span></a></li>
</ol>
<h3 id="domestic-conferences">Domestic Conferences<a class="headerlink" href="#domestic-conferences" title="Permanent link">&para;</a></h3>
<ol>
<li>齋藤 弘一, <ins>中村 友彦</ins>, 矢田部 浩平, 小泉 悠馬,  猿渡洋, “<strong>潜在アナログフィルタ表現に基づく畳み込み層を用いたサンプリング周波数非依存なDNN音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, Mar. 2021. (to appear)</li>
<li>蓮実 拓也, <ins>中村 友彦</ins>, 高宗 典玄, 猿渡 洋, 北村 大地, 高橋 祐,  近藤 多伸, “<strong>経験ベイズ独立深層学習行列分析による多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, Mar. 2021. (to appear)</li>
<li>成澤 直輝, 池下 林太郎, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>, 猿渡 洋,  中谷 智広, “<strong>独立深層学習テンソル分析に基づく多チャネル音源分離</strong>,” <em>日本音響学会 2021年春季研究発表会講演論文集</em>, Mar. 2021. (to appear)</li>
<li>成澤 直輝, 高宗 典玄, 北村 大地, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>音源分離のための周波数間相関を考慮した多変量複素Gauss分布に基づく深層学習による分散共分散行列推定の検討</strong>,” <em>日本音響学会 2020年秋季研究発表会講演論文集</em>, pp. 315–318, Sep. 2020.</li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>ニューラルネットワークとウェーブレット基底関数の同時学習に基づく多重解像度深層分析を用いた時間領域音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, pp. 279–284, Mar. 2020.</li>
<li>高道 慎之介, 齋藤 佑樹, <ins>中村 友彦</ins>, 郡山 知樹,  猿渡 洋, “<strong>manga2voice: マンガ画像からの音声合成に向けた音声分析</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 1065–1068, Mar. 2020.</li>
<li>小塚 詩穂里, <ins>中村 友彦</ins>,  猿渡 洋, “<strong>リフティングスキームによる離散ウェーブレット変換を導入した深層ニューラルネットに基づく時間領域音源分離</strong>,” <em>日本音響学会2020年春季研究発表会講演論文集</em>, pp. 325–328, Mar. 2020.</li>
<li><ins>中村 友彦</ins> and 猿渡 洋, “<strong>Haar変換を導入した時間領域深層ニューラルネットに基づく音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 119, pp. 41–48, Nov. 2019.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムからの逐次位相推定法</strong>,” <em>情報処理学会研究報告</em>, May 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による超解像声道スペクトル推定法</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 115, pp. 99–104, Mar. 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>高速近似連続ウェーブレット変換による振幅スペクトログラムに対する実時間位相推定法</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 933–936, Mar. 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>非負値行列因子分解に基づく欠損データ補間による声道スペクトル推定法の検討</strong>,” <em>日本音響学会2016年春季研究発表会</em>, pp. 393–396, Mar. 2016.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>全極スペクトルモデルと擬似周期信号モデルのウェーブレット変換表現を用いた多重音スペクトログラムの調波時間因子分解</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–107, May 2015.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>全極スペクトルモデルを用いた調波時間因子分解による多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2015–MUS–106, Mar. 2015.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–104, Aug. 2014.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>無矛盾性規準に基づく連続ウェーブレット変換スペクトログラムへの位相推定法と高速化</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, May 2014.</li>
<li>樋口 卓也, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>確率的モデル化に基づく移動音源の劣決定ブラインド音源分離</strong>,” <em>電子情報通信学会技術研究報告</em>, vol. 114, pp. 211–216, May 2014.</li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解法に基づく事前情報付き多重音解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2014–MUS–103, May 2014.</li>
<li><ins>中村 友彦</ins> and 亀岡 弘和, “<strong>連続ウェーブレット変換の高速近似アルゴリズムに基づく振幅スケーログラムへの無矛盾位相付加法の検討</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, Mar. 2014.</li>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝,  亀岡 弘和, “<strong>音楽音響信号に含まれる調波音の周波数特性とドラムの音色の転写システム</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, Mar. 2014.</li>
<li>四方 紘太郎, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>調波時間因子分解に基づく音楽事前情報付き多重音解析</strong>,” <em>日本音響学会2014年春季研究発表会講演集</em>, Mar. 2014.</li>
<li>樋口 卓哉, 高宗 典玄, <ins>中村 友彦</ins>,  亀岡 弘和, “<strong>DOA-HMMに基づく劣決定ブラインド音源分離</strong>,” <em>日本音響学会2013年秋季研究発表会講演集</em>, Sep. 2013.</li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>誤り・任意の弾き直し・弾き飛ばしを含む演奏音響信号への高速な楽譜追跡</strong>,” <em>情報処理学会研究報告</em>, vol. 2013–MUS–99, May 2013.</li>
<li><ins>中村 友彦</ins>, 中村 栄太,  嵯峨山 茂樹, “<strong>弾き直し・弾き飛ばしを含む音楽演奏への高速な音響入力楽譜追跡</strong>,” <em>情報処理学会 第75回全国大会</em>, vol. 2013, pp. 283–284, Mar. 2013.</li>
<li><ins>中村 友彦</ins>, 水野 優, 鈴木 孝輔, 中村 栄太, 樋口 祐介, 深山 覚,  嵯峨山 茂樹, “<strong>音楽演奏の誤りや反復に頑健な音響入力自動伴奏</strong>,” <em>日本音響学会2012年秋季研究発表会講演集</em>, pp. 931–934, Sep. 2012.</li>
<li>中野 允裕, ルルー ジョナトン, 亀岡 弘和, <ins>中村 友彦</ins>, 小野 順貴,  嵯峨山 茂樹, “<strong>スペクトログラムのベイジアンノンパラメトリックモデリングに基づく音楽信号の解析</strong>,” <em>情報処理学会研究報告</em>, vol. 2011–MUS–91, Jul. 2011.</li>
</ol>
<h3 id="review-papers">Review Papers<a class="headerlink" href="#review-papers" title="Permanent link">&para;</a></h3>
<ol>
<li>亀岡 弘和, <ins>中村 友彦</ins>,  高宗 典玄, “<strong>音楽音響信号処理技術の最先端</strong>,” <em>電子情報通信学会誌</em>, vol. 98, no. 6, pp. 467–474, Jun. 2015.</li>
</ol>
<h3 id="symposium">Symposium<a class="headerlink" href="#symposium" title="Permanent link">&para;</a></h3>
<ol>
<li><ins>中村 友彦</ins>, 吉井 和佳, 後藤 真孝, 亀岡 弘和, <strong>"音楽音響信号中の調波音の周波数特性およびドラムの音色の置換システム,"</strong> <em>OngaCRESTシンポジウム2014-音楽情報処理研究が切り拓く未来を探る-,</em> Aug. 23, 2014.<ul>
<li><a href="http://ongacrest.jp/">OngaCREST</a></li>
<li><a href="http://av.watch.impress.co.jp/docs/series/dal/20140825_663420.html">「人型ロボットのダンス」や「声の年齢制御」など、音楽情報処理の最先端をレポート - 藤本健のDigital Audio Laboratory</a></li>
<li><a href="http://pc.watch.impress.co.jp/docs/column/kyokai/20140827_663740.html">コピー不可能な体験を価値の中核に～音楽情報処理の「OngaCRESTシンポジウム」レポート - 森山和道の「ヒトと機械の境界面」</a></li>
</ul>
</li>
</ol>
<h3 id="thesis">Thesis<a class="headerlink" href="#thesis" title="Permanent link">&para;</a></h3>
<ol>
<li>Ph.D. Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Source-Filter Representation and Phase Estimation in Continuous Wavelet Transform Domain for Monaural Music Audio Editing,"</strong> the University of Tokyo, Mar. 2016. <br />
   <span style="color: var(--md-code-hl-function-color)">[Dean’s Award, Graduate School of Information Science and Technology, The University of Tokyo / 東京大学大学院情報理工学系研究科 研究科長賞]</span></li>
<li>Master's Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Fast Score Following to Acoustic Signal of Musical Performance with Errors, Repeats and Skips,"</strong> the University of Tokyo, Mar. 2013. (in Japanese)</li>
<li>Bachelor's Thesis: <ins>Tomohiko Nakamura</ins>, <strong>"Local Stability Analysis of Cell-to-Cell Networks with Cyclic Gene Regulatory Networks,"</strong> the University of Tokyo, Mar. 2011. (in Japanese)</li>
</ol>
<h3 id="patents">Patents<a class="headerlink" href="#patents" title="Permanent link">&para;</a></h3>
<ol>
<li><ins>Tomohiko Nakamura</ins>, “<strong>Database Integration Device, Method, and Program, and Data Imputation Device</strong>,” Japan Unexamined Patent Application JP2020-140493, 28-Feb-2019. (in Japanse)</li>
<li><ins>Tomohiko Nakamura</ins>, “<strong>Object Recognition Device, Method, and Program</strong>,” Japan Unexamined Patent Application JP2020-135551, 21-Feb-2019. (in Japanse)</li>
<li><ins>Tomohiko Nakamura</ins>, “<strong>Training Device, Method, and Program for Object Recognition, and Object Recognition Device</strong>,” Japan Unexamined Patent Application JP2020-123105, 30-Jan-2019. (in Japanse)</li>
<li><ins>Tomohiko Nakamura</ins>, Tadahiko Ito, and Masaki Shimaoka, “<strong>Certificate Management Device</strong>,” Japan Patent JP6657259, 16-Jan-2020. (in Japanse)</li>
<li><ins>Tomohiko Nakamura</ins> and Hirokazu Kameoka, “<strong>Vocal Tract Spectrum Estimation Device, Method, and Program</strong>,” Japan Patent JP6420781, 19-Oct-2018. (in Japanse)</li>
</ol>
<h2 id="funds-awards">Funds &amp; Awards<a class="headerlink" href="#funds-awards" title="Permanent link">&para;</a></h2>
<h3 id="competitive-funds">Competitive Funds<a class="headerlink" href="#competitive-funds" title="Permanent link">&para;</a></h3>
<ul>
<li>Apr. 2020 - Present<ul>
<li>JSPS KAKENHI, Grant No. 20K19818, <strong>research representative</strong>.</li>
</ul>
</li>
<li>Apr. 2020 - Present<ul>
<li>Research Grant (A) of the Tateisi Science and Technology Foundation, <strong>research representative</strong>.</li>
</ul>
</li>
<li>Apr. 2020 - Present<ul>
<li>2020 Research Grant of Kawai Foundation for Sound Technology &amp; Music, <strong>research representative</strong>.</li>
</ul>
</li>
<li>Apr. 2020 - Present<ul>
<li>JSPS KAKENHI, Grant No. 19H01116, co-researcher.</li>
</ul>
</li>
<li>Apr. 2015 - Mar. 2016<ul>
<li>JSPS KAKENHI, Grant No. 15J09992, <strong>research representative</strong>.</li>
</ul>
</li>
</ul>
<h3 id="travel-grants">Travel Grants<a class="headerlink" href="#travel-grants" title="Permanent link">&para;</a></h3>
<ul>
<li>Grants for Researchers Attending International Conferences, The Tateishi Science and Technology Foundation (Oct. 2014)</li>
<li>Grants for Researchers Attending International Conferences, The Hara Research Foundation (Sept. 2014)</li>
<li>Grants for Researchers Attending International Conferences, The Telecommunications Advancement Foundation (Aug. 2013)</li>
</ul>
<h3 id="awards">Awards<a class="headerlink" href="#awards" title="Permanent link">&para;</a></h3>
<ul>
<li>IPSJ Recommended Ph.D. Thesis (Aug. 2016)</li>
<li>Dean’s Award from Graduate School of Information Science and Technology, The University of Tokyo (Mar. 2016)</li>
<li>Best Paper Award (Takeda Award) from SICE (Oct. 2015)</li>
<li>IPSJ Yamashita SIG Research Award (Mar. 2015)</li>
<li>Best Poster Award from Otogaku Symposium 2015 (May 2015)</li>
<li>Student Presentation Award from ASJ (Mar. 2014)</li>
<li>IPSJ Certificate of Excellent Master’s Thesis (Mar. 2013)</li>
<li>Student Encouragement Award of IPSJ National Convention (Mar. 2013)</li>
<li>SICE Annual Conference 2011 International Award (Sept. 2011)</li>
<li>SICE Annual Conference 2011 Finalist of Young Author Award (Sept. 2011)</li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2021- Tomohoiko Nakamura
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="assets/javascripts/vendor.08c56446.min.js"></script>
      <script src="assets/javascripts/bundle.6ced434e.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: ".",
          features: ['navigation.tabs', 'navigation.tabs.sticky', 'toc.integrate'],
          search: Object.assign({
            worker: "assets/javascripts/worker/search.8c7e0a7e.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>